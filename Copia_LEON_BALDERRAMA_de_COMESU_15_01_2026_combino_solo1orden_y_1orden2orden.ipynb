{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM2HaKKfijO8oCmhWsrrVfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatrizarellanograjales/seminario5/blob/main/Copia_LEON_BALDERRAMA_de_COMESU_15_01_2026_combino_solo1orden_y_1orden2orden.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fiabilidad interna: se calculó el alfa de Cronbach por constructo para medir la consistencia interna de los ítems.\n",
        "\n",
        "- Adecuación factorial: se aplicaron las pruebas KMO y Bartlett para confirmar la pertinencia del análisis factorial.  \n",
        "\n",
        "- Análisis factorial exploratorio (EFA): se identificó la estructura subyacente y el número óptimo de factores mediante autovalores y cargas.  \n",
        "\n",
        "- Análisis factorial confirmatorio (CFA): se usó el paquete semopy en Python para estimar el modelo y verificar la carga de cada ítem en su factor teórico.  \n",
        "\n",
        "- Índices de ajuste global (CFI, TLI, RMSEA, AIC, BIC): se evaluó el ajuste general del modelo confirmatorio.  \n",
        "\n",
        "- Validez convergente: se calcularon los valores de AVE y CR, comprobando que los ítems explican suficiente varianza compartida.  \n",
        "\n",
        "- Validez discriminante: se aplicó el criterio de Fornell–Larcker para confirmar la independencia entre constructos.  \n"
      ],
      "metadata": {
        "id": "WH8mcxm2K6Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección  de promedio de los constructos de primer orden\n",
        "\n",
        "> Generar excel  y CSV con el promedio de los constructos, sin necesidad de hacerlo manualmente\n",
        "\n",
        "\n",
        "\n",
        "carculos sacados del paper\n",
        "https://www.mendeley.com/reference-manager/reader/cdbc238a-5061-32dd-860f-ca1fe3b85626/0aef4186-c8c2-9a41-3e14-816a75c39d89\n",
        "\n",
        "Congruence effects in social media influencer marketing in\n",
        "online impulse buying intentions of digital immigrants: The\n",
        "mediating role of descriptive and injunctive norms\n",
        "\n",
        "https://doi.org/10.1080/13527266.2025.2527249\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b61EhAFSusqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Cargar el Excel (en Colab suele estar en /content/ si lo subes manualmente)\n",
        "path = \"datos_codificados_ajustados (1).xlsx\"\n",
        "df = pd.read_excel(path)\n",
        "\n",
        "# 2) Diccionario de constructos -> ítems/columnas\n",
        "constructos = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# 3) Validar columnas (por si falta algo)\n",
        "cols = set(df.columns)\n",
        "faltantes = {k: [c for c in v if c not in cols] for k, v in constructos.items()}\n",
        "faltantes = {k: v for k, v in faltantes.items() if v}\n",
        "if faltantes:\n",
        "    raise ValueError(f\"Faltan columnas en el archivo: {faltantes}\")\n",
        "\n",
        "# 4) Asegurar que los ítems sean numéricos (si hay textos, se convierten a NaN)\n",
        "items_all = [c for items in constructos.values() for c in items]\n",
        "df[items_all] = df[items_all].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# 5) Calcular promedios por constructo (fila por fila)\n",
        "df_constructos = pd.DataFrame(index=df.index)\n",
        "for nombre, items in constructos.items():\n",
        "    df_constructos[nombre] = df[items].mean(axis=1, skipna=True)\n",
        "\n",
        "# 6) Resultado: dataframe solo con los promedios solo los primero 5 resultados\n",
        "#print(\"Promedios por constructo (primeras filas):\")\n",
        "#display(df_constructos.head())\n",
        "\n",
        "# 6) Resultado:\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "display(df_constructos)\n",
        "\n",
        "\n",
        "# (Opcional) Guardar a Excel/CSV\n",
        "df_constructos.to_excel(\"promedios_constructos.xlsx\", index=False)\n",
        "df_constructos.to_csv(\"promedios_constructos.csv\", index=False)\n",
        "\n",
        "print(\"Archivos guardados: promedios_constructos.xlsx y promedios_constructos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kEb1iAkIkxjz",
        "outputId": "f07b70ad-5696-4495-d16f-b3be685d77be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     integridad  expertis  autenticidad  atractividad  similitud  \\\n",
              "0          3.50      4.00      5.000000          3.50   4.000000   \n",
              "1          4.25      3.50      4.666667          4.00   4.000000   \n",
              "2          2.75      4.25      4.666667          4.00   3.666667   \n",
              "3          5.00      3.75      4.000000          4.00   2.333333   \n",
              "4          4.25      3.50      3.666667          4.00   4.333333   \n",
              "5          5.00      3.50      3.666667          4.25   3.000000   \n",
              "6          4.00      3.50      5.000000          3.75   4.000000   \n",
              "7          4.50      3.75      3.000000          4.00   3.666667   \n",
              "8          4.50      4.25      4.666667          4.50   4.000000   \n",
              "9          4.00      4.00      3.333333          4.00   4.000000   \n",
              "10         4.25      3.00      5.000000          4.00   4.666667   \n",
              "11         4.50      4.75      4.333333          3.25   3.666667   \n",
              "12         4.00      3.25      4.666667          3.50   4.000000   \n",
              "13         3.00      3.75      3.333333          2.75   4.000000   \n",
              "14         4.25      4.25      4.000000          3.00   5.000000   \n",
              "15         2.75      3.75      3.666667          3.50   3.666667   \n",
              "16         4.00      3.75      5.000000          3.50   3.333333   \n",
              "17         4.00      5.00      2.666667          4.00   4.333333   \n",
              "18         4.00      4.25      3.666667          4.50   4.000000   \n",
              "19         3.50      3.50      3.000000          3.50   3.333333   \n",
              "20         4.50      2.25      3.666667          4.50   5.000000   \n",
              "21         4.25      5.00      4.000000          4.00   4.333333   \n",
              "22         4.00      4.25      2.666667          5.00   3.666667   \n",
              "23         4.00      3.25      3.000000          1.75   4.666667   \n",
              "24         4.25      4.50      4.000000          4.00   4.666667   \n",
              "25         3.50      3.50      2.666667          4.50   4.333333   \n",
              "26         4.00      4.50      4.000000          4.50   4.000000   \n",
              "27         4.25      5.00      5.000000          3.50   2.333333   \n",
              "28         3.75      4.25      3.333333          4.00   4.333333   \n",
              "29         4.75      4.00      4.000000          5.00   4.666667   \n",
              "30         4.50      4.25      3.666667          3.75   2.666667   \n",
              "31         5.00      4.50      4.000000          4.50   3.666667   \n",
              "32         5.00      5.00      5.000000          4.50   4.000000   \n",
              "33         4.75      4.50      3.333333          3.75   4.000000   \n",
              "34         3.75      4.75      5.000000          5.00   4.000000   \n",
              "35         2.75      3.75      3.000000          5.00   4.000000   \n",
              "36         3.50      4.25      4.000000          4.50   4.000000   \n",
              "37         4.25      4.00      4.333333          3.50   4.000000   \n",
              "38         4.00      4.25      4.333333          4.00   5.000000   \n",
              "39         3.75      2.50      4.333333          5.00   5.000000   \n",
              "40         5.00      4.50      4.666667          3.50   3.000000   \n",
              "41         4.75      4.50      4.000000          4.00   4.000000   \n",
              "42         3.50      4.50      4.666667          5.00   4.333333   \n",
              "43         4.75      3.75      3.666667          4.25   3.666667   \n",
              "44         3.25      4.50      5.000000          4.00   3.333333   \n",
              "45         4.00      2.75      4.000000          3.75   1.000000   \n",
              "46         4.00      3.50      4.000000          3.50   4.000000   \n",
              "47         4.25      4.00      4.000000          4.00   4.666667   \n",
              "48         4.00      4.50      3.333333          4.25   4.333333   \n",
              "49         3.75      4.00      3.333333          4.75   4.000000   \n",
              "50         4.75      4.25      2.666667          4.00   4.000000   \n",
              "51         4.00      5.00      5.000000          5.00   4.333333   \n",
              "52         4.00      3.50      4.666667          3.75   2.000000   \n",
              "53         4.25      3.75      4.333333          5.00   4.000000   \n",
              "54         4.75      3.50      3.000000          4.00   4.666667   \n",
              "55         4.00      4.00      4.333333          4.50   3.666667   \n",
              "56         3.75      4.75      4.333333          3.75   4.000000   \n",
              "57         4.00      4.75      5.000000          3.75   4.000000   \n",
              "58         3.25      4.25      4.000000          3.75   4.000000   \n",
              "59         4.25      3.75      4.666667          4.25   4.000000   \n",
              "60         4.25      4.75      4.666667          4.50   4.666667   \n",
              "61         2.50      3.25      4.000000          5.00   3.666667   \n",
              "62         4.75      4.50      4.000000          3.50   4.000000   \n",
              "63         3.50      4.00      4.333333          4.00   5.000000   \n",
              "64         4.50      4.25      4.000000          4.00   4.666667   \n",
              "65         3.25      3.50      3.666667          3.50   4.666667   \n",
              "66         3.25      4.50      5.000000          3.25   3.666667   \n",
              "67         3.75      3.50      5.000000          3.50   4.333333   \n",
              "68         3.25      4.75      5.000000          3.75   4.000000   \n",
              "69         5.00      4.50      4.666667          5.00   3.666667   \n",
              "70         4.75      4.75      4.000000          3.25   3.000000   \n",
              "71         3.50      3.75      3.666667          3.00   5.000000   \n",
              "72         5.00      3.50      4.000000          5.00   4.000000   \n",
              "73         3.75      3.25      2.666667          3.75   4.000000   \n",
              "74         3.50      4.00      5.000000          4.00   3.333333   \n",
              "75         3.00      4.25      4.000000          4.00   4.000000   \n",
              "76         5.00      5.00      4.000000          5.00   3.000000   \n",
              "77         4.25      4.75      4.333333          4.00   5.000000   \n",
              "78         4.50      3.00      4.333333          2.00   4.000000   \n",
              "79         4.00      4.75      4.333333          3.00   4.666667   \n",
              "80         4.50      4.00      4.333333          4.25   3.333333   \n",
              "81         1.75      4.75      2.666667          3.50   4.333333   \n",
              "82         4.50      5.00      3.333333          4.50   4.333333   \n",
              "83         3.25      3.25      5.000000          4.00   5.000000   \n",
              "84         4.00      3.75      3.333333          4.00   3.666667   \n",
              "85         4.50      2.25      4.333333          3.75   5.000000   \n",
              "86         5.00      4.00      4.666667          4.00   4.333333   \n",
              "87         3.50      3.75      4.666667          3.50   4.000000   \n",
              "88         4.00      3.75      4.000000          5.00   5.000000   \n",
              "89         4.50      4.00      4.333333          4.00   4.333333   \n",
              "90         4.50      4.00      3.666667          4.00   3.666667   \n",
              "91         4.25      3.75      4.333333          4.25   5.000000   \n",
              "92         3.25      3.00      4.000000          3.75   5.000000   \n",
              "93         4.00      4.75      4.000000          3.75   3.666667   \n",
              "94         5.00      3.50      5.000000          3.50   3.666667   \n",
              "95         4.25      4.25      4.000000          4.75   3.666667   \n",
              "96         4.50      3.50      5.000000          4.75   3.333333   \n",
              "97         4.00      4.75      2.666667          4.25   3.333333   \n",
              "98         3.25      4.00      3.000000          4.00   4.000000   \n",
              "99         5.00      4.75      4.666667          4.25   3.666667   \n",
              "100        5.00      4.00      3.333333          3.50   4.666667   \n",
              "101        4.00      4.25      4.333333          2.75   4.000000   \n",
              "102        4.50      4.50      4.666667          3.25   4.000000   \n",
              "103        4.25      4.50      4.333333          3.50   3.333333   \n",
              "104        3.50      3.75      4.000000          3.00   4.000000   \n",
              "105        4.25      3.50      4.000000          4.00   5.000000   \n",
              "106        3.00      3.50      4.333333          4.00   4.000000   \n",
              "107        5.00      4.75      4.666667          5.00   3.666667   \n",
              "108        3.00      3.00      5.000000          5.00   3.666667   \n",
              "109        4.00      3.25      4.333333          4.00   3.333333   \n",
              "110        2.25      4.50      4.000000          4.25   4.000000   \n",
              "111        4.50      2.75      2.666667          3.75   3.000000   \n",
              "112        4.50      4.25      4.666667          3.50   4.333333   \n",
              "113        3.75      4.25      4.333333          4.00   5.000000   \n",
              "114        4.50      3.25      4.666667          4.50   5.000000   \n",
              "115        4.00      4.50      3.666667          2.00   3.666667   \n",
              "116        5.00      4.00      5.000000          4.25   4.666667   \n",
              "117        4.00      4.00      3.333333          3.25   4.000000   \n",
              "118        4.25      4.00      4.000000          3.75   4.333333   \n",
              "119        4.00      4.25      4.666667          4.00   4.000000   \n",
              "120        5.00      4.00      3.666667          4.25   4.000000   \n",
              "121        3.75      2.75      4.000000          3.50   5.000000   \n",
              "122        2.25      3.75      4.000000          4.25   5.000000   \n",
              "123        2.25      4.00      3.666667          3.50   5.000000   \n",
              "124        3.00      3.25      4.333333          3.25   4.000000   \n",
              "125        4.25      4.50      4.333333          3.50   4.000000   \n",
              "126        4.75      3.75      4.000000          2.75   5.000000   \n",
              "127        4.50      4.00      4.333333          3.75   4.000000   \n",
              "128        3.75      4.00      4.000000          3.50   2.333333   \n",
              "129        2.00      4.25      3.000000          3.50   4.666667   \n",
              "130        4.25      4.25      5.000000          4.50   5.000000   \n",
              "131        3.25      4.00      4.333333          4.00   4.666667   \n",
              "132        4.00      2.50      2.666667          4.00   5.000000   \n",
              "133        3.75      5.00      5.000000          5.00   4.666667   \n",
              "134        4.25      4.00      4.333333          3.75   4.000000   \n",
              "135        5.00      4.00      3.333333          5.00   3.333333   \n",
              "136        3.75      3.50      3.333333          4.75   4.000000   \n",
              "137        4.75      3.75      4.666667          4.50   4.000000   \n",
              "138        3.75      4.25      3.000000          4.00   4.333333   \n",
              "139        2.75      4.25      3.000000          5.00   5.000000   \n",
              "140        4.75      4.75      5.000000          5.00   5.000000   \n",
              "141        3.75      3.75      3.666667          4.25   4.000000   \n",
              "142        4.50      2.75      4.666667          4.00   2.000000   \n",
              "143        5.00      3.25      4.666667          3.25   4.333333   \n",
              "144        4.75      4.25      3.666667          4.00   4.000000   \n",
              "145        4.00      4.50      4.333333          4.00   3.000000   \n",
              "146        3.75      4.50      3.000000          4.25   4.000000   \n",
              "147        4.00      4.25      3.333333          3.25   4.000000   \n",
              "148        3.75      3.00      5.000000          4.00   4.666667   \n",
              "149        4.25      4.75      4.666667          4.00   4.666667   \n",
              "150        3.25      3.50      4.333333          3.00   2.666667   \n",
              "151        2.50      4.25      4.000000          3.50   4.333333   \n",
              "152        4.00      4.25      4.000000          4.50   4.000000   \n",
              "153        4.50      3.25      5.000000          4.00   4.666667   \n",
              "154        3.75      3.00      3.666667          3.50   4.000000   \n",
              "155        5.00      4.25      4.000000          2.50   4.333333   \n",
              "156        4.00      3.00      2.000000          5.00   4.333333   \n",
              "157        3.50      4.25      4.000000          4.00   3.333333   \n",
              "158        4.75      4.75      4.333333          4.25   4.000000   \n",
              "159        3.75      2.75      4.666667          5.00   3.000000   \n",
              "160        4.25      4.00      3.333333          4.00   4.666667   \n",
              "161        4.25      3.50      3.666667          4.00   5.000000   \n",
              "162        4.00      4.50      4.000000          4.00   4.666667   \n",
              "163        4.00      3.50      4.666667          4.00   4.000000   \n",
              "164        3.75      3.50      2.333333          3.00   3.666667   \n",
              "165        4.25      4.75      4.666667          4.25   4.333333   \n",
              "166        3.50      4.00      4.333333          4.00   3.000000   \n",
              "167        4.00      4.00      3.666667          4.00   3.666667   \n",
              "168        2.75      3.25      5.000000          3.75   5.000000   \n",
              "169        4.00      3.75      4.000000          4.00   3.000000   \n",
              "170        3.75      4.75      3.333333          3.50   4.000000   \n",
              "171        4.50      4.00      4.666667          4.25   3.666667   \n",
              "172        3.75      4.75      3.666667          3.25   4.666667   \n",
              "173        3.00      4.00      4.333333          4.75   4.333333   \n",
              "174        4.00      4.50      3.000000          4.50   3.333333   \n",
              "175        3.75      4.50      4.666667          3.75   3.000000   \n",
              "176        4.25      3.75      4.000000          4.00   3.333333   \n",
              "177        4.25      4.00      4.000000          4.50   4.666667   \n",
              "178        3.25      3.75      3.666667          3.00   4.000000   \n",
              "179        3.75      3.25      3.333333          3.00   5.000000   \n",
              "180        2.50      3.25      4.666667          4.50   4.000000   \n",
              "181        3.50      3.25      4.000000          4.50   5.000000   \n",
              "182        3.50      4.25      4.333333          4.75   4.000000   \n",
              "183        3.75      4.25      3.000000          5.00   4.000000   \n",
              "184        4.00      4.50      3.666667          3.25   3.333333   \n",
              "185        3.00      3.25      4.000000          4.00   2.000000   \n",
              "186        3.00      4.25      5.000000          4.75   4.333333   \n",
              "187        4.25      3.00      3.000000          4.00   5.000000   \n",
              "188        4.00      4.00      4.000000          4.75   4.000000   \n",
              "189        3.50      4.50      3.000000          3.00   2.333333   \n",
              "190        3.25      4.00      4.666667          3.50   4.333333   \n",
              "191        3.75      3.25      4.000000          3.50   5.000000   \n",
              "192        3.50      3.25      4.000000          1.25   2.666667   \n",
              "193        4.25      4.00      3.666667          4.25   3.333333   \n",
              "194        3.75      4.75      4.000000          4.00   4.666667   \n",
              "195        4.00      4.75      4.333333          4.50   5.000000   \n",
              "196        3.75      3.75      3.333333          4.00   3.333333   \n",
              "197        4.25      4.75      4.333333          3.75   2.666667   \n",
              "198        5.00      5.00      4.000000          4.00   5.000000   \n",
              "199        4.25      4.75      5.000000          3.50   3.666667   \n",
              "200        2.50      5.00      4.333333          4.50   3.666667   \n",
              "201        5.00      5.00      3.666667          4.50   3.000000   \n",
              "202        3.25      3.50      4.000000          5.00   3.000000   \n",
              "203        4.75      4.50      4.333333          3.75   1.333333   \n",
              "204        3.25      4.75      5.000000          3.75   4.000000   \n",
              "205        4.00      3.75      4.666667          4.00   3.666667   \n",
              "206        4.00      4.75      5.000000          4.75   3.333333   \n",
              "207        4.00      5.00      2.000000          3.25   4.000000   \n",
              "208        4.25      3.75      5.000000          3.00   4.333333   \n",
              "209        4.00      4.00      4.333333          4.00   2.666667   \n",
              "210        4.50      5.00      3.666667          4.75   4.666667   \n",
              "211        3.50      3.25      3.666667          3.00   2.666667   \n",
              "212        4.00      3.75      4.000000          2.75   5.000000   \n",
              "213        4.25      3.00      4.666667           NaN   4.000000   \n",
              "214        4.00      4.00      4.000000          4.75   2.333333   \n",
              "215        3.50      4.50      4.000000          4.75   4.333333   \n",
              "216        4.50      4.00      3.333333          4.50   3.333333   \n",
              "217        4.25      3.75      4.666667          4.25   5.000000   \n",
              "218        3.75      4.25      4.333333          4.00   4.333333   \n",
              "219        4.25      2.50      5.000000           NaN   4.000000   \n",
              "220        4.50      4.00      4.000000          4.75   5.000000   \n",
              "221        3.25      5.00      5.000000          3.25   1.333333   \n",
              "222        4.75      4.00      4.666667          4.00   4.000000   \n",
              "223        4.00      3.75      5.000000          3.75   3.666667   \n",
              "224        4.00      4.50      4.000000          4.25   4.000000   \n",
              "225        3.75      3.75      4.000000          3.25   4.000000   \n",
              "226        3.00      4.75      4.000000          2.50   3.666667   \n",
              "227        4.75      4.25      4.000000          4.50   3.666667   \n",
              "228        3.50      4.25      4.333333          4.50   4.000000   \n",
              "229        3.25      4.25      4.000000          4.75   3.666667   \n",
              "230        5.00      4.25      4.333333          3.50   3.666667   \n",
              "231        3.25      4.50      3.333333          5.00   5.000000   \n",
              "232        3.75      3.75      4.000000          5.00   3.333333   \n",
              "233        4.50      3.50      3.666667          3.75   1.333333   \n",
              "234        3.25      4.75      4.666667          5.00   3.333333   \n",
              "235        5.00      3.25      3.666667          3.75   4.666667   \n",
              "236        3.00      2.75      4.000000          4.00   4.000000   \n",
              "237        5.00      2.75      5.000000          4.00   3.333333   \n",
              "238        4.75      4.75      4.000000          4.25   3.333333   \n",
              "239        4.25      4.00      4.333333          5.00   2.666667   \n",
              "\n",
              "     lider_de_opinion  informatividad_del_contenido  \\\n",
              "0                1.75                      4.000000   \n",
              "1                4.00                      3.333333   \n",
              "2                4.00                      5.000000   \n",
              "3                1.50                      3.666667   \n",
              "4                5.00                      5.000000   \n",
              "5                3.75                      3.666667   \n",
              "6                4.75                      4.000000   \n",
              "7                2.75                      4.333333   \n",
              "8                4.00                      3.333333   \n",
              "9                4.25                      4.666667   \n",
              "10               4.50                      4.333333   \n",
              "11               2.75                      4.000000   \n",
              "12               4.00                      4.333333   \n",
              "13               5.00                      3.666667   \n",
              "14               4.25                      3.333333   \n",
              "15               3.75                      3.666667   \n",
              "16               4.25                      5.000000   \n",
              "17               3.25                      3.000000   \n",
              "18               3.75                      4.333333   \n",
              "19               4.25                      3.333333   \n",
              "20               4.25                      4.000000   \n",
              "21               4.25                      4.333333   \n",
              "22               4.00                      3.333333   \n",
              "23               3.00                      3.333333   \n",
              "24               3.00                      3.666667   \n",
              "25               4.00                      5.000000   \n",
              "26               2.50                      4.666667   \n",
              "27               4.50                      3.333333   \n",
              "28               4.25                      4.000000   \n",
              "29               4.25                      5.000000   \n",
              "30               4.25                      4.666667   \n",
              "31               3.00                      4.333333   \n",
              "32               4.00                      3.666667   \n",
              "33               3.75                      4.000000   \n",
              "34               3.25                      4.000000   \n",
              "35               3.25                      4.666667   \n",
              "36               3.75                      5.000000   \n",
              "37               4.00                      5.000000   \n",
              "38               4.00                      3.666667   \n",
              "39               4.00                      4.000000   \n",
              "40               4.50                      3.666667   \n",
              "41               4.75                      3.333333   \n",
              "42               2.25                      4.000000   \n",
              "43               5.00                      4.333333   \n",
              "44               4.00                      3.000000   \n",
              "45               4.25                      3.000000   \n",
              "46               4.25                      4.000000   \n",
              "47               4.00                      4.000000   \n",
              "48               4.25                      2.666667   \n",
              "49               4.25                      5.000000   \n",
              "50               4.00                      3.666667   \n",
              "51               4.00                      4.000000   \n",
              "52               5.00                      4.000000   \n",
              "53               3.00                      3.333333   \n",
              "54               3.75                      4.666667   \n",
              "55               4.75                      3.000000   \n",
              "56               4.25                      4.666667   \n",
              "57               4.50                      3.000000   \n",
              "58               4.25                      3.666667   \n",
              "59               4.75                      4.333333   \n",
              "60               4.25                      4.000000   \n",
              "61               4.00                      4.000000   \n",
              "62               4.75                      4.000000   \n",
              "63               3.75                      4.000000   \n",
              "64               2.75                      2.000000   \n",
              "65               2.50                      4.666667   \n",
              "66               3.75                      3.000000   \n",
              "67               4.00                      3.666667   \n",
              "68               3.00                      3.333333   \n",
              "69               4.00                      4.000000   \n",
              "70               5.00                      4.000000   \n",
              "71               4.25                      4.333333   \n",
              "72               4.75                      5.000000   \n",
              "73               4.00                      5.000000   \n",
              "74               4.25                      5.000000   \n",
              "75               3.75                      3.666667   \n",
              "76               4.25                      4.333333   \n",
              "77               3.00                      3.333333   \n",
              "78               3.25                      4.000000   \n",
              "79               4.75                      4.666667   \n",
              "80               3.50                      3.666667   \n",
              "81               3.75                      3.000000   \n",
              "82               4.00                      5.000000   \n",
              "83               4.50                      4.000000   \n",
              "84               4.25                      3.666667   \n",
              "85               4.00                      4.000000   \n",
              "86               4.00                      4.333333   \n",
              "87               3.75                      5.000000   \n",
              "88               4.00                      4.000000   \n",
              "89               3.25                      4.000000   \n",
              "90               4.25                      4.666667   \n",
              "91               4.00                      3.666667   \n",
              "92               3.50                      4.333333   \n",
              "93               3.75                      4.666667   \n",
              "94               4.75                      3.333333   \n",
              "95               3.00                      4.000000   \n",
              "96               4.00                      4.333333   \n",
              "97               4.00                      4.333333   \n",
              "98               5.00                      3.333333   \n",
              "99               3.75                      4.333333   \n",
              "100              3.25                      4.666667   \n",
              "101              3.75                      3.000000   \n",
              "102              4.00                      4.000000   \n",
              "103              3.75                      3.666667   \n",
              "104              4.25                      4.333333   \n",
              "105              4.00                      4.666667   \n",
              "106              4.00                      4.000000   \n",
              "107              4.75                      4.333333   \n",
              "108              4.75                      4.333333   \n",
              "109              2.75                      4.666667   \n",
              "110              3.75                      4.333333   \n",
              "111              3.25                      4.666667   \n",
              "112              4.00                      4.000000   \n",
              "113              4.00                      5.000000   \n",
              "114              2.75                      4.333333   \n",
              "115              4.25                      4.000000   \n",
              "116              4.00                      3.000000   \n",
              "117              4.25                      3.666667   \n",
              "118              4.00                      4.000000   \n",
              "119              4.25                      4.000000   \n",
              "120              5.00                      4.333333   \n",
              "121              5.00                      4.333333   \n",
              "122              5.00                      4.666667   \n",
              "123              2.50                      3.666667   \n",
              "124              4.50                      3.666667   \n",
              "125              5.00                      5.000000   \n",
              "126              3.75                      4.666667   \n",
              "127              3.25                      4.333333   \n",
              "128              5.00                      2.666667   \n",
              "129              4.00                      4.000000   \n",
              "130              3.75                      3.666667   \n",
              "131              4.50                      4.333333   \n",
              "132              4.50                      2.666667   \n",
              "133              4.00                      3.000000   \n",
              "134              4.00                      3.000000   \n",
              "135              3.25                      4.333333   \n",
              "136              4.00                      4.000000   \n",
              "137              4.50                      3.333333   \n",
              "138              4.00                      5.000000   \n",
              "139              4.00                      3.666667   \n",
              "140              4.00                      5.000000   \n",
              "141              4.00                      3.000000   \n",
              "142              3.25                      2.666667   \n",
              "143              4.00                      4.666667   \n",
              "144              4.00                      2.666667   \n",
              "145              3.75                      5.000000   \n",
              "146              4.50                      3.666667   \n",
              "147              4.25                      4.333333   \n",
              "148              3.50                      4.333333   \n",
              "149              4.25                      4.000000   \n",
              "150              5.00                      3.666667   \n",
              "151              4.00                      3.333333   \n",
              "152              5.00                      3.000000   \n",
              "153              4.00                      4.333333   \n",
              "154              5.00                      4.000000   \n",
              "155              3.50                      3.333333   \n",
              "156              4.00                      3.666667   \n",
              "157              4.25                      3.333333   \n",
              "158              3.75                      3.666667   \n",
              "159              3.75                      3.333333   \n",
              "160              3.75                      5.000000   \n",
              "161              3.75                      5.000000   \n",
              "162              4.25                      3.666667   \n",
              "163              4.00                      5.000000   \n",
              "164              3.50                      5.000000   \n",
              "165              4.75                      4.333333   \n",
              "166              4.25                      3.000000   \n",
              "167              4.25                      4.333333   \n",
              "168              3.75                      4.000000   \n",
              "169              4.00                      4.000000   \n",
              "170              3.75                      4.666667   \n",
              "171              4.75                      3.666667   \n",
              "172              4.00                      4.000000   \n",
              "173              4.25                      3.333333   \n",
              "174              4.75                      4.000000   \n",
              "175              2.25                      4.000000   \n",
              "176              3.00                      4.333333   \n",
              "177              5.00                      4.666667   \n",
              "178              4.00                      4.000000   \n",
              "179              4.25                      5.000000   \n",
              "180              3.50                      5.000000   \n",
              "181              4.00                      4.333333   \n",
              "182              4.75                      4.000000   \n",
              "183              3.00                      4.333333   \n",
              "184              4.00                      4.333333   \n",
              "185              4.25                      4.666667   \n",
              "186              4.00                      4.000000   \n",
              "187              4.00                      3.000000   \n",
              "188              4.00                      3.000000   \n",
              "189              4.50                      4.000000   \n",
              "190              4.75                      4.333333   \n",
              "191              4.00                      3.666667   \n",
              "192              4.00                      4.666667   \n",
              "193              5.00                      5.000000   \n",
              "194              3.50                      5.000000   \n",
              "195              4.25                      5.000000   \n",
              "196              3.75                      4.333333   \n",
              "197              4.00                      3.000000   \n",
              "198              5.00                      4.000000   \n",
              "199              4.00                      4.333333   \n",
              "200              4.00                      4.333333   \n",
              "201              3.75                      3.000000   \n",
              "202              3.00                      4.000000   \n",
              "203              4.00                      4.000000   \n",
              "204              5.00                      3.666667   \n",
              "205              4.25                      4.333333   \n",
              "206              4.75                      4.666667   \n",
              "207              4.00                      4.333333   \n",
              "208              3.50                      3.333333   \n",
              "209              5.00                      4.000000   \n",
              "210              4.25                      4.000000   \n",
              "211              4.25                      4.666667   \n",
              "212              4.25                      3.333333   \n",
              "213              3.25                      3.666667   \n",
              "214              4.00                      4.000000   \n",
              "215              4.75                      4.000000   \n",
              "216              4.00                      4.000000   \n",
              "217              4.25                      3.666667   \n",
              "218              4.00                      5.000000   \n",
              "219              2.50                      4.333333   \n",
              "220              4.50                      4.333333   \n",
              "221              4.25                      3.666667   \n",
              "222              4.00                      4.333333   \n",
              "223              5.00                      3.666667   \n",
              "224              4.00                      3.333333   \n",
              "225              4.50                      4.333333   \n",
              "226              3.75                      5.000000   \n",
              "227              3.75                      4.333333   \n",
              "228              4.25                      3.333333   \n",
              "229              2.50                      4.000000   \n",
              "230              3.50                      2.666667   \n",
              "231              4.00                      3.666667   \n",
              "232              4.00                      4.000000   \n",
              "233              4.50                      4.000000   \n",
              "234              3.50                      4.333333   \n",
              "235              4.50                      4.666667   \n",
              "236              4.75                      4.000000   \n",
              "237              4.50                      3.000000   \n",
              "238              5.00                      5.000000   \n",
              "239              3.75                      3.666667   \n",
              "\n",
              "     congruencia_influencer_follower  congruencia_influencer_producto  \\\n",
              "0                           4.333333                         3.666667   \n",
              "1                           3.333333                         5.000000   \n",
              "2                           4.000000                         3.333333   \n",
              "3                           4.333333                         4.000000   \n",
              "4                           1.666667                         4.333333   \n",
              "5                           4.000000                         4.333333   \n",
              "6                           4.333333                         3.666667   \n",
              "7                           4.000000                         5.000000   \n",
              "8                           4.333333                         4.000000   \n",
              "9                           4.666667                         4.000000   \n",
              "10                          3.666667                         4.666667   \n",
              "11                          1.000000                         4.000000   \n",
              "12                          4.333333                         4.000000   \n",
              "13                          4.000000                         4.333333   \n",
              "14                          3.333333                         4.000000   \n",
              "15                          3.333333                         5.000000   \n",
              "16                          4.666667                         4.000000   \n",
              "17                          1.666667                         4.000000   \n",
              "18                          4.666667                         3.000000   \n",
              "19                          3.666667                         4.333333   \n",
              "20                          4.333333                         3.333333   \n",
              "21                          4.333333                         2.666667   \n",
              "22                          4.000000                         5.000000   \n",
              "23                          3.000000                         5.000000   \n",
              "24                          4.000000                         4.333333   \n",
              "25                          3.000000                         4.000000   \n",
              "26                          4.000000                         5.000000   \n",
              "27                          4.333333                         3.666667   \n",
              "28                          3.000000                         4.000000   \n",
              "29                          3.333333                         3.333333   \n",
              "30                          3.666667                         5.000000   \n",
              "31                          4.333333                         2.666667   \n",
              "32                          3.000000                         4.000000   \n",
              "33                          5.000000                         3.666667   \n",
              "34                          4.333333                         5.000000   \n",
              "35                          4.333333                         5.000000   \n",
              "36                          2.666667                         3.666667   \n",
              "37                          4.333333                         4.666667   \n",
              "38                          3.333333                         4.000000   \n",
              "39                          4.000000                         4.000000   \n",
              "40                          4.666667                         4.000000   \n",
              "41                          4.333333                         4.000000   \n",
              "42                          3.666667                         4.666667   \n",
              "43                          2.666667                         3.666667   \n",
              "44                          4.333333                         4.666667   \n",
              "45                          4.333333                         3.333333   \n",
              "46                          4.666667                         4.333333   \n",
              "47                          2.333333                         4.000000   \n",
              "48                          4.000000                         4.000000   \n",
              "49                          3.666667                         4.333333   \n",
              "50                          4.000000                         4.333333   \n",
              "51                          4.666667                         4.333333   \n",
              "52                          4.000000                         4.000000   \n",
              "53                          3.333333                         4.333333   \n",
              "54                          4.000000                         4.000000   \n",
              "55                          4.000000                         3.666667   \n",
              "56                          4.666667                         4.333333   \n",
              "57                          4.000000                         4.666667   \n",
              "58                          4.000000                         3.333333   \n",
              "59                          5.000000                         4.000000   \n",
              "60                          3.333333                         4.000000   \n",
              "61                          4.333333                         4.000000   \n",
              "62                          4.666667                         4.000000   \n",
              "63                          4.000000                         4.333333   \n",
              "64                          2.000000                         4.333333   \n",
              "65                          5.000000                         3.000000   \n",
              "66                          2.000000                         5.000000   \n",
              "67                          4.333333                         4.000000   \n",
              "68                          4.000000                         4.000000   \n",
              "69                          5.000000                         3.666667   \n",
              "70                          4.000000                         4.333333   \n",
              "71                          4.333333                         4.333333   \n",
              "72                          3.333333                         4.000000   \n",
              "73                          4.000000                         3.666667   \n",
              "74                          3.333333                         4.000000   \n",
              "75                          4.333333                         3.666667   \n",
              "76                          4.666667                         4.666667   \n",
              "77                          4.000000                         5.000000   \n",
              "78                          3.333333                         4.000000   \n",
              "79                          4.333333                         2.666667   \n",
              "80                          2.333333                         3.666667   \n",
              "81                          4.333333                         4.000000   \n",
              "82                          4.333333                         4.000000   \n",
              "83                          4.333333                         3.666667   \n",
              "84                          4.000000                         5.000000   \n",
              "85                          4.000000                         5.000000   \n",
              "86                          4.000000                         4.666667   \n",
              "87                          4.000000                         4.333333   \n",
              "88                          4.333333                         4.333333   \n",
              "89                          3.333333                         4.000000   \n",
              "90                          3.000000                         4.333333   \n",
              "91                          3.333333                         3.666667   \n",
              "92                          4.000000                         3.666667   \n",
              "93                          4.666667                         3.666667   \n",
              "94                          4.000000                         4.000000   \n",
              "95                          4.000000                         4.000000   \n",
              "96                          4.666667                         3.333333   \n",
              "97                          4.666667                         4.333333   \n",
              "98                          4.000000                         4.000000   \n",
              "99                          5.000000                         4.000000   \n",
              "100                         2.333333                         4.000000   \n",
              "101                         4.333333                         3.333333   \n",
              "102                         5.000000                         4.000000   \n",
              "103                         4.333333                         4.000000   \n",
              "104                         4.666667                         4.666667   \n",
              "105                         4.333333                         3.666667   \n",
              "106                         4.333333                         4.666667   \n",
              "107                         3.333333                         4.333333   \n",
              "108                         3.333333                         4.333333   \n",
              "109                         4.000000                         4.333333   \n",
              "110                         3.333333                         3.666667   \n",
              "111                         4.000000                         3.666667   \n",
              "112                         4.333333                         4.000000   \n",
              "113                         5.000000                         3.666667   \n",
              "114                         4.000000                         3.666667   \n",
              "115                         4.333333                         4.000000   \n",
              "116                         3.666667                         3.666667   \n",
              "117                         4.000000                         3.666667   \n",
              "118                         3.666667                         4.000000   \n",
              "119                         4.333333                         4.000000   \n",
              "120                         4.000000                         4.000000   \n",
              "121                         4.000000                         4.000000   \n",
              "122                         3.666667                         4.333333   \n",
              "123                         4.000000                         5.000000   \n",
              "124                         4.666667                         4.000000   \n",
              "125                         4.333333                         5.000000   \n",
              "126                         3.333333                         4.000000   \n",
              "127                         4.333333                         4.666667   \n",
              "128                         4.000000                         5.000000   \n",
              "129                         4.000000                         4.333333   \n",
              "130                         3.333333                         4.666667   \n",
              "131                         5.000000                         5.000000   \n",
              "132                         4.000000                         3.666667   \n",
              "133                         3.666667                         4.000000   \n",
              "134                         3.333333                         4.666667   \n",
              "135                         3.333333                         4.666667   \n",
              "136                         1.333333                         1.333333   \n",
              "137                         1.666667                         4.666667   \n",
              "138                         3.333333                         5.000000   \n",
              "139                         3.666667                         4.333333   \n",
              "140                         3.666667                         4.000000   \n",
              "141                         4.333333                         4.333333   \n",
              "142                         5.000000                         4.333333   \n",
              "143                         3.666667                         3.333333   \n",
              "144                         4.000000                         4.333333   \n",
              "145                         4.000000                         3.666667   \n",
              "146                         4.333333                         3.666667   \n",
              "147                         3.333333                         4.000000   \n",
              "148                         3.666667                         4.000000   \n",
              "149                         3.333333                         3.666667   \n",
              "150                         5.000000                         4.333333   \n",
              "151                         4.000000                         3.333333   \n",
              "152                         3.666667                         3.666667   \n",
              "153                         3.333333                         3.333333   \n",
              "154                         4.333333                         2.333333   \n",
              "155                         4.000000                         4.000000   \n",
              "156                         3.333333                         4.000000   \n",
              "157                         5.000000                         4.666667   \n",
              "158                         2.666667                         5.000000   \n",
              "159                         5.000000                         4.000000   \n",
              "160                         4.333333                         3.333333   \n",
              "161                         3.666667                         3.666667   \n",
              "162                         4.666667                         4.333333   \n",
              "163                         3.666667                         5.000000   \n",
              "164                         3.333333                         4.333333   \n",
              "165                         4.000000                         3.666667   \n",
              "166                         5.000000                         4.000000   \n",
              "167                         3.333333                         5.000000   \n",
              "168                         4.333333                         4.333333   \n",
              "169                         3.666667                         5.000000   \n",
              "170                         4.000000                         5.000000   \n",
              "171                         5.000000                         4.000000   \n",
              "172                         4.666667                         3.666667   \n",
              "173                         3.666667                         4.333333   \n",
              "174                         4.333333                         3.000000   \n",
              "175                         4.000000                         4.000000   \n",
              "176                         4.000000                         4.000000   \n",
              "177                         5.000000                         4.000000   \n",
              "178                         2.000000                         4.000000   \n",
              "179                         3.666667                         4.000000   \n",
              "180                         3.333333                         3.666667   \n",
              "181                         1.000000                         4.000000   \n",
              "182                         3.333333                         4.000000   \n",
              "183                         2.000000                         4.000000   \n",
              "184                         5.000000                         4.000000   \n",
              "185                         5.000000                         4.000000   \n",
              "186                         4.666667                         3.666667   \n",
              "187                         3.333333                         5.000000   \n",
              "188                         3.000000                         4.000000   \n",
              "189                         3.666667                         5.000000   \n",
              "190                         2.666667                         4.000000   \n",
              "191                         4.000000                         5.000000   \n",
              "192                         4.000000                         4.000000   \n",
              "193                         3.666667                         3.000000   \n",
              "194                         3.333333                         4.000000   \n",
              "195                         3.333333                         4.666667   \n",
              "196                         4.000000                         4.000000   \n",
              "197                         2.666667                         4.000000   \n",
              "198                         5.000000                         5.000000   \n",
              "199                         4.000000                         4.000000   \n",
              "200                         4.333333                         4.000000   \n",
              "201                         4.333333                         4.000000   \n",
              "202                         3.333333                         4.666667   \n",
              "203                         4.000000                         2.000000   \n",
              "204                         3.000000                         4.666667   \n",
              "205                         5.000000                         4.333333   \n",
              "206                         5.000000                         5.000000   \n",
              "207                         4.666667                         5.000000   \n",
              "208                         4.333333                         3.333333   \n",
              "209                         5.000000                         5.000000   \n",
              "210                         3.333333                         4.000000   \n",
              "211                         4.000000                         4.333333   \n",
              "212                         5.000000                         3.000000   \n",
              "213                         4.000000                         1.000000   \n",
              "214                         4.666667                         4.000000   \n",
              "215                         3.333333                         4.333333   \n",
              "216                         5.000000                         4.000000   \n",
              "217                         3.000000                         4.333333   \n",
              "218                         2.333333                         5.000000   \n",
              "219                         3.333333                         3.000000   \n",
              "220                         3.333333                         4.000000   \n",
              "221                         2.000000                         4.333333   \n",
              "222                         3.666667                         5.000000   \n",
              "223                         5.000000                         4.333333   \n",
              "224                         4.000000                         4.000000   \n",
              "225                         3.666667                         4.000000   \n",
              "226                         4.000000                         4.000000   \n",
              "227                         4.666667                         5.000000   \n",
              "228                         5.000000                         4.333333   \n",
              "229                         4.666667                         2.666667   \n",
              "230                         2.333333                         3.000000   \n",
              "231                         2.666667                         3.666667   \n",
              "232                         4.333333                         3.666667   \n",
              "233                         3.333333                         3.666667   \n",
              "234                         4.333333                         5.000000   \n",
              "235                         4.000000                         4.333333   \n",
              "236                         3.666667                         4.666667   \n",
              "237                         4.333333                         5.000000   \n",
              "238                         4.333333                         5.000000   \n",
              "239                         3.666667                         4.000000   \n",
              "\n",
              "     conciencia_de_la_persuasion   actitud  \\\n",
              "0                            3.6  3.333333   \n",
              "1                            4.2  3.000000   \n",
              "2                            1.8  4.333333   \n",
              "3                            5.0  3.333333   \n",
              "4                            2.8  4.333333   \n",
              "5                            4.8  5.000000   \n",
              "6                            3.8  3.666667   \n",
              "7                            4.0  5.000000   \n",
              "8                            4.2  4.000000   \n",
              "9                            4.0  3.666667   \n",
              "10                           3.8  4.000000   \n",
              "11                           4.8  3.666667   \n",
              "12                           4.0  4.333333   \n",
              "13                           4.0  3.000000   \n",
              "14                           4.4  4.666667   \n",
              "15                           4.2  5.000000   \n",
              "16                           4.6  3.666667   \n",
              "17                           4.2  4.333333   \n",
              "18                           4.6  4.666667   \n",
              "19                           4.0  4.333333   \n",
              "20                           4.0  3.000000   \n",
              "21                           5.0  4.666667   \n",
              "22                           4.2  4.666667   \n",
              "23                           4.2  4.333333   \n",
              "24                           4.0  4.333333   \n",
              "25                           4.8  4.333333   \n",
              "26                           2.8  3.333333   \n",
              "27                           3.6  3.000000   \n",
              "28                           4.4  4.000000   \n",
              "29                           4.0  4.000000   \n",
              "30                           5.0  4.000000   \n",
              "31                           4.4  3.666667   \n",
              "32                           4.4  4.333333   \n",
              "33                           3.0  3.666667   \n",
              "34                           4.0  3.666667   \n",
              "35                           3.4  4.000000   \n",
              "36                           4.0  4.666667   \n",
              "37                           3.2  4.333333   \n",
              "38                           3.2  4.333333   \n",
              "39                           4.6  3.000000   \n",
              "40                           3.6  4.000000   \n",
              "41                           4.8  4.333333   \n",
              "42                           2.6  3.666667   \n",
              "43                           3.6  3.333333   \n",
              "44                           3.8  4.333333   \n",
              "45                           4.4  4.333333   \n",
              "46                           3.8  3.666667   \n",
              "47                           4.2  4.333333   \n",
              "48                           3.6  4.666667   \n",
              "49                           4.0  4.000000   \n",
              "50                           4.0  3.000000   \n",
              "51                           3.8  3.666667   \n",
              "52                           1.6  2.000000   \n",
              "53                           4.2  4.666667   \n",
              "54                           3.0  4.333333   \n",
              "55                           4.0  3.666667   \n",
              "56                           4.8  4.000000   \n",
              "57                           4.2  3.333333   \n",
              "58                           3.6  4.333333   \n",
              "59                           4.2  4.666667   \n",
              "60                           3.4  5.000000   \n",
              "61                           3.4  2.000000   \n",
              "62                           4.4  4.333333   \n",
              "63                           2.8  5.000000   \n",
              "64                           4.0  2.666667   \n",
              "65                           4.8  4.666667   \n",
              "66                           4.0  4.000000   \n",
              "67                           4.0  4.666667   \n",
              "68                           4.4  3.333333   \n",
              "69                           2.8  3.333333   \n",
              "70                           3.6  3.333333   \n",
              "71                           4.2  3.333333   \n",
              "72                           4.0  4.333333   \n",
              "73                           4.2  4.333333   \n",
              "74                           3.2  5.000000   \n",
              "75                           3.8  3.333333   \n",
              "76                           3.6  4.000000   \n",
              "77                           4.8  4.000000   \n",
              "78                           4.0  3.000000   \n",
              "79                           4.0  3.666667   \n",
              "80                           4.2  3.000000   \n",
              "81                           3.6  4.666667   \n",
              "82                           3.8  4.000000   \n",
              "83                           4.0  4.333333   \n",
              "84                           4.2  4.333333   \n",
              "85                           3.8  5.000000   \n",
              "86                           4.4  4.000000   \n",
              "87                           4.6  5.000000   \n",
              "88                           3.4  4.000000   \n",
              "89                           3.4  3.333333   \n",
              "90                           2.6  5.000000   \n",
              "91                           3.8  4.000000   \n",
              "92                           4.0  4.000000   \n",
              "93                           3.4  3.666667   \n",
              "94                           3.2  3.333333   \n",
              "95                           4.8  4.333333   \n",
              "96                           3.6  2.333333   \n",
              "97                           3.8  3.333333   \n",
              "98                           4.8  2.666667   \n",
              "99                           4.2  4.666667   \n",
              "100                          4.6  4.000000   \n",
              "101                          3.6  4.666667   \n",
              "102                          3.8  4.666667   \n",
              "103                          4.6  3.666667   \n",
              "104                          4.4  4.000000   \n",
              "105                          4.6  4.000000   \n",
              "106                          4.4  2.333333   \n",
              "107                          4.4  4.000000   \n",
              "108                          4.2  3.000000   \n",
              "109                          4.0  4.000000   \n",
              "110                          4.4  4.333333   \n",
              "111                          3.6  3.666667   \n",
              "112                          4.6  4.666667   \n",
              "113                          5.0  3.666667   \n",
              "114                          5.0  3.333333   \n",
              "115                          4.6  3.333333   \n",
              "116                          4.6  4.333333   \n",
              "117                          3.0  4.666667   \n",
              "118                          4.0  4.000000   \n",
              "119                          3.6  3.333333   \n",
              "120                          3.8  2.000000   \n",
              "121                          3.8  4.666667   \n",
              "122                          3.8  3.333333   \n",
              "123                          2.8  4.333333   \n",
              "124                          4.0  2.666667   \n",
              "125                          2.0  3.333333   \n",
              "126                          3.6  3.666667   \n",
              "127                          3.2  4.000000   \n",
              "128                          4.0  3.333333   \n",
              "129                          3.6  4.333333   \n",
              "130                          2.2  4.666667   \n",
              "131                          4.0  4.000000   \n",
              "132                          4.2  4.666667   \n",
              "133                          4.4  4.333333   \n",
              "134                          3.8  5.000000   \n",
              "135                          3.0  1.666667   \n",
              "136                          3.8  4.000000   \n",
              "137                          2.2  4.666667   \n",
              "138                          3.8  3.666667   \n",
              "139                          4.4  4.333333   \n",
              "140                          3.8  5.000000   \n",
              "141                          4.6  4.666667   \n",
              "142                          3.8  4.333333   \n",
              "143                          3.8  4.333333   \n",
              "144                          4.4  4.333333   \n",
              "145                          4.0  4.333333   \n",
              "146                          3.6  4.000000   \n",
              "147                          3.2  2.666667   \n",
              "148                          4.4  5.000000   \n",
              "149                          4.2  4.000000   \n",
              "150                          5.0  4.666667   \n",
              "151                          3.8  3.333333   \n",
              "152                          2.8  3.666667   \n",
              "153                          3.6  3.333333   \n",
              "154                          1.8  3.333333   \n",
              "155                          4.8  3.333333   \n",
              "156                          3.6  3.333333   \n",
              "157                          3.8  3.333333   \n",
              "158                          4.0  5.000000   \n",
              "159                          3.8  3.333333   \n",
              "160                          4.6  3.666667   \n",
              "161                          4.0  3.666667   \n",
              "162                          3.8  5.000000   \n",
              "163                          4.6  4.333333   \n",
              "164                          4.0  4.000000   \n",
              "165                          3.2  3.666667   \n",
              "166                          4.8  5.000000   \n",
              "167                          4.4  4.666667   \n",
              "168                          5.0  4.666667   \n",
              "169                          4.0  3.333333   \n",
              "170                          2.8  3.333333   \n",
              "171                          3.8  5.000000   \n",
              "172                          5.0  1.000000   \n",
              "173                          2.8  3.666667   \n",
              "174                          4.2  4.000000   \n",
              "175                          3.8  5.000000   \n",
              "176                          4.8  5.000000   \n",
              "177                          4.4  4.666667   \n",
              "178                          3.6  3.333333   \n",
              "179                          3.0  4.000000   \n",
              "180                          3.8  4.666667   \n",
              "181                          4.0  4.000000   \n",
              "182                          4.4  5.000000   \n",
              "183                          3.6  5.000000   \n",
              "184                          4.6  4.666667   \n",
              "185                          4.0  3.333333   \n",
              "186                          3.8  4.666667   \n",
              "187                          4.6  4.333333   \n",
              "188                          4.0  4.333333   \n",
              "189                          3.6  4.000000   \n",
              "190                          4.4  4.000000   \n",
              "191                          3.6  3.000000   \n",
              "192                          3.0  4.333333   \n",
              "193                          4.4  5.000000   \n",
              "194                          3.4  4.333333   \n",
              "195                          4.6  4.333333   \n",
              "196                          5.0  3.666667   \n",
              "197                          4.2  3.666667   \n",
              "198                          4.2  3.000000   \n",
              "199                          2.2  5.000000   \n",
              "200                          2.2  4.666667   \n",
              "201                          4.0  3.666667   \n",
              "202                          4.0  3.666667   \n",
              "203                          4.2  4.666667   \n",
              "204                          3.8  5.000000   \n",
              "205                          4.0  4.666667   \n",
              "206                          3.8  5.000000   \n",
              "207                          4.6  5.000000   \n",
              "208                          3.8  4.000000   \n",
              "209                          3.8  5.000000   \n",
              "210                          5.0  4.666667   \n",
              "211                          3.0  3.666667   \n",
              "212                          3.8  4.000000   \n",
              "213                          4.4  3.333333   \n",
              "214                          4.0  4.333333   \n",
              "215                          3.8  4.666667   \n",
              "216                          4.2  4.333333   \n",
              "217                          4.0  4.333333   \n",
              "218                          2.2  4.666667   \n",
              "219                          2.8  4.333333   \n",
              "220                          4.6  4.333333   \n",
              "221                          3.2  4.333333   \n",
              "222                          3.4  4.666667   \n",
              "223                          2.2  5.000000   \n",
              "224                          4.8  4.000000   \n",
              "225                          4.4  4.666667   \n",
              "226                          3.4  4.333333   \n",
              "227                          3.4  3.000000   \n",
              "228                          3.8  3.666667   \n",
              "229                          5.0  4.000000   \n",
              "230                          3.0  4.000000   \n",
              "231                          4.2  4.000000   \n",
              "232                          5.0  4.000000   \n",
              "233                          4.0  1.333333   \n",
              "234                          4.0  3.000000   \n",
              "235                          4.8  5.000000   \n",
              "236                          4.0  4.333333   \n",
              "237                          3.6  4.000000   \n",
              "238                          3.4  4.666667   \n",
              "239                          4.0  4.333333   \n",
              "\n",
              "     predisposicion_a_comprar_un_producto  engagement  \n",
              "0                                4.000000         2.2  \n",
              "1                                3.666667         4.2  \n",
              "2                                4.000000         3.8  \n",
              "3                                4.000000         3.8  \n",
              "4                                4.333333         4.0  \n",
              "5                                4.666667         4.0  \n",
              "6                                4.333333         4.6  \n",
              "7                                4.000000         3.6  \n",
              "8                                4.000000         4.0  \n",
              "9                                5.000000         4.4  \n",
              "10                               5.000000         4.0  \n",
              "11                               4.333333         3.8  \n",
              "12                               4.000000         3.8  \n",
              "13                               3.333333         4.0  \n",
              "14                               5.000000         4.4  \n",
              "15                               4.000000         4.0  \n",
              "16                               3.666667         5.0  \n",
              "17                               4.000000         3.8  \n",
              "18                               3.333333         3.2  \n",
              "19                               3.333333         4.2  \n",
              "20                               3.333333         4.2  \n",
              "21                               4.333333         3.8  \n",
              "22                               4.666667         4.4  \n",
              "23                               2.666667         4.2  \n",
              "24                               3.333333         4.2  \n",
              "25                               4.000000         4.4  \n",
              "26                               3.666667         3.8  \n",
              "27                               4.000000         2.8  \n",
              "28                               5.000000         4.2  \n",
              "29                               3.666667         5.0  \n",
              "30                               5.000000         3.8  \n",
              "31                               4.333333         3.4  \n",
              "32                               3.666667         3.6  \n",
              "33                               2.666667         4.4  \n",
              "34                               5.000000         3.6  \n",
              "35                               4.000000         3.6  \n",
              "36                               4.000000         4.2  \n",
              "37                               5.000000         3.8  \n",
              "38                               3.333333         4.0  \n",
              "39                               4.000000         3.6  \n",
              "40                               4.000000         4.8  \n",
              "41                               3.000000         4.8  \n",
              "42                               4.333333         3.8  \n",
              "43                               3.666667         4.2  \n",
              "44                               2.666667         3.8  \n",
              "45                               3.000000         4.0  \n",
              "46                               3.000000         4.6  \n",
              "47                               5.000000         4.4  \n",
              "48                               4.000000         4.0  \n",
              "49                               4.333333         4.6  \n",
              "50                               3.000000         3.6  \n",
              "51                               4.000000         4.4  \n",
              "52                               3.666667         4.0  \n",
              "53                               4.000000         3.8  \n",
              "54                               3.000000         3.2  \n",
              "55                               3.666667         3.8  \n",
              "56                               2.666667         4.6  \n",
              "57                               3.666667         4.4  \n",
              "58                               3.666667         4.4  \n",
              "59                               3.333333         4.2  \n",
              "60                               3.333333         3.0  \n",
              "61                               2.000000         4.4  \n",
              "62                               3.666667         4.2  \n",
              "63                               2.666667         4.2  \n",
              "64                               5.000000         3.8  \n",
              "65                               4.333333         3.8  \n",
              "66                               5.000000         3.6  \n",
              "67                               5.000000         4.0  \n",
              "68                               3.666667         3.4  \n",
              "69                               3.000000         3.2  \n",
              "70                               3.333333         2.8  \n",
              "71                               5.000000         4.8  \n",
              "72                               4.333333         5.0  \n",
              "73                               4.000000         3.4  \n",
              "74                               4.000000         4.6  \n",
              "75                               4.333333         4.6  \n",
              "76                               3.666667         3.6  \n",
              "77                               5.000000         4.8  \n",
              "78                               3.000000         4.2  \n",
              "79                               3.000000         3.6  \n",
              "80                               3.666667         3.8  \n",
              "81                               5.000000         4.2  \n",
              "82                               4.666667         4.2  \n",
              "83                               3.000000         4.2  \n",
              "84                               5.000000         3.6  \n",
              "85                               3.333333         4.6  \n",
              "86                               2.666667         4.0  \n",
              "87                               4.333333         4.2  \n",
              "88                               3.666667         3.0  \n",
              "89                               4.000000         3.4  \n",
              "90                               4.000000         4.8  \n",
              "91                               4.000000         4.2  \n",
              "92                               4.000000         4.2  \n",
              "93                               3.000000         3.2  \n",
              "94                               5.000000         2.8  \n",
              "95                               4.000000         4.4  \n",
              "96                               4.000000         4.2  \n",
              "97                               3.666667         4.8  \n",
              "98                               5.000000         4.8  \n",
              "99                               3.000000         3.6  \n",
              "100                              5.000000         4.2  \n",
              "101                              5.000000         3.6  \n",
              "102                              4.666667         3.8  \n",
              "103                              4.666667         4.2  \n",
              "104                              4.000000         3.4  \n",
              "105                              5.000000         4.2  \n",
              "106                              3.666667         4.0  \n",
              "107                              4.333333         4.6  \n",
              "108                              4.666667         4.4  \n",
              "109                              3.333333         4.4  \n",
              "110                              3.333333         3.6  \n",
              "111                              4.333333         4.8  \n",
              "112                              4.333333         4.6  \n",
              "113                              4.333333         3.8  \n",
              "114                              3.666667         4.2  \n",
              "115                              4.666667         4.6  \n",
              "116                              3.666667         3.6  \n",
              "117                              4.000000         4.0  \n",
              "118                              4.000000         1.4  \n",
              "119                              2.000000         4.4  \n",
              "120                              3.333333         4.8  \n",
              "121                              4.000000         4.8  \n",
              "122                              4.000000         3.2  \n",
              "123                              3.666667         4.0  \n",
              "124                              3.333333         4.0  \n",
              "125                              4.000000         4.0  \n",
              "126                              3.666667         3.6  \n",
              "127                              4.000000         2.2  \n",
              "128                              3.666667         4.0  \n",
              "129                              4.000000         4.4  \n",
              "130                              2.666667         3.4  \n",
              "131                              4.000000         4.0  \n",
              "132                              4.333333         4.2  \n",
              "133                              4.000000         3.2  \n",
              "134                              4.000000         4.6  \n",
              "135                              3.666667         3.6  \n",
              "136                              4.000000         4.0  \n",
              "137                              3.333333         4.0  \n",
              "138                              5.000000         4.4  \n",
              "139                              5.000000         4.4  \n",
              "140                              4.000000         4.4  \n",
              "141                              5.000000         4.0  \n",
              "142                              4.000000         3.2  \n",
              "143                              4.666667         4.0  \n",
              "144                              3.666667         4.4  \n",
              "145                              3.000000         4.2  \n",
              "146                              4.333333         4.4  \n",
              "147                              4.333333         3.8  \n",
              "148                              4.333333         4.0  \n",
              "149                              3.666667         4.0  \n",
              "150                              5.000000         3.2  \n",
              "151                              5.000000         4.0  \n",
              "152                              3.666667         2.6  \n",
              "153                              3.333333         3.2  \n",
              "154                              4.000000         2.4  \n",
              "155                              5.000000         3.8  \n",
              "156                              5.000000         4.4  \n",
              "157                              4.000000         3.8  \n",
              "158                              4.000000         4.2  \n",
              "159                              4.000000         4.4  \n",
              "160                              4.333333         4.0  \n",
              "161                              5.000000         4.0  \n",
              "162                              4.000000         3.8  \n",
              "163                              3.666667         3.0  \n",
              "164                              5.000000         3.4  \n",
              "165                              4.000000         3.8  \n",
              "166                              3.333333         3.6  \n",
              "167                              4.333333         3.4  \n",
              "168                              4.000000         3.6  \n",
              "169                              4.666667         4.4  \n",
              "170                              4.333333         4.2  \n",
              "171                              4.000000         4.2  \n",
              "172                              5.000000         4.2  \n",
              "173                              3.333333         3.2  \n",
              "174                              3.000000         4.8  \n",
              "175                              3.666667         4.0  \n",
              "176                              5.000000         3.2  \n",
              "177                              5.000000         4.2  \n",
              "178                              3.666667         3.0  \n",
              "179                              5.000000         4.6  \n",
              "180                              4.000000         3.6  \n",
              "181                              4.000000         4.6  \n",
              "182                              4.333333         4.4  \n",
              "183                              4.000000         4.0  \n",
              "184                              4.333333         5.0  \n",
              "185                              4.000000         3.2  \n",
              "186                              3.000000         4.2  \n",
              "187                              5.000000         4.0  \n",
              "188                              3.333333         3.8  \n",
              "189                              4.333333         4.4  \n",
              "190                              5.000000         3.4  \n",
              "191                              4.333333         3.2  \n",
              "192                              5.000000         4.4  \n",
              "193                              4.000000         4.4  \n",
              "194                              1.333333         4.6  \n",
              "195                              4.000000         4.8  \n",
              "196                              4.000000         4.4  \n",
              "197                              3.666667         4.4  \n",
              "198                              3.666667         4.4  \n",
              "199                              4.000000         4.4  \n",
              "200                              3.333333         4.4  \n",
              "201                              3.333333         5.0  \n",
              "202                              3.000000         4.0  \n",
              "203                              4.666667         4.0  \n",
              "204                              3.000000         4.6  \n",
              "205                              4.000000         3.6  \n",
              "206                              4.666667         4.2  \n",
              "207                              3.000000         4.4  \n",
              "208                              4.000000         4.0  \n",
              "209                              4.000000         4.2  \n",
              "210                              3.333333         3.6  \n",
              "211                              4.000000         4.4  \n",
              "212                              3.666667         3.4  \n",
              "213                              4.000000         2.8  \n",
              "214                              4.666667         4.8  \n",
              "215                              4.333333         4.2  \n",
              "216                              5.000000         1.8  \n",
              "217                              4.000000         4.6  \n",
              "218                              3.666667         4.2  \n",
              "219                              3.000000         1.6  \n",
              "220                              4.666667         5.0  \n",
              "221                              4.666667         4.2  \n",
              "222                              4.000000         4.8  \n",
              "223                              4.666667         3.6  \n",
              "224                              5.000000         3.4  \n",
              "225                              4.666667         4.2  \n",
              "226                              3.333333         4.8  \n",
              "227                              4.000000         4.4  \n",
              "228                              5.000000         3.4  \n",
              "229                              4.333333         2.0  \n",
              "230                              3.333333         3.6  \n",
              "231                              3.333333         2.8  \n",
              "232                              4.000000         2.8  \n",
              "233                              4.000000         4.6  \n",
              "234                              4.000000         3.8  \n",
              "235                              4.333333         3.8  \n",
              "236                              4.333333         5.0  \n",
              "237                              3.000000         5.0  \n",
              "238                              3.666667         4.0  \n",
              "239                              4.000000         4.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ba5f458-c4f3-48f0-b21a-22e10b54c0a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>integridad</th>\n",
              "      <th>expertis</th>\n",
              "      <th>autenticidad</th>\n",
              "      <th>atractividad</th>\n",
              "      <th>similitud</th>\n",
              "      <th>lider_de_opinion</th>\n",
              "      <th>informatividad_del_contenido</th>\n",
              "      <th>congruencia_influencer_follower</th>\n",
              "      <th>congruencia_influencer_producto</th>\n",
              "      <th>conciencia_de_la_persuasion</th>\n",
              "      <th>actitud</th>\n",
              "      <th>predisposicion_a_comprar_un_producto</th>\n",
              "      <th>engagement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>1.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.50</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4.50</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.25</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>4.25</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3.75</td>\n",
              "      <td>2.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.00</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>4.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>2.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.75</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>3.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>3.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>4.50</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>4.50</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>4.50</td>\n",
              "      <td>2.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.6</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>3.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>4.50</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>3.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>3.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>2.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>4.50</td>\n",
              "      <td>2.75</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>4.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>3.75</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>2.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>2.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>3.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>4.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>4.00</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>3.75</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>4.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>2.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>4.50</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>5.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>3.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>2.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>4.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>1.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>3.75</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>2.75</td>\n",
              "      <td>3.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>3.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>2.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>3.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>3.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.25</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.2</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>2.50</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>3.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.75</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>4.50</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>4.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>3.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>4.25</td>\n",
              "      <td>2.50</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>3.25</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.2</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>3.00</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>3.50</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>4.50</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>5.00</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>3.00</td>\n",
              "      <td>2.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>5.00</td>\n",
              "      <td>2.75</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>4.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>4.25</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ba5f458-c4f3-48f0-b21a-22e10b54c0a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ba5f458-c4f3-48f0-b21a-22e10b54c0a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ba5f458-c4f3-48f0-b21a-22e10b54c0a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e1b5c78f-3dea-4ad5-a5c1-1380e0c7350a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_constructos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e1b5c78f-3dea-4ad5-a5c1-1380e0c7350a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_constructos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_constructos",
              "summary": "{\n  \"name\": \"df_constructos\",\n  \"rows\": 240,\n  \"fields\": [\n    {\n      \"column\": \"integridad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6557465110470264,\n        \"min\": 1.75,\n        \"max\": 5.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          3.25,\n          1.75,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expertis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.615990679381658,\n        \"min\": 2.25,\n        \"max\": 5.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.5,\n          4.5,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"autenticidad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.661620839636178,\n        \"min\": 2.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.0,\n          4.666666666666667,\n          3.3333333333333335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atractividad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6532244393843939,\n        \"min\": 1.25,\n        \"max\": 5.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          1.75,\n          2.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similitud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.772150811611105,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.0,\n          1.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lider_de_opinion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6298443707067785,\n        \"min\": 1.5,\n        \"max\": 5.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          3.25,\n          2.5,\n          1.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"informatividad_del_contenido\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6252599025698524,\n        \"min\": 2.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2.6666666666666665,\n          3.3333333333333335,\n          4.666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"congruencia_influencer_follower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7902189532726144,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          2.0,\n          2.6666666666666665,\n          4.333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"congruencia_influencer_producto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6250848385004274,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.0,\n          2.3333333333333335,\n          3.6666666666666665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conciencia_de_la_persuasion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6719400916378996,\n        \"min\": 1.6,\n        \"max\": 5.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          3.6,\n          4.2,\n          4.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actitud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7259977130638458,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1.0,\n          2.3333333333333335,\n          3.3333333333333335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predisposicion_a_comprar_un_producto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6810114081601867,\n        \"min\": 1.3333333333333333,\n        \"max\": 5.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.0,\n          3.6666666666666665,\n          3.3333333333333335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"engagement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6237422490944792,\n        \"min\": 1.4,\n        \"max\": 5.0,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          2.2,\n          3.6,\n          4.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos guardados: promedios_constructos.xlsx y promedios_constructos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descripción de la muestra\n",
        "Generación de tabla y excel con ITEM, categoria, frecuencia y porcentaje."
      ],
      "metadata": {
        "id": "4n9xBbfXox7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Cargar la base de datos (si no la has cargado en una celda anterior)\n",
        "# nombre_archivo = 'datos_codificados_ajustados (1).xlsx'\n",
        "# df = pd.read_excel(nombre_archivo) # O pd.read_csv(...)\n",
        "\n",
        "# 2. DEFINICIÓN DE VARIABLES DEMOGRÁFICAS\n",
        "vars_demograficas = ['edad', 'genero', 'escolaridad', 'ingreso', 'residencia']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TABLAS DE PERFIL DEMOGRÁFICO (TOTAL MUESTRA)\")\n",
        "print(f\"Total de encuestados: {len(df)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 3. GENERACIÓN AUTOMÁTICA DE TABLAS\n",
        "for var in vars_demograficas:\n",
        "    if var in df.columns:\n",
        "        # Calcular frecuencia absoluta (conteo)\n",
        "        # dropna=False es la clave para contar \"absolutamente todos\" (incluso vacíos)\n",
        "        frecuencia = df[var].value_counts(dropna=False)\n",
        "\n",
        "        # Calcular porcentaje\n",
        "        porcentaje = df[var].value_counts(dropna=False, normalize=True) * 100\n",
        "\n",
        "        # Crear la tabla combinada\n",
        "        tabla = pd.DataFrame({\n",
        "            'Cantidad': frecuencia,\n",
        "            'Porcentaje (%)': porcentaje\n",
        "        })\n",
        "\n",
        "        # Mostrar la tabla formateada\n",
        "        print(f\"\\n>>> Variable: {var.upper()}\")\n",
        "        # round(2) para que se vea limpio con dos decimales\n",
        "        print(tabla.round(2))\n",
        "        print(\"-\" * 60)\n",
        "    else:\n",
        "        print(f\"\\n[!] La columna '{var}' no existe en el archivo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSNUWxZXpgdE",
        "outputId": "056c7e13-ab37-49b4-8e18-adeca77a8c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TABLAS DE PERFIL DEMOGRÁFICO (TOTAL MUESTRA)\n",
            "Total de encuestados: 240\n",
            "============================================================\n",
            "\n",
            ">>> Variable: EDAD\n",
            "                  Cantidad  Porcentaje (%)\n",
            "edad                                      \n",
            "De 18 a 24 años        106           44.17\n",
            "De 25 a 34 años         87           36.25\n",
            "De 35 a 44 años         42           17.50\n",
            "De 45 a 54 años          3            1.25\n",
            "De 55 a 64 años          1            0.42\n",
            "De 65 años y más         1            0.42\n",
            "------------------------------------------------------------\n",
            "\n",
            ">>> Variable: GENERO\n",
            "            Cantidad  Porcentaje (%)\n",
            "genero                              \n",
            "Femenino         161           67.08\n",
            "Masculino         78           32.50\n",
            "No binario         1            0.42\n",
            "------------------------------------------------------------\n",
            "\n",
            ">>> Variable: ESCOLARIDAD\n",
            "                             Cantidad  Porcentaje (%)\n",
            "escolaridad                                          \n",
            "Preparatoria o bachillerato       141           58.75\n",
            "Secundaria                         63           26.25\n",
            "Licenciatura o ingeniería          16            6.67\n",
            "Primaria                           10            4.17\n",
            "Posgrado                            9            3.75\n",
            "Ninguna escolaridad                 1            0.42\n",
            "------------------------------------------------------------\n",
            "\n",
            ">>> Variable: INGRESO\n",
            "                         Cantidad  Porcentaje (%)\n",
            "ingreso                                          \n",
            "De 5,000 a 10,000 MXN         180           75.00\n",
            "< De 5,000 MXN                 36           15.00\n",
            "De 10,000 a 20,000 MXN         11            4.58\n",
            "De 20,000 a 35,000 MXN          8            3.33\n",
            "De 35,000 a 50,000 MXN          2            0.83\n",
            "De 50,000 a 100,000 MXN         2            0.83\n",
            "NaN                             1            0.42\n",
            "------------------------------------------------------------\n",
            "\n",
            ">>> Variable: RESIDENCIA\n",
            "                           Cantidad  Porcentaje (%)\n",
            "residencia                                         \n",
            "Otra entidad de México          218           90.83\n",
            "Sonora                           13            5.42\n",
            "Un país distinto a México         9            3.75\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dZ82D2-aw7xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# 1. Cargar datos (si es necesario)\n",
        "# df = pd.read_csv('datos_codificados_ajustados (1).xlsx - Sheet1.csv')\n",
        "\n",
        "# 2. Variables a incluir\n",
        "vars_demograficas = ['genero', 'edad', 'escolaridad', 'ingreso', 'residencia']\n",
        "\n",
        "# 3. Construcción de la Tabla Consolidada\n",
        "datos_resumen = []\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TABLA 1: PERFIL DEMOGRÁFICO DE LA MUESTRA\")\n",
        "print(f\"Total de participantes: {len(df)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for var in vars_demograficas:\n",
        "    if var in df.columns:\n",
        "        # Calcular conteos y porcentajes (incluyendo nulos)\n",
        "        counts = df[var].value_counts(dropna=False)\n",
        "        percentages = df[var].value_counts(dropna=False, normalize=True) * 100\n",
        "\n",
        "        # Iterar sobre cada categoría de la variable\n",
        "        for categoria in counts.index:\n",
        "            # Manejo de etiquetas para valores vacíos\n",
        "            etiqueta = str(categoria) if pd.notna(categoria) else \"Sin Respuesta\"\n",
        "\n",
        "            # Agregar fila a la lista\n",
        "            datos_resumen.append({\n",
        "                'Variable': var.capitalize(), # Nombre de la variable (Ej. Edad)\n",
        "                'Categoría': etiqueta,        # Rango o grupo (Ej. 18-24)\n",
        "                'Frecuencia (n)': counts[categoria],\n",
        "                'Porcentaje (%)': f\"{percentages[categoria]:.2f}%\"\n",
        "            })\n",
        "\n",
        "# 4. Crear el DataFrame final\n",
        "tabla_final = pd.DataFrame(datos_resumen)\n",
        "\n",
        "# 5. Estilizar para visualización final\n",
        "# Usamos un MultiIndex para agrupar visualmente por Variable\n",
        "tabla_final = tabla_final.set_index(['Variable', 'Categoría'])\n",
        "\n",
        "# Mostrar la tabla limpia\n",
        "display(tabla_final)\n",
        "\n",
        "# Opcional: Guardar esta tabla en Excel para descargarla\n",
        "tabla_final.to_excel(\"Tabla_Demografica_Resumen.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "PZ-mg06CsLe3",
        "outputId": "50d111a3-05cb-4234-fe14-2d5f7d5aa6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TABLA 1: PERFIL DEMOGRÁFICO DE LA MUESTRA\n",
            "Total de participantes: 240\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                         Frecuencia (n) Porcentaje (%)\n",
              "Variable    Categoría                                                 \n",
              "Genero      Femenino                                161         67.08%\n",
              "            Masculino                                78         32.50%\n",
              "            No binario                                1          0.42%\n",
              "Edad        De 18 a 24 años                         106         44.17%\n",
              "            De 25 a 34 años                          87         36.25%\n",
              "            De 35 a 44 años                          42         17.50%\n",
              "            De 45 a 54 años                           3          1.25%\n",
              "            De 55 a 64 años                           1          0.42%\n",
              "            De 65 años y más                          1          0.42%\n",
              "Escolaridad Preparatoria o bachillerato             141         58.75%\n",
              "            Secundaria                               63         26.25%\n",
              "            Licenciatura o ingeniería                16          6.67%\n",
              "            Primaria                                 10          4.17%\n",
              "            Posgrado                                  9          3.75%\n",
              "            Ninguna escolaridad                       1          0.42%\n",
              "Ingreso     De 5,000 a 10,000 MXN                   180         75.00%\n",
              "            < De 5,000 MXN                           36         15.00%\n",
              "            De 10,000 a 20,000 MXN                   11          4.58%\n",
              "            De 20,000 a 35,000 MXN                    8          3.33%\n",
              "            De 35,000 a 50,000 MXN                    2          0.83%\n",
              "            De 50,000 a 100,000 MXN                   2          0.83%\n",
              "            Sin Respuesta                             1          0.42%\n",
              "Residencia  Otra entidad de México                  218         90.83%\n",
              "            Sonora                                   13          5.42%\n",
              "            Un país distinto a México                 9          3.75%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42cfebe1-2b98-4f93-b6bc-4d4845774887\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Frecuencia (n)</th>\n",
              "      <th>Porcentaje (%)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variable</th>\n",
              "      <th>Categoría</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Genero</th>\n",
              "      <th>Femenino</th>\n",
              "      <td>161</td>\n",
              "      <td>67.08%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Masculino</th>\n",
              "      <td>78</td>\n",
              "      <td>32.50%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No binario</th>\n",
              "      <td>1</td>\n",
              "      <td>0.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">Edad</th>\n",
              "      <th>De 18 a 24 años</th>\n",
              "      <td>106</td>\n",
              "      <td>44.17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 25 a 34 años</th>\n",
              "      <td>87</td>\n",
              "      <td>36.25%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 35 a 44 años</th>\n",
              "      <td>42</td>\n",
              "      <td>17.50%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 45 a 54 años</th>\n",
              "      <td>3</td>\n",
              "      <td>1.25%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 55 a 64 años</th>\n",
              "      <td>1</td>\n",
              "      <td>0.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 65 años y más</th>\n",
              "      <td>1</td>\n",
              "      <td>0.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">Escolaridad</th>\n",
              "      <th>Preparatoria o bachillerato</th>\n",
              "      <td>141</td>\n",
              "      <td>58.75%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Secundaria</th>\n",
              "      <td>63</td>\n",
              "      <td>26.25%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Licenciatura o ingeniería</th>\n",
              "      <td>16</td>\n",
              "      <td>6.67%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Primaria</th>\n",
              "      <td>10</td>\n",
              "      <td>4.17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Posgrado</th>\n",
              "      <td>9</td>\n",
              "      <td>3.75%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ninguna escolaridad</th>\n",
              "      <td>1</td>\n",
              "      <td>0.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"7\" valign=\"top\">Ingreso</th>\n",
              "      <th>De 5,000 a 10,000 MXN</th>\n",
              "      <td>180</td>\n",
              "      <td>75.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&lt; De 5,000 MXN</th>\n",
              "      <td>36</td>\n",
              "      <td>15.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 10,000 a 20,000 MXN</th>\n",
              "      <td>11</td>\n",
              "      <td>4.58%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 20,000 a 35,000 MXN</th>\n",
              "      <td>8</td>\n",
              "      <td>3.33%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 35,000 a 50,000 MXN</th>\n",
              "      <td>2</td>\n",
              "      <td>0.83%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>De 50,000 a 100,000 MXN</th>\n",
              "      <td>2</td>\n",
              "      <td>0.83%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sin Respuesta</th>\n",
              "      <td>1</td>\n",
              "      <td>0.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Residencia</th>\n",
              "      <th>Otra entidad de México</th>\n",
              "      <td>218</td>\n",
              "      <td>90.83%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sonora</th>\n",
              "      <td>13</td>\n",
              "      <td>5.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Un país distinto a México</th>\n",
              "      <td>9</td>\n",
              "      <td>3.75%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42cfebe1-2b98-4f93-b6bc-4d4845774887')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42cfebe1-2b98-4f93-b6bc-4d4845774887 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42cfebe1-2b98-4f93-b6bc-4d4845774887');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_6d69a0a3-fcf0-4ffe-9f0f-86db7ad80bd0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tabla_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d69a0a3-fcf0-4ffe-9f0f-86db7ad80bd0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tabla_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tabla_final",
              "summary": "{\n  \"name\": \"tabla_final\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Frecuencia (n)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 1,\n        \"max\": 218,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          161,\n          42,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Porcentaje (%)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"67.08%\",\n          \"17.50%\",\n          \"3.75%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading, CR y AVE α\n",
        "\n",
        "SOLO contrsuctos de primer ORDEN"
      ],
      "metadata": {
        "id": "6_hew93sx8aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from google.colab import files # Necesario para descargar archivos\n",
        "\n",
        "# 1. Cargar Datos (Asegúrate de que df ya está cargado con tu archivo)\n",
        "# df = pd.read_csv('tu_archivo.csv') # Descomenta si necesitas cargarlo de nuevo\n",
        "\n",
        "# 2. Definir Diccionario\n",
        "constructos = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# 3. Función para Alpha de Cronbach\n",
        "def calculate_cronbach_alpha(itemscores):\n",
        "    itemscores = np.asarray(itemscores)\n",
        "    itemvars = itemscores.var(axis=0, ddof=1)\n",
        "    tscores = itemscores.sum(axis=1)\n",
        "    nitems = itemscores.shape[1]\n",
        "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))\n",
        "\n",
        "# 4. Procesamiento\n",
        "output_rows = []\n",
        "\n",
        "for construct, items in constructos.items():\n",
        "    # Filtrar datos válidos para este constructo\n",
        "    if not all(col in df.columns for col in items):\n",
        "        continue\n",
        "    block = df[items].dropna()\n",
        "\n",
        "    # Cálculos\n",
        "    alpha = calculate_cronbach_alpha(block)\n",
        "\n",
        "    # PCA para simular PLS (1er componente)\n",
        "    pca = PCA(n_components=1)\n",
        "    latent_score = pca.fit_transform(block)\n",
        "\n",
        "    # Loadings (Correlación ítem - latente)\n",
        "    loadings = []\n",
        "    for col in block.columns:\n",
        "        loading = np.corrcoef(block[col], latent_score[:, 0])[0, 1]\n",
        "        loadings.append(abs(loading))\n",
        "    loadings = np.array(loadings)\n",
        "\n",
        "    # AVE\n",
        "    ave = np.mean(loadings**2)\n",
        "\n",
        "    # Composite Reliability (CR)\n",
        "    sum_loadings_sq = np.sum(loadings)**2\n",
        "    sum_error = np.sum(1 - loadings**2)\n",
        "    cr = sum_loadings_sq / (sum_loadings_sq + sum_error)\n",
        "\n",
        "    # Formatear filas para la tabla final\n",
        "    # Fila del Constructo (Con métricas globales)\n",
        "    output_rows.append({\n",
        "        'Constructs/items': f\"{construct.capitalize()}\",\n",
        "        'Loading': \"\",\n",
        "        'α': f\"{alpha:.3f}\",\n",
        "        'CR': f\"{cr:.3f}\",\n",
        "        'AVE': f\"{ave:.3f}\"\n",
        "    })\n",
        "\n",
        "    # Filas de los Ítems (Solo loadings)\n",
        "    for item_name, loading_val in zip(items, loadings):\n",
        "        output_rows.append({\n",
        "            'Constructs/items': item_name,\n",
        "            'Loading': f\"{loading_val:.3f}\",\n",
        "            'α': \"\",\n",
        "            'CR': \"\",\n",
        "            'AVE': \"\"\n",
        "        })\n",
        "\n",
        "# 5. Generar Tabla y Descargar\n",
        "results_df = pd.DataFrame(output_rows)\n",
        "\n",
        "print(\"Previsualización de la tabla:\")\n",
        "display(results_df)\n",
        "\n",
        "# Guardar y Descargar CSV\n",
        "results_df.to_csv('measurement_model_evaluation.csv', index=False, encoding='utf-8-sig')\n",
        "files.download('measurement_model_evaluation.csv')"
      ],
      "metadata": {
        "id": "AKH62WlAuKHS",
        "outputId": "d6840d10-eeac-437b-bc65-23f90984bf04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previsualización de la tabla:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        Constructs/items Loading      α     CR    AVE\n",
              "0                             Integridad          0.876  0.915  0.729\n",
              "1                                  int_1   0.879                     \n",
              "2                                  int_2   0.864                     \n",
              "3                                  int_3   0.827                     \n",
              "4                                  int_4   0.846                     \n",
              "5                               Expertis          0.813  0.877  0.642\n",
              "6                                  exp_1   0.823                     \n",
              "7                                  exp_2   0.796                     \n",
              "8                                  exp_3   0.813                     \n",
              "9                                  exp_4   0.771                     \n",
              "10                          Autenticidad          0.846  0.907  0.765\n",
              "11                                 aut_1   0.848                     \n",
              "12                                 aut_2   0.902                     \n",
              "13                                 aut_3   0.873                     \n",
              "14                          Atractividad          0.883  0.919  0.741\n",
              "15                                 att_1   0.852                     \n",
              "16                                 att_2   0.849                     \n",
              "17                                 att_3   0.861                     \n",
              "18                                 att_4   0.880                     \n",
              "19                             Similitud          0.875  0.924  0.801\n",
              "20                                 sim_1   0.858                     \n",
              "21                                 sim_2   0.923                     \n",
              "22                                 sim_3   0.903                     \n",
              "23                      Lider_de_opinion          0.878  0.916  0.732\n",
              "24                                 lid_1   0.856                     \n",
              "25                                 lid_2   0.813                     \n",
              "26                                 lid_3   0.871                     \n",
              "27                                 lid_4   0.882                     \n",
              "28          Informatividad_del_contenido          0.843  0.905  0.761\n",
              "29                                 inf_1   0.919                     \n",
              "30                                 inf_2   0.875                     \n",
              "31                                 inf_3   0.820                     \n",
              "32       Congruencia_influencer_follower          0.847  0.907  0.766\n",
              "33                               congf_1   0.931                     \n",
              "34                               congf_2   0.851                     \n",
              "35                               congf_3   0.840                     \n",
              "36       Congruencia_influencer_producto          0.850  0.910  0.771\n",
              "37                               congp_1   0.894                     \n",
              "38                               congp_2   0.883                     \n",
              "39                               congp_3   0.857                     \n",
              "40           Conciencia_de_la_persuasion          0.853  0.895  0.630\n",
              "41                               concp_1   0.883                     \n",
              "42                               concp_2   0.844                     \n",
              "43                               concp_3   0.750                     \n",
              "44                               concp_4   0.735                     \n",
              "45                               concp_5   0.747                     \n",
              "46                               Actitud          0.845  0.906  0.764\n",
              "47                                 act_1   0.883                     \n",
              "48                                 act_2   0.833                     \n",
              "49                                 act_3   0.905                     \n",
              "50  Predisposicion_a_comprar_un_producto          0.854  0.911  0.774\n",
              "51                                pred_1   0.917                     \n",
              "52                                pred_2   0.872                     \n",
              "53                                pred_3   0.850                     \n",
              "54                            Engagement          0.831  0.881  0.598\n",
              "55                                 eng_1   0.723                     \n",
              "56                                 eng_2   0.817                     \n",
              "57                                 eng_3   0.711                     \n",
              "58                                 eng_4   0.817                     \n",
              "59                                 eng_5   0.791                     "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af752760-d331-42a4-957d-45cd3da21e98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Constructs/items</th>\n",
              "      <th>Loading</th>\n",
              "      <th>α</th>\n",
              "      <th>CR</th>\n",
              "      <th>AVE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Integridad</td>\n",
              "      <td></td>\n",
              "      <td>0.876</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>int_1</td>\n",
              "      <td>0.879</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>int_2</td>\n",
              "      <td>0.864</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>int_3</td>\n",
              "      <td>0.827</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>int_4</td>\n",
              "      <td>0.846</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Expertis</td>\n",
              "      <td></td>\n",
              "      <td>0.813</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>exp_1</td>\n",
              "      <td>0.823</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>exp_2</td>\n",
              "      <td>0.796</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>exp_3</td>\n",
              "      <td>0.813</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>exp_4</td>\n",
              "      <td>0.771</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Autenticidad</td>\n",
              "      <td></td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.907</td>\n",
              "      <td>0.765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>aut_1</td>\n",
              "      <td>0.848</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>aut_2</td>\n",
              "      <td>0.902</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>aut_3</td>\n",
              "      <td>0.873</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Atractividad</td>\n",
              "      <td></td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.919</td>\n",
              "      <td>0.741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>att_1</td>\n",
              "      <td>0.852</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>att_2</td>\n",
              "      <td>0.849</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>att_3</td>\n",
              "      <td>0.861</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>att_4</td>\n",
              "      <td>0.880</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Similitud</td>\n",
              "      <td></td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.924</td>\n",
              "      <td>0.801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>sim_1</td>\n",
              "      <td>0.858</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>sim_2</td>\n",
              "      <td>0.923</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>sim_3</td>\n",
              "      <td>0.903</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Lider_de_opinion</td>\n",
              "      <td></td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>lid_1</td>\n",
              "      <td>0.856</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>lid_2</td>\n",
              "      <td>0.813</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>lid_3</td>\n",
              "      <td>0.871</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>lid_4</td>\n",
              "      <td>0.882</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Informatividad_del_contenido</td>\n",
              "      <td></td>\n",
              "      <td>0.843</td>\n",
              "      <td>0.905</td>\n",
              "      <td>0.761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>inf_1</td>\n",
              "      <td>0.919</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>inf_2</td>\n",
              "      <td>0.875</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>inf_3</td>\n",
              "      <td>0.820</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Congruencia_influencer_follower</td>\n",
              "      <td></td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.907</td>\n",
              "      <td>0.766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>congf_1</td>\n",
              "      <td>0.931</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>congf_2</td>\n",
              "      <td>0.851</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>congf_3</td>\n",
              "      <td>0.840</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Congruencia_influencer_producto</td>\n",
              "      <td></td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.910</td>\n",
              "      <td>0.771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>congp_1</td>\n",
              "      <td>0.894</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>congp_2</td>\n",
              "      <td>0.883</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>congp_3</td>\n",
              "      <td>0.857</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Conciencia_de_la_persuasion</td>\n",
              "      <td></td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>concp_1</td>\n",
              "      <td>0.883</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>concp_2</td>\n",
              "      <td>0.844</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>concp_3</td>\n",
              "      <td>0.750</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>concp_4</td>\n",
              "      <td>0.735</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>concp_5</td>\n",
              "      <td>0.747</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Actitud</td>\n",
              "      <td></td>\n",
              "      <td>0.845</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>act_1</td>\n",
              "      <td>0.883</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>act_2</td>\n",
              "      <td>0.833</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>act_3</td>\n",
              "      <td>0.905</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Predisposicion_a_comprar_un_producto</td>\n",
              "      <td></td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.911</td>\n",
              "      <td>0.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>pred_1</td>\n",
              "      <td>0.917</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>pred_2</td>\n",
              "      <td>0.872</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>pred_3</td>\n",
              "      <td>0.850</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Engagement</td>\n",
              "      <td></td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>eng_1</td>\n",
              "      <td>0.723</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>eng_2</td>\n",
              "      <td>0.817</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>eng_3</td>\n",
              "      <td>0.711</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>eng_4</td>\n",
              "      <td>0.817</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>eng_5</td>\n",
              "      <td>0.791</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af752760-d331-42a4-957d-45cd3da21e98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af752760-d331-42a4-957d-45cd3da21e98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af752760-d331-42a4-957d-45cd3da21e98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_66e7452d-f999-438f-b846-554491221f8a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_66e7452d-f999-438f-b846-554491221f8a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"Constructs/items\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Integridad\",\n          \"Expertis\",\n          \"Congruencia_influencer_producto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loading\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"0.917\",\n          \"0.820\",\n          \"0.931\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u03b1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"0.850\",\n          \"0.845\",\n          \"0.876\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CR\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"0.911\",\n          \"0.895\",\n          \"0.915\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"0.771\",\n          \"0.764\",\n          \"0.729\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_328bf7bc-08b9-496c-bddb-cb080b92e9da\", \"measurement_model_evaluation.csv\", 1265)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de los resultados** de evaluación del modelo con solo variables de Primer orden"
      ],
      "metadata": {
        "id": "OFld6aP1xpAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display\n",
        "\n",
        "# 1. Cargar datos\n",
        "# Asegúrate de que el archivo 'datos_codificados_ajustados (1).xlsx' (o .csv) esté en Colab\n",
        "try:\n",
        "    df = pd.read_excel('datos_codificados_ajustados (1).xlsx')\n",
        "except:\n",
        "    try:\n",
        "        df = pd.read_csv('datos_codificados_ajustados (1).xlsx - Sheet1.csv')\n",
        "    except:\n",
        "        # En caso de que no esté cargado, usa un placeholder o avisa\n",
        "        print(\"Asegúrate de cargar tu archivo de datos primero.\")\n",
        "\n",
        "# 2. Definir Diccionario de Constructos\n",
        "constructos = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# 3. Funciones Auxiliares\n",
        "def calculate_cronbach_alpha(itemscores):\n",
        "    itemscores = np.asarray(itemscores)\n",
        "    itemvars = itemscores.var(axis=0, ddof=1)\n",
        "    tscores = itemscores.sum(axis=1)\n",
        "    nitems = itemscores.shape[1]\n",
        "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))\n",
        "\n",
        "def evaluar_metricas(tipo, valor):\n",
        "    \"\"\"Devuelve (Estado, Color, Interpretación)\"\"\"\n",
        "    if tipo == 'Loading':\n",
        "        if valor >= 0.708: return \"Bueno\", \"background-color: #d4edda; color: #155724\", \"Carga ideal (>0.708). Ítem confiable.\"\n",
        "        elif valor >= 0.40: return \"Aceptable\", \"background-color: #fff3cd; color: #856404\", \"Carga flexible (0.4-0.7). Revisar si afecta AVE.\"\n",
        "        else: return \"No Cumple\", \"background-color: #f8d7da; color: #721c24\", \"Carga baja (<0.4). Considerar eliminar.\"\n",
        "\n",
        "    elif tipo in ['Alpha', 'CR']:\n",
        "        if valor >= 0.70: return \"Bueno\", \"background-color: #d4edda; color: #155724\", \"Alta consistencia interna.\"\n",
        "        elif valor >= 0.60: return \"Aceptable\", \"background-color: #fff3cd; color: #856404\", \"Aceptable para estudios exploratorios.\"\n",
        "        else: return \"No Cumple\", \"background-color: #f8d7da; color: #721c24\", \"Falta de consistencia interna.\"\n",
        "\n",
        "    elif tipo == 'AVE':\n",
        "        if valor >= 0.50: return \"Bueno\", \"background-color: #d4edda; color: #155724\", \"Converge satisfactoriamente (>50% varianza explicada).\"\n",
        "        else: return \"No Cumple\", \"background-color: #f8d7da; color: #721c24\", \"Problemas de validez convergente (<0.50).\"\n",
        "\n",
        "    return \"\", \"\", \"\"\n",
        "\n",
        "# 4. Procesamiento y Creación del Reporte\n",
        "reporte_data = []\n",
        "\n",
        "for construct, items in constructos.items():\n",
        "    # Validar columnas\n",
        "    valid_items = [col for col in items if col in df.columns]\n",
        "    if not valid_items: continue\n",
        "    block = df[valid_items].dropna()\n",
        "\n",
        "    # --- CÁLCULOS ---\n",
        "    # Alpha\n",
        "    alpha = calculate_cronbach_alpha(block)\n",
        "    # PCA para Loadings\n",
        "    pca = PCA(n_components=1)\n",
        "    latent_score = pca.fit_transform(block)\n",
        "    loadings = [np.corrcoef(block[col], latent_score[:, 0])[0, 1] for col in valid_items]\n",
        "    loadings = np.abs(loadings) # Usar valor absoluto\n",
        "    # AVE y CR\n",
        "    ave = np.mean(loadings**2)\n",
        "    sum_loadings_sq = np.sum(loadings)**2\n",
        "    sum_error = np.sum(1 - loadings**2)\n",
        "    cr = sum_loadings_sq / (sum_loadings_sq + sum_error)\n",
        "\n",
        "    # --- EVALUACIÓN CONSTRUCTO ---\n",
        "    # Agregar filas para Alpha, CR, AVE\n",
        "    metricas_constructo = [('Alpha (α)', alpha, 'Alpha'), ('CR (Fiabilidad)', cr, 'CR'), ('AVE (Varianza)', ave, 'AVE')]\n",
        "\n",
        "    for nombre_metrica, valor, tipo in metricas_constructo:\n",
        "        estado, estilo, interp = evaluar_metricas(tipo, valor)\n",
        "        reporte_data.append({\n",
        "            'Constructo / Ítem': f\"**{construct.upper()}**\",\n",
        "            'Tipo Indicador': nombre_metrica,\n",
        "            'Valor': valor,\n",
        "            'Evaluación': estado,\n",
        "            'Interpretación': interp,\n",
        "            'Estilo': estilo # Columna oculta para usar en el estilo\n",
        "        })\n",
        "\n",
        "    # --- EVALUACIÓN ÍTEMS (LOADINGS) ---\n",
        "    for item, load in zip(valid_items, loadings):\n",
        "        estado, estilo, interp = evaluar_metricas('Loading', load)\n",
        "        reporte_data.append({\n",
        "            'Constructo / Ítem': f\"   - {item}\",\n",
        "            'Tipo Indicador': 'Carga (Loading)',\n",
        "            'Valor': load,\n",
        "            'Evaluación': estado,\n",
        "            'Interpretación': interp,\n",
        "            'Estilo': estilo\n",
        "        })\n",
        "\n",
        "# 5. Generar DataFrame y Estilizar\n",
        "df_reporte = pd.DataFrame(reporte_data)\n",
        "\n",
        "def aplicar_estilo(x):\n",
        "    # Aplica el estilo guardado en la columna 'Estilo' a toda la fila\n",
        "    # O mejor, solo a las celdas de Evaluación/Interpretación\n",
        "    c = x['Estilo']\n",
        "    return [c if col in ['Evaluación', 'Interpretación'] else '' for col in x.index]\n",
        "\n",
        "# Visualización Final\n",
        "print(\"=\"*80)\n",
        "print(\"REPORTE DE EVALUACIÓN DEL MODELO DE MEDICIÓN (CRITERIOS HAIR ET AL.)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Crear tabla estilizada\n",
        "tabla_estilizada = (df_reporte.style\n",
        "    .apply(aplicar_estilo, axis=1) # Aplica colores según el estado\n",
        "    .format({'Valor': '{:.3f}'})    # Redondea a 3 decimales\n",
        "    .hide(axis='index')             # Oculta el índice numérico\n",
        "    .hide(['Estilo'], axis='columns') # Oculta la columna auxiliar de estilo\n",
        "    .set_properties(**{'text-align': 'left'})\n",
        ")\n",
        "\n",
        "display(tabla_estilizada)\n",
        "\n",
        "# Opción para descargar\n",
        "# df_reporte.drop(columns=['Estilo']).to_excel(\"Evaluacion_Modelo_Medicion.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MdriB24Jxgjx",
        "outputId": "5d20725b-6b78-4696-fc26-1f4e8202cddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "REPORTE DE EVALUACIÓN DEL MODELO DE MEDICIÓN (CRITERIOS HAIR ET AL.)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e5dea929fa0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_8f626_row0_col0, #T_8f626_row0_col1, #T_8f626_row0_col2, #T_8f626_row1_col0, #T_8f626_row1_col1, #T_8f626_row1_col2, #T_8f626_row2_col0, #T_8f626_row2_col1, #T_8f626_row2_col2, #T_8f626_row3_col0, #T_8f626_row3_col1, #T_8f626_row3_col2, #T_8f626_row4_col0, #T_8f626_row4_col1, #T_8f626_row4_col2, #T_8f626_row5_col0, #T_8f626_row5_col1, #T_8f626_row5_col2, #T_8f626_row6_col0, #T_8f626_row6_col1, #T_8f626_row6_col2, #T_8f626_row7_col0, #T_8f626_row7_col1, #T_8f626_row7_col2, #T_8f626_row8_col0, #T_8f626_row8_col1, #T_8f626_row8_col2, #T_8f626_row9_col0, #T_8f626_row9_col1, #T_8f626_row9_col2, #T_8f626_row10_col0, #T_8f626_row10_col1, #T_8f626_row10_col2, #T_8f626_row11_col0, #T_8f626_row11_col1, #T_8f626_row11_col2, #T_8f626_row12_col0, #T_8f626_row12_col1, #T_8f626_row12_col2, #T_8f626_row13_col0, #T_8f626_row13_col1, #T_8f626_row13_col2, #T_8f626_row14_col0, #T_8f626_row14_col1, #T_8f626_row14_col2, #T_8f626_row15_col0, #T_8f626_row15_col1, #T_8f626_row15_col2, #T_8f626_row16_col0, #T_8f626_row16_col1, #T_8f626_row16_col2, #T_8f626_row17_col0, #T_8f626_row17_col1, #T_8f626_row17_col2, #T_8f626_row18_col0, #T_8f626_row18_col1, #T_8f626_row18_col2, #T_8f626_row19_col0, #T_8f626_row19_col1, #T_8f626_row19_col2, #T_8f626_row20_col0, #T_8f626_row20_col1, #T_8f626_row20_col2, #T_8f626_row21_col0, #T_8f626_row21_col1, #T_8f626_row21_col2, #T_8f626_row22_col0, #T_8f626_row22_col1, #T_8f626_row22_col2, #T_8f626_row23_col0, #T_8f626_row23_col1, #T_8f626_row23_col2, #T_8f626_row24_col0, #T_8f626_row24_col1, #T_8f626_row24_col2, #T_8f626_row25_col0, #T_8f626_row25_col1, #T_8f626_row25_col2, #T_8f626_row26_col0, #T_8f626_row26_col1, #T_8f626_row26_col2, #T_8f626_row27_col0, #T_8f626_row27_col1, #T_8f626_row27_col2, #T_8f626_row28_col0, #T_8f626_row28_col1, #T_8f626_row28_col2, #T_8f626_row29_col0, #T_8f626_row29_col1, #T_8f626_row29_col2, #T_8f626_row30_col0, #T_8f626_row30_col1, #T_8f626_row30_col2, #T_8f626_row31_col0, #T_8f626_row31_col1, #T_8f626_row31_col2, #T_8f626_row32_col0, #T_8f626_row32_col1, #T_8f626_row32_col2, #T_8f626_row33_col0, #T_8f626_row33_col1, #T_8f626_row33_col2, #T_8f626_row34_col0, #T_8f626_row34_col1, #T_8f626_row34_col2, #T_8f626_row35_col0, #T_8f626_row35_col1, #T_8f626_row35_col2, #T_8f626_row36_col0, #T_8f626_row36_col1, #T_8f626_row36_col2, #T_8f626_row37_col0, #T_8f626_row37_col1, #T_8f626_row37_col2, #T_8f626_row38_col0, #T_8f626_row38_col1, #T_8f626_row38_col2, #T_8f626_row39_col0, #T_8f626_row39_col1, #T_8f626_row39_col2, #T_8f626_row40_col0, #T_8f626_row40_col1, #T_8f626_row40_col2, #T_8f626_row41_col0, #T_8f626_row41_col1, #T_8f626_row41_col2, #T_8f626_row42_col0, #T_8f626_row42_col1, #T_8f626_row42_col2, #T_8f626_row43_col0, #T_8f626_row43_col1, #T_8f626_row43_col2, #T_8f626_row44_col0, #T_8f626_row44_col1, #T_8f626_row44_col2, #T_8f626_row45_col0, #T_8f626_row45_col1, #T_8f626_row45_col2, #T_8f626_row46_col0, #T_8f626_row46_col1, #T_8f626_row46_col2, #T_8f626_row47_col0, #T_8f626_row47_col1, #T_8f626_row47_col2, #T_8f626_row48_col0, #T_8f626_row48_col1, #T_8f626_row48_col2, #T_8f626_row49_col0, #T_8f626_row49_col1, #T_8f626_row49_col2, #T_8f626_row50_col0, #T_8f626_row50_col1, #T_8f626_row50_col2, #T_8f626_row51_col0, #T_8f626_row51_col1, #T_8f626_row51_col2, #T_8f626_row52_col0, #T_8f626_row52_col1, #T_8f626_row52_col2, #T_8f626_row53_col0, #T_8f626_row53_col1, #T_8f626_row53_col2, #T_8f626_row54_col0, #T_8f626_row54_col1, #T_8f626_row54_col2, #T_8f626_row55_col0, #T_8f626_row55_col1, #T_8f626_row55_col2, #T_8f626_row56_col0, #T_8f626_row56_col1, #T_8f626_row56_col2, #T_8f626_row57_col0, #T_8f626_row57_col1, #T_8f626_row57_col2, #T_8f626_row58_col0, #T_8f626_row58_col1, #T_8f626_row58_col2, #T_8f626_row59_col0, #T_8f626_row59_col1, #T_8f626_row59_col2, #T_8f626_row60_col0, #T_8f626_row60_col1, #T_8f626_row60_col2, #T_8f626_row61_col0, #T_8f626_row61_col1, #T_8f626_row61_col2, #T_8f626_row62_col0, #T_8f626_row62_col1, #T_8f626_row62_col2, #T_8f626_row63_col0, #T_8f626_row63_col1, #T_8f626_row63_col2, #T_8f626_row64_col0, #T_8f626_row64_col1, #T_8f626_row64_col2, #T_8f626_row65_col0, #T_8f626_row65_col1, #T_8f626_row65_col2, #T_8f626_row66_col0, #T_8f626_row66_col1, #T_8f626_row66_col2, #T_8f626_row67_col0, #T_8f626_row67_col1, #T_8f626_row67_col2, #T_8f626_row68_col0, #T_8f626_row68_col1, #T_8f626_row68_col2, #T_8f626_row69_col0, #T_8f626_row69_col1, #T_8f626_row69_col2, #T_8f626_row70_col0, #T_8f626_row70_col1, #T_8f626_row70_col2, #T_8f626_row71_col0, #T_8f626_row71_col1, #T_8f626_row71_col2, #T_8f626_row72_col0, #T_8f626_row72_col1, #T_8f626_row72_col2, #T_8f626_row73_col0, #T_8f626_row73_col1, #T_8f626_row73_col2, #T_8f626_row74_col0, #T_8f626_row74_col1, #T_8f626_row74_col2, #T_8f626_row75_col0, #T_8f626_row75_col1, #T_8f626_row75_col2, #T_8f626_row76_col0, #T_8f626_row76_col1, #T_8f626_row76_col2, #T_8f626_row77_col0, #T_8f626_row77_col1, #T_8f626_row77_col2, #T_8f626_row78_col0, #T_8f626_row78_col1, #T_8f626_row78_col2, #T_8f626_row79_col0, #T_8f626_row79_col1, #T_8f626_row79_col2, #T_8f626_row80_col0, #T_8f626_row80_col1, #T_8f626_row80_col2, #T_8f626_row81_col0, #T_8f626_row81_col1, #T_8f626_row81_col2, #T_8f626_row82_col0, #T_8f626_row82_col1, #T_8f626_row82_col2, #T_8f626_row83_col0, #T_8f626_row83_col1, #T_8f626_row83_col2, #T_8f626_row84_col0, #T_8f626_row84_col1, #T_8f626_row84_col2, #T_8f626_row85_col0, #T_8f626_row85_col1, #T_8f626_row85_col2 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_8f626_row0_col3, #T_8f626_row0_col4, #T_8f626_row1_col3, #T_8f626_row1_col4, #T_8f626_row2_col3, #T_8f626_row2_col4, #T_8f626_row3_col3, #T_8f626_row3_col4, #T_8f626_row4_col3, #T_8f626_row4_col4, #T_8f626_row5_col3, #T_8f626_row5_col4, #T_8f626_row6_col3, #T_8f626_row6_col4, #T_8f626_row7_col3, #T_8f626_row7_col4, #T_8f626_row8_col3, #T_8f626_row8_col4, #T_8f626_row9_col3, #T_8f626_row9_col4, #T_8f626_row10_col3, #T_8f626_row10_col4, #T_8f626_row11_col3, #T_8f626_row11_col4, #T_8f626_row12_col3, #T_8f626_row12_col4, #T_8f626_row13_col3, #T_8f626_row13_col4, #T_8f626_row14_col3, #T_8f626_row14_col4, #T_8f626_row15_col3, #T_8f626_row15_col4, #T_8f626_row16_col3, #T_8f626_row16_col4, #T_8f626_row17_col3, #T_8f626_row17_col4, #T_8f626_row18_col3, #T_8f626_row18_col4, #T_8f626_row19_col3, #T_8f626_row19_col4, #T_8f626_row20_col3, #T_8f626_row20_col4, #T_8f626_row21_col3, #T_8f626_row21_col4, #T_8f626_row22_col3, #T_8f626_row22_col4, #T_8f626_row23_col3, #T_8f626_row23_col4, #T_8f626_row24_col3, #T_8f626_row24_col4, #T_8f626_row25_col3, #T_8f626_row25_col4, #T_8f626_row26_col3, #T_8f626_row26_col4, #T_8f626_row27_col3, #T_8f626_row27_col4, #T_8f626_row28_col3, #T_8f626_row28_col4, #T_8f626_row29_col3, #T_8f626_row29_col4, #T_8f626_row30_col3, #T_8f626_row30_col4, #T_8f626_row31_col3, #T_8f626_row31_col4, #T_8f626_row32_col3, #T_8f626_row32_col4, #T_8f626_row33_col3, #T_8f626_row33_col4, #T_8f626_row34_col3, #T_8f626_row34_col4, #T_8f626_row35_col3, #T_8f626_row35_col4, #T_8f626_row36_col3, #T_8f626_row36_col4, #T_8f626_row37_col3, #T_8f626_row37_col4, #T_8f626_row38_col3, #T_8f626_row38_col4, #T_8f626_row39_col3, #T_8f626_row39_col4, #T_8f626_row40_col3, #T_8f626_row40_col4, #T_8f626_row41_col3, #T_8f626_row41_col4, #T_8f626_row42_col3, #T_8f626_row42_col4, #T_8f626_row43_col3, #T_8f626_row43_col4, #T_8f626_row44_col3, #T_8f626_row44_col4, #T_8f626_row45_col3, #T_8f626_row45_col4, #T_8f626_row46_col3, #T_8f626_row46_col4, #T_8f626_row47_col3, #T_8f626_row47_col4, #T_8f626_row48_col3, #T_8f626_row48_col4, #T_8f626_row49_col3, #T_8f626_row49_col4, #T_8f626_row50_col3, #T_8f626_row50_col4, #T_8f626_row51_col3, #T_8f626_row51_col4, #T_8f626_row52_col3, #T_8f626_row52_col4, #T_8f626_row53_col3, #T_8f626_row53_col4, #T_8f626_row54_col3, #T_8f626_row54_col4, #T_8f626_row55_col3, #T_8f626_row55_col4, #T_8f626_row56_col3, #T_8f626_row56_col4, #T_8f626_row57_col3, #T_8f626_row57_col4, #T_8f626_row58_col3, #T_8f626_row58_col4, #T_8f626_row59_col3, #T_8f626_row59_col4, #T_8f626_row60_col3, #T_8f626_row60_col4, #T_8f626_row61_col3, #T_8f626_row61_col4, #T_8f626_row62_col3, #T_8f626_row62_col4, #T_8f626_row63_col3, #T_8f626_row63_col4, #T_8f626_row64_col3, #T_8f626_row64_col4, #T_8f626_row65_col3, #T_8f626_row65_col4, #T_8f626_row66_col3, #T_8f626_row66_col4, #T_8f626_row67_col3, #T_8f626_row67_col4, #T_8f626_row68_col3, #T_8f626_row68_col4, #T_8f626_row69_col3, #T_8f626_row69_col4, #T_8f626_row70_col3, #T_8f626_row70_col4, #T_8f626_row71_col3, #T_8f626_row71_col4, #T_8f626_row72_col3, #T_8f626_row72_col4, #T_8f626_row73_col3, #T_8f626_row73_col4, #T_8f626_row74_col3, #T_8f626_row74_col4, #T_8f626_row75_col3, #T_8f626_row75_col4, #T_8f626_row76_col3, #T_8f626_row76_col4, #T_8f626_row77_col3, #T_8f626_row77_col4, #T_8f626_row78_col3, #T_8f626_row78_col4, #T_8f626_row79_col3, #T_8f626_row79_col4, #T_8f626_row80_col3, #T_8f626_row80_col4, #T_8f626_row81_col3, #T_8f626_row81_col4, #T_8f626_row82_col3, #T_8f626_row82_col4, #T_8f626_row83_col3, #T_8f626_row83_col4, #T_8f626_row84_col3, #T_8f626_row84_col4, #T_8f626_row85_col3, #T_8f626_row85_col4 {\n",
              "  background-color: #d4edda;\n",
              "  color: #155724;\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_8f626\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_8f626_level0_col0\" class=\"col_heading level0 col0\" >Constructo / Ítem</th>\n",
              "      <th id=\"T_8f626_level0_col1\" class=\"col_heading level0 col1\" >Tipo Indicador</th>\n",
              "      <th id=\"T_8f626_level0_col2\" class=\"col_heading level0 col2\" >Valor</th>\n",
              "      <th id=\"T_8f626_level0_col3\" class=\"col_heading level0 col3\" >Evaluación</th>\n",
              "      <th id=\"T_8f626_level0_col4\" class=\"col_heading level0 col4\" >Interpretación</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row0_col0\" class=\"data row0 col0\" >**INTEGRIDAD**</td>\n",
              "      <td id=\"T_8f626_row0_col1\" class=\"data row0 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row0_col2\" class=\"data row0 col2\" >0.876</td>\n",
              "      <td id=\"T_8f626_row0_col3\" class=\"data row0 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row0_col4\" class=\"data row0 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row1_col0\" class=\"data row1 col0\" >**INTEGRIDAD**</td>\n",
              "      <td id=\"T_8f626_row1_col1\" class=\"data row1 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row1_col2\" class=\"data row1 col2\" >0.915</td>\n",
              "      <td id=\"T_8f626_row1_col3\" class=\"data row1 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row1_col4\" class=\"data row1 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row2_col0\" class=\"data row2 col0\" >**INTEGRIDAD**</td>\n",
              "      <td id=\"T_8f626_row2_col1\" class=\"data row2 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row2_col2\" class=\"data row2 col2\" >0.729</td>\n",
              "      <td id=\"T_8f626_row2_col3\" class=\"data row2 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row2_col4\" class=\"data row2 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row3_col0\" class=\"data row3 col0\" >   - int_1</td>\n",
              "      <td id=\"T_8f626_row3_col1\" class=\"data row3 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row3_col2\" class=\"data row3 col2\" >0.879</td>\n",
              "      <td id=\"T_8f626_row3_col3\" class=\"data row3 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row3_col4\" class=\"data row3 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row4_col0\" class=\"data row4 col0\" >   - int_2</td>\n",
              "      <td id=\"T_8f626_row4_col1\" class=\"data row4 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row4_col2\" class=\"data row4 col2\" >0.864</td>\n",
              "      <td id=\"T_8f626_row4_col3\" class=\"data row4 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row4_col4\" class=\"data row4 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row5_col0\" class=\"data row5 col0\" >   - int_3</td>\n",
              "      <td id=\"T_8f626_row5_col1\" class=\"data row5 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row5_col2\" class=\"data row5 col2\" >0.827</td>\n",
              "      <td id=\"T_8f626_row5_col3\" class=\"data row5 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row5_col4\" class=\"data row5 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row6_col0\" class=\"data row6 col0\" >   - int_4</td>\n",
              "      <td id=\"T_8f626_row6_col1\" class=\"data row6 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row6_col2\" class=\"data row6 col2\" >0.846</td>\n",
              "      <td id=\"T_8f626_row6_col3\" class=\"data row6 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row6_col4\" class=\"data row6 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row7_col0\" class=\"data row7 col0\" >**EXPERTIS**</td>\n",
              "      <td id=\"T_8f626_row7_col1\" class=\"data row7 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row7_col2\" class=\"data row7 col2\" >0.813</td>\n",
              "      <td id=\"T_8f626_row7_col3\" class=\"data row7 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row7_col4\" class=\"data row7 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row8_col0\" class=\"data row8 col0\" >**EXPERTIS**</td>\n",
              "      <td id=\"T_8f626_row8_col1\" class=\"data row8 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row8_col2\" class=\"data row8 col2\" >0.877</td>\n",
              "      <td id=\"T_8f626_row8_col3\" class=\"data row8 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row8_col4\" class=\"data row8 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row9_col0\" class=\"data row9 col0\" >**EXPERTIS**</td>\n",
              "      <td id=\"T_8f626_row9_col1\" class=\"data row9 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row9_col2\" class=\"data row9 col2\" >0.642</td>\n",
              "      <td id=\"T_8f626_row9_col3\" class=\"data row9 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row9_col4\" class=\"data row9 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row10_col0\" class=\"data row10 col0\" >   - exp_1</td>\n",
              "      <td id=\"T_8f626_row10_col1\" class=\"data row10 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row10_col2\" class=\"data row10 col2\" >0.823</td>\n",
              "      <td id=\"T_8f626_row10_col3\" class=\"data row10 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row10_col4\" class=\"data row10 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row11_col0\" class=\"data row11 col0\" >   - exp_2</td>\n",
              "      <td id=\"T_8f626_row11_col1\" class=\"data row11 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row11_col2\" class=\"data row11 col2\" >0.796</td>\n",
              "      <td id=\"T_8f626_row11_col3\" class=\"data row11 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row11_col4\" class=\"data row11 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row12_col0\" class=\"data row12 col0\" >   - exp_3</td>\n",
              "      <td id=\"T_8f626_row12_col1\" class=\"data row12 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row12_col2\" class=\"data row12 col2\" >0.813</td>\n",
              "      <td id=\"T_8f626_row12_col3\" class=\"data row12 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row12_col4\" class=\"data row12 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row13_col0\" class=\"data row13 col0\" >   - exp_4</td>\n",
              "      <td id=\"T_8f626_row13_col1\" class=\"data row13 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row13_col2\" class=\"data row13 col2\" >0.771</td>\n",
              "      <td id=\"T_8f626_row13_col3\" class=\"data row13 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row13_col4\" class=\"data row13 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row14_col0\" class=\"data row14 col0\" >**AUTENTICIDAD**</td>\n",
              "      <td id=\"T_8f626_row14_col1\" class=\"data row14 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row14_col2\" class=\"data row14 col2\" >0.846</td>\n",
              "      <td id=\"T_8f626_row14_col3\" class=\"data row14 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row14_col4\" class=\"data row14 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row15_col0\" class=\"data row15 col0\" >**AUTENTICIDAD**</td>\n",
              "      <td id=\"T_8f626_row15_col1\" class=\"data row15 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row15_col2\" class=\"data row15 col2\" >0.907</td>\n",
              "      <td id=\"T_8f626_row15_col3\" class=\"data row15 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row15_col4\" class=\"data row15 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row16_col0\" class=\"data row16 col0\" >**AUTENTICIDAD**</td>\n",
              "      <td id=\"T_8f626_row16_col1\" class=\"data row16 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row16_col2\" class=\"data row16 col2\" >0.765</td>\n",
              "      <td id=\"T_8f626_row16_col3\" class=\"data row16 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row16_col4\" class=\"data row16 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row17_col0\" class=\"data row17 col0\" >   - aut_1</td>\n",
              "      <td id=\"T_8f626_row17_col1\" class=\"data row17 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row17_col2\" class=\"data row17 col2\" >0.848</td>\n",
              "      <td id=\"T_8f626_row17_col3\" class=\"data row17 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row17_col4\" class=\"data row17 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row18_col0\" class=\"data row18 col0\" >   - aut_2</td>\n",
              "      <td id=\"T_8f626_row18_col1\" class=\"data row18 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row18_col2\" class=\"data row18 col2\" >0.902</td>\n",
              "      <td id=\"T_8f626_row18_col3\" class=\"data row18 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row18_col4\" class=\"data row18 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row19_col0\" class=\"data row19 col0\" >   - aut_3</td>\n",
              "      <td id=\"T_8f626_row19_col1\" class=\"data row19 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row19_col2\" class=\"data row19 col2\" >0.873</td>\n",
              "      <td id=\"T_8f626_row19_col3\" class=\"data row19 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row19_col4\" class=\"data row19 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row20_col0\" class=\"data row20 col0\" >**ATRACTIVIDAD**</td>\n",
              "      <td id=\"T_8f626_row20_col1\" class=\"data row20 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row20_col2\" class=\"data row20 col2\" >0.883</td>\n",
              "      <td id=\"T_8f626_row20_col3\" class=\"data row20 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row20_col4\" class=\"data row20 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row21_col0\" class=\"data row21 col0\" >**ATRACTIVIDAD**</td>\n",
              "      <td id=\"T_8f626_row21_col1\" class=\"data row21 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row21_col2\" class=\"data row21 col2\" >0.919</td>\n",
              "      <td id=\"T_8f626_row21_col3\" class=\"data row21 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row21_col4\" class=\"data row21 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row22_col0\" class=\"data row22 col0\" >**ATRACTIVIDAD**</td>\n",
              "      <td id=\"T_8f626_row22_col1\" class=\"data row22 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row22_col2\" class=\"data row22 col2\" >0.741</td>\n",
              "      <td id=\"T_8f626_row22_col3\" class=\"data row22 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row22_col4\" class=\"data row22 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row23_col0\" class=\"data row23 col0\" >   - att_1</td>\n",
              "      <td id=\"T_8f626_row23_col1\" class=\"data row23 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row23_col2\" class=\"data row23 col2\" >0.852</td>\n",
              "      <td id=\"T_8f626_row23_col3\" class=\"data row23 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row23_col4\" class=\"data row23 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row24_col0\" class=\"data row24 col0\" >   - att_2</td>\n",
              "      <td id=\"T_8f626_row24_col1\" class=\"data row24 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row24_col2\" class=\"data row24 col2\" >0.849</td>\n",
              "      <td id=\"T_8f626_row24_col3\" class=\"data row24 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row24_col4\" class=\"data row24 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row25_col0\" class=\"data row25 col0\" >   - att_3</td>\n",
              "      <td id=\"T_8f626_row25_col1\" class=\"data row25 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row25_col2\" class=\"data row25 col2\" >0.861</td>\n",
              "      <td id=\"T_8f626_row25_col3\" class=\"data row25 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row25_col4\" class=\"data row25 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row26_col0\" class=\"data row26 col0\" >   - att_4</td>\n",
              "      <td id=\"T_8f626_row26_col1\" class=\"data row26 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row26_col2\" class=\"data row26 col2\" >0.880</td>\n",
              "      <td id=\"T_8f626_row26_col3\" class=\"data row26 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row26_col4\" class=\"data row26 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row27_col0\" class=\"data row27 col0\" >**SIMILITUD**</td>\n",
              "      <td id=\"T_8f626_row27_col1\" class=\"data row27 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row27_col2\" class=\"data row27 col2\" >0.875</td>\n",
              "      <td id=\"T_8f626_row27_col3\" class=\"data row27 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row27_col4\" class=\"data row27 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row28_col0\" class=\"data row28 col0\" >**SIMILITUD**</td>\n",
              "      <td id=\"T_8f626_row28_col1\" class=\"data row28 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row28_col2\" class=\"data row28 col2\" >0.924</td>\n",
              "      <td id=\"T_8f626_row28_col3\" class=\"data row28 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row28_col4\" class=\"data row28 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row29_col0\" class=\"data row29 col0\" >**SIMILITUD**</td>\n",
              "      <td id=\"T_8f626_row29_col1\" class=\"data row29 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row29_col2\" class=\"data row29 col2\" >0.801</td>\n",
              "      <td id=\"T_8f626_row29_col3\" class=\"data row29 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row29_col4\" class=\"data row29 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row30_col0\" class=\"data row30 col0\" >   - sim_1</td>\n",
              "      <td id=\"T_8f626_row30_col1\" class=\"data row30 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row30_col2\" class=\"data row30 col2\" >0.858</td>\n",
              "      <td id=\"T_8f626_row30_col3\" class=\"data row30 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row30_col4\" class=\"data row30 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row31_col0\" class=\"data row31 col0\" >   - sim_2</td>\n",
              "      <td id=\"T_8f626_row31_col1\" class=\"data row31 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row31_col2\" class=\"data row31 col2\" >0.923</td>\n",
              "      <td id=\"T_8f626_row31_col3\" class=\"data row31 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row31_col4\" class=\"data row31 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row32_col0\" class=\"data row32 col0\" >   - sim_3</td>\n",
              "      <td id=\"T_8f626_row32_col1\" class=\"data row32 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row32_col2\" class=\"data row32 col2\" >0.903</td>\n",
              "      <td id=\"T_8f626_row32_col3\" class=\"data row32 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row32_col4\" class=\"data row32 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row33_col0\" class=\"data row33 col0\" >**LIDER_DE_OPINION**</td>\n",
              "      <td id=\"T_8f626_row33_col1\" class=\"data row33 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row33_col2\" class=\"data row33 col2\" >0.878</td>\n",
              "      <td id=\"T_8f626_row33_col3\" class=\"data row33 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row33_col4\" class=\"data row33 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row34_col0\" class=\"data row34 col0\" >**LIDER_DE_OPINION**</td>\n",
              "      <td id=\"T_8f626_row34_col1\" class=\"data row34 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row34_col2\" class=\"data row34 col2\" >0.916</td>\n",
              "      <td id=\"T_8f626_row34_col3\" class=\"data row34 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row34_col4\" class=\"data row34 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row35_col0\" class=\"data row35 col0\" >**LIDER_DE_OPINION**</td>\n",
              "      <td id=\"T_8f626_row35_col1\" class=\"data row35 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row35_col2\" class=\"data row35 col2\" >0.732</td>\n",
              "      <td id=\"T_8f626_row35_col3\" class=\"data row35 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row35_col4\" class=\"data row35 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row36_col0\" class=\"data row36 col0\" >   - lid_1</td>\n",
              "      <td id=\"T_8f626_row36_col1\" class=\"data row36 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row36_col2\" class=\"data row36 col2\" >0.856</td>\n",
              "      <td id=\"T_8f626_row36_col3\" class=\"data row36 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row36_col4\" class=\"data row36 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row37_col0\" class=\"data row37 col0\" >   - lid_2</td>\n",
              "      <td id=\"T_8f626_row37_col1\" class=\"data row37 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row37_col2\" class=\"data row37 col2\" >0.813</td>\n",
              "      <td id=\"T_8f626_row37_col3\" class=\"data row37 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row37_col4\" class=\"data row37 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row38_col0\" class=\"data row38 col0\" >   - lid_3</td>\n",
              "      <td id=\"T_8f626_row38_col1\" class=\"data row38 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row38_col2\" class=\"data row38 col2\" >0.871</td>\n",
              "      <td id=\"T_8f626_row38_col3\" class=\"data row38 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row38_col4\" class=\"data row38 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row39_col0\" class=\"data row39 col0\" >   - lid_4</td>\n",
              "      <td id=\"T_8f626_row39_col1\" class=\"data row39 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row39_col2\" class=\"data row39 col2\" >0.882</td>\n",
              "      <td id=\"T_8f626_row39_col3\" class=\"data row39 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row39_col4\" class=\"data row39 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row40_col0\" class=\"data row40 col0\" >**INFORMATIVIDAD_DEL_CONTENIDO**</td>\n",
              "      <td id=\"T_8f626_row40_col1\" class=\"data row40 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row40_col2\" class=\"data row40 col2\" >0.843</td>\n",
              "      <td id=\"T_8f626_row40_col3\" class=\"data row40 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row40_col4\" class=\"data row40 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row41_col0\" class=\"data row41 col0\" >**INFORMATIVIDAD_DEL_CONTENIDO**</td>\n",
              "      <td id=\"T_8f626_row41_col1\" class=\"data row41 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row41_col2\" class=\"data row41 col2\" >0.905</td>\n",
              "      <td id=\"T_8f626_row41_col3\" class=\"data row41 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row41_col4\" class=\"data row41 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row42_col0\" class=\"data row42 col0\" >**INFORMATIVIDAD_DEL_CONTENIDO**</td>\n",
              "      <td id=\"T_8f626_row42_col1\" class=\"data row42 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row42_col2\" class=\"data row42 col2\" >0.761</td>\n",
              "      <td id=\"T_8f626_row42_col3\" class=\"data row42 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row42_col4\" class=\"data row42 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row43_col0\" class=\"data row43 col0\" >   - inf_1</td>\n",
              "      <td id=\"T_8f626_row43_col1\" class=\"data row43 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row43_col2\" class=\"data row43 col2\" >0.919</td>\n",
              "      <td id=\"T_8f626_row43_col3\" class=\"data row43 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row43_col4\" class=\"data row43 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row44_col0\" class=\"data row44 col0\" >   - inf_2</td>\n",
              "      <td id=\"T_8f626_row44_col1\" class=\"data row44 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row44_col2\" class=\"data row44 col2\" >0.875</td>\n",
              "      <td id=\"T_8f626_row44_col3\" class=\"data row44 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row44_col4\" class=\"data row44 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row45_col0\" class=\"data row45 col0\" >   - inf_3</td>\n",
              "      <td id=\"T_8f626_row45_col1\" class=\"data row45 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row45_col2\" class=\"data row45 col2\" >0.820</td>\n",
              "      <td id=\"T_8f626_row45_col3\" class=\"data row45 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row45_col4\" class=\"data row45 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row46_col0\" class=\"data row46 col0\" >**CONGRUENCIA_INFLUENCER_FOLLOWER**</td>\n",
              "      <td id=\"T_8f626_row46_col1\" class=\"data row46 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row46_col2\" class=\"data row46 col2\" >0.847</td>\n",
              "      <td id=\"T_8f626_row46_col3\" class=\"data row46 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row46_col4\" class=\"data row46 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row47_col0\" class=\"data row47 col0\" >**CONGRUENCIA_INFLUENCER_FOLLOWER**</td>\n",
              "      <td id=\"T_8f626_row47_col1\" class=\"data row47 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row47_col2\" class=\"data row47 col2\" >0.907</td>\n",
              "      <td id=\"T_8f626_row47_col3\" class=\"data row47 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row47_col4\" class=\"data row47 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row48_col0\" class=\"data row48 col0\" >**CONGRUENCIA_INFLUENCER_FOLLOWER**</td>\n",
              "      <td id=\"T_8f626_row48_col1\" class=\"data row48 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row48_col2\" class=\"data row48 col2\" >0.766</td>\n",
              "      <td id=\"T_8f626_row48_col3\" class=\"data row48 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row48_col4\" class=\"data row48 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row49_col0\" class=\"data row49 col0\" >   - congf_1</td>\n",
              "      <td id=\"T_8f626_row49_col1\" class=\"data row49 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row49_col2\" class=\"data row49 col2\" >0.931</td>\n",
              "      <td id=\"T_8f626_row49_col3\" class=\"data row49 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row49_col4\" class=\"data row49 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row50_col0\" class=\"data row50 col0\" >   - congf_2</td>\n",
              "      <td id=\"T_8f626_row50_col1\" class=\"data row50 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row50_col2\" class=\"data row50 col2\" >0.851</td>\n",
              "      <td id=\"T_8f626_row50_col3\" class=\"data row50 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row50_col4\" class=\"data row50 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row51_col0\" class=\"data row51 col0\" >   - congf_3</td>\n",
              "      <td id=\"T_8f626_row51_col1\" class=\"data row51 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row51_col2\" class=\"data row51 col2\" >0.840</td>\n",
              "      <td id=\"T_8f626_row51_col3\" class=\"data row51 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row51_col4\" class=\"data row51 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row52_col0\" class=\"data row52 col0\" >**CONGRUENCIA_INFLUENCER_PRODUCTO**</td>\n",
              "      <td id=\"T_8f626_row52_col1\" class=\"data row52 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row52_col2\" class=\"data row52 col2\" >0.850</td>\n",
              "      <td id=\"T_8f626_row52_col3\" class=\"data row52 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row52_col4\" class=\"data row52 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row53_col0\" class=\"data row53 col0\" >**CONGRUENCIA_INFLUENCER_PRODUCTO**</td>\n",
              "      <td id=\"T_8f626_row53_col1\" class=\"data row53 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row53_col2\" class=\"data row53 col2\" >0.910</td>\n",
              "      <td id=\"T_8f626_row53_col3\" class=\"data row53 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row53_col4\" class=\"data row53 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row54_col0\" class=\"data row54 col0\" >**CONGRUENCIA_INFLUENCER_PRODUCTO**</td>\n",
              "      <td id=\"T_8f626_row54_col1\" class=\"data row54 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row54_col2\" class=\"data row54 col2\" >0.771</td>\n",
              "      <td id=\"T_8f626_row54_col3\" class=\"data row54 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row54_col4\" class=\"data row54 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row55_col0\" class=\"data row55 col0\" >   - congp_1</td>\n",
              "      <td id=\"T_8f626_row55_col1\" class=\"data row55 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row55_col2\" class=\"data row55 col2\" >0.894</td>\n",
              "      <td id=\"T_8f626_row55_col3\" class=\"data row55 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row55_col4\" class=\"data row55 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row56_col0\" class=\"data row56 col0\" >   - congp_2</td>\n",
              "      <td id=\"T_8f626_row56_col1\" class=\"data row56 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row56_col2\" class=\"data row56 col2\" >0.883</td>\n",
              "      <td id=\"T_8f626_row56_col3\" class=\"data row56 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row56_col4\" class=\"data row56 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row57_col0\" class=\"data row57 col0\" >   - congp_3</td>\n",
              "      <td id=\"T_8f626_row57_col1\" class=\"data row57 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row57_col2\" class=\"data row57 col2\" >0.857</td>\n",
              "      <td id=\"T_8f626_row57_col3\" class=\"data row57 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row57_col4\" class=\"data row57 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row58_col0\" class=\"data row58 col0\" >**CONCIENCIA_DE_LA_PERSUASION**</td>\n",
              "      <td id=\"T_8f626_row58_col1\" class=\"data row58 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row58_col2\" class=\"data row58 col2\" >0.853</td>\n",
              "      <td id=\"T_8f626_row58_col3\" class=\"data row58 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row58_col4\" class=\"data row58 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row59_col0\" class=\"data row59 col0\" >**CONCIENCIA_DE_LA_PERSUASION**</td>\n",
              "      <td id=\"T_8f626_row59_col1\" class=\"data row59 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row59_col2\" class=\"data row59 col2\" >0.895</td>\n",
              "      <td id=\"T_8f626_row59_col3\" class=\"data row59 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row59_col4\" class=\"data row59 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row60_col0\" class=\"data row60 col0\" >**CONCIENCIA_DE_LA_PERSUASION**</td>\n",
              "      <td id=\"T_8f626_row60_col1\" class=\"data row60 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row60_col2\" class=\"data row60 col2\" >0.630</td>\n",
              "      <td id=\"T_8f626_row60_col3\" class=\"data row60 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row60_col4\" class=\"data row60 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row61_col0\" class=\"data row61 col0\" >   - concp_1</td>\n",
              "      <td id=\"T_8f626_row61_col1\" class=\"data row61 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row61_col2\" class=\"data row61 col2\" >0.883</td>\n",
              "      <td id=\"T_8f626_row61_col3\" class=\"data row61 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row61_col4\" class=\"data row61 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row62_col0\" class=\"data row62 col0\" >   - concp_2</td>\n",
              "      <td id=\"T_8f626_row62_col1\" class=\"data row62 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row62_col2\" class=\"data row62 col2\" >0.844</td>\n",
              "      <td id=\"T_8f626_row62_col3\" class=\"data row62 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row62_col4\" class=\"data row62 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row63_col0\" class=\"data row63 col0\" >   - concp_3</td>\n",
              "      <td id=\"T_8f626_row63_col1\" class=\"data row63 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row63_col2\" class=\"data row63 col2\" >0.750</td>\n",
              "      <td id=\"T_8f626_row63_col3\" class=\"data row63 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row63_col4\" class=\"data row63 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row64_col0\" class=\"data row64 col0\" >   - concp_4</td>\n",
              "      <td id=\"T_8f626_row64_col1\" class=\"data row64 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row64_col2\" class=\"data row64 col2\" >0.735</td>\n",
              "      <td id=\"T_8f626_row64_col3\" class=\"data row64 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row64_col4\" class=\"data row64 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row65_col0\" class=\"data row65 col0\" >   - concp_5</td>\n",
              "      <td id=\"T_8f626_row65_col1\" class=\"data row65 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row65_col2\" class=\"data row65 col2\" >0.747</td>\n",
              "      <td id=\"T_8f626_row65_col3\" class=\"data row65 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row65_col4\" class=\"data row65 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row66_col0\" class=\"data row66 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_8f626_row66_col1\" class=\"data row66 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row66_col2\" class=\"data row66 col2\" >0.845</td>\n",
              "      <td id=\"T_8f626_row66_col3\" class=\"data row66 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row66_col4\" class=\"data row66 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row67_col0\" class=\"data row67 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_8f626_row67_col1\" class=\"data row67 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row67_col2\" class=\"data row67 col2\" >0.906</td>\n",
              "      <td id=\"T_8f626_row67_col3\" class=\"data row67 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row67_col4\" class=\"data row67 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row68_col0\" class=\"data row68 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_8f626_row68_col1\" class=\"data row68 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row68_col2\" class=\"data row68 col2\" >0.764</td>\n",
              "      <td id=\"T_8f626_row68_col3\" class=\"data row68 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row68_col4\" class=\"data row68 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row69_col0\" class=\"data row69 col0\" >   - act_1</td>\n",
              "      <td id=\"T_8f626_row69_col1\" class=\"data row69 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row69_col2\" class=\"data row69 col2\" >0.883</td>\n",
              "      <td id=\"T_8f626_row69_col3\" class=\"data row69 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row69_col4\" class=\"data row69 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row70_col0\" class=\"data row70 col0\" >   - act_2</td>\n",
              "      <td id=\"T_8f626_row70_col1\" class=\"data row70 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row70_col2\" class=\"data row70 col2\" >0.833</td>\n",
              "      <td id=\"T_8f626_row70_col3\" class=\"data row70 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row70_col4\" class=\"data row70 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row71_col0\" class=\"data row71 col0\" >   - act_3</td>\n",
              "      <td id=\"T_8f626_row71_col1\" class=\"data row71 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row71_col2\" class=\"data row71 col2\" >0.905</td>\n",
              "      <td id=\"T_8f626_row71_col3\" class=\"data row71 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row71_col4\" class=\"data row71 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row72_col0\" class=\"data row72 col0\" >**PREDISPOSICION_A_COMPRAR_UN_PRODUCTO**</td>\n",
              "      <td id=\"T_8f626_row72_col1\" class=\"data row72 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row72_col2\" class=\"data row72 col2\" >0.854</td>\n",
              "      <td id=\"T_8f626_row72_col3\" class=\"data row72 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row72_col4\" class=\"data row72 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row73_col0\" class=\"data row73 col0\" >**PREDISPOSICION_A_COMPRAR_UN_PRODUCTO**</td>\n",
              "      <td id=\"T_8f626_row73_col1\" class=\"data row73 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row73_col2\" class=\"data row73 col2\" >0.911</td>\n",
              "      <td id=\"T_8f626_row73_col3\" class=\"data row73 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row73_col4\" class=\"data row73 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row74_col0\" class=\"data row74 col0\" >**PREDISPOSICION_A_COMPRAR_UN_PRODUCTO**</td>\n",
              "      <td id=\"T_8f626_row74_col1\" class=\"data row74 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row74_col2\" class=\"data row74 col2\" >0.774</td>\n",
              "      <td id=\"T_8f626_row74_col3\" class=\"data row74 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row74_col4\" class=\"data row74 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row75_col0\" class=\"data row75 col0\" >   - pred_1</td>\n",
              "      <td id=\"T_8f626_row75_col1\" class=\"data row75 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row75_col2\" class=\"data row75 col2\" >0.917</td>\n",
              "      <td id=\"T_8f626_row75_col3\" class=\"data row75 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row75_col4\" class=\"data row75 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row76_col0\" class=\"data row76 col0\" >   - pred_2</td>\n",
              "      <td id=\"T_8f626_row76_col1\" class=\"data row76 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row76_col2\" class=\"data row76 col2\" >0.872</td>\n",
              "      <td id=\"T_8f626_row76_col3\" class=\"data row76 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row76_col4\" class=\"data row76 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row77_col0\" class=\"data row77 col0\" >   - pred_3</td>\n",
              "      <td id=\"T_8f626_row77_col1\" class=\"data row77 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row77_col2\" class=\"data row77 col2\" >0.850</td>\n",
              "      <td id=\"T_8f626_row77_col3\" class=\"data row77 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row77_col4\" class=\"data row77 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row78_col0\" class=\"data row78 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_8f626_row78_col1\" class=\"data row78 col1\" >Alpha (α)</td>\n",
              "      <td id=\"T_8f626_row78_col2\" class=\"data row78 col2\" >0.831</td>\n",
              "      <td id=\"T_8f626_row78_col3\" class=\"data row78 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row78_col4\" class=\"data row78 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row79_col0\" class=\"data row79 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_8f626_row79_col1\" class=\"data row79 col1\" >CR (Fiabilidad)</td>\n",
              "      <td id=\"T_8f626_row79_col2\" class=\"data row79 col2\" >0.881</td>\n",
              "      <td id=\"T_8f626_row79_col3\" class=\"data row79 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row79_col4\" class=\"data row79 col4\" >Alta consistencia interna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row80_col0\" class=\"data row80 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_8f626_row80_col1\" class=\"data row80 col1\" >AVE (Varianza)</td>\n",
              "      <td id=\"T_8f626_row80_col2\" class=\"data row80 col2\" >0.598</td>\n",
              "      <td id=\"T_8f626_row80_col3\" class=\"data row80 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row80_col4\" class=\"data row80 col4\" >Converge satisfactoriamente (>50% varianza explicada).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row81_col0\" class=\"data row81 col0\" >   - eng_1</td>\n",
              "      <td id=\"T_8f626_row81_col1\" class=\"data row81 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row81_col2\" class=\"data row81 col2\" >0.723</td>\n",
              "      <td id=\"T_8f626_row81_col3\" class=\"data row81 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row81_col4\" class=\"data row81 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row82_col0\" class=\"data row82 col0\" >   - eng_2</td>\n",
              "      <td id=\"T_8f626_row82_col1\" class=\"data row82 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row82_col2\" class=\"data row82 col2\" >0.817</td>\n",
              "      <td id=\"T_8f626_row82_col3\" class=\"data row82 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row82_col4\" class=\"data row82 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row83_col0\" class=\"data row83 col0\" >   - eng_3</td>\n",
              "      <td id=\"T_8f626_row83_col1\" class=\"data row83 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row83_col2\" class=\"data row83 col2\" >0.711</td>\n",
              "      <td id=\"T_8f626_row83_col3\" class=\"data row83 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row83_col4\" class=\"data row83 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row84_col0\" class=\"data row84 col0\" >   - eng_4</td>\n",
              "      <td id=\"T_8f626_row84_col1\" class=\"data row84 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row84_col2\" class=\"data row84 col2\" >0.817</td>\n",
              "      <td id=\"T_8f626_row84_col3\" class=\"data row84 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row84_col4\" class=\"data row84 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_8f626_row85_col0\" class=\"data row85 col0\" >   - eng_5</td>\n",
              "      <td id=\"T_8f626_row85_col1\" class=\"data row85 col1\" >Carga (Loading)</td>\n",
              "      <td id=\"T_8f626_row85_col2\" class=\"data row85 col2\" >0.791</td>\n",
              "      <td id=\"T_8f626_row85_col3\" class=\"data row85 col3\" >Bueno</td>\n",
              "      <td id=\"T_8f626_row85_col4\" class=\"data row85 col4\" >Carga ideal (>0.708). Ítem confiable.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display\n",
        "\n",
        "# 1. Cargar datos\n",
        "# Ajusta el nombre del archivo si es necesario\n",
        "try:\n",
        "    df = pd.read_excel('datos_codificados_ajustados (1).xlsx')\n",
        "except:\n",
        "    try:\n",
        "        df = pd.read_csv('datos_codificados_ajustados (1).xlsx - Sheet1.csv')\n",
        "    except:\n",
        "        print(\"Error: Carga tu archivo de datos primero.\")\n",
        "\n",
        "# 2. Definir Constructos\n",
        "constructos = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# 3. Funciones de Cálculo\n",
        "def calculate_cronbach_alpha(itemscores):\n",
        "    itemscores = np.asarray(itemscores)\n",
        "    itemvars = itemscores.var(axis=0, ddof=1)\n",
        "    tscores = itemscores.sum(axis=1)\n",
        "    nitems = itemscores.shape[1]\n",
        "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))\n",
        "\n",
        "# 4. Funciones de Interpretación (SEGÚN TUS REGLAS EXACTAS)\n",
        "def interpretar_loading(val):\n",
        "    if val >= 0.70: return \"Ideal (≥ 0.70)\"\n",
        "    elif val >= 0.60: return \"Aceptable (Exploratoria 0.60-0.70)\"\n",
        "    else: return \"Bajo/Revisar (< 0.60)\"\n",
        "\n",
        "def interpretar_alpha(val):\n",
        "    if val >= 0.80: return \"Bueno (≥ 0.80)\"\n",
        "    elif val >= 0.70: return \"Aceptable (0.70-0.80)\"\n",
        "    else: return \"Bajo (< 0.70)\"\n",
        "\n",
        "def interpretar_cr(val):\n",
        "    if val > 0.95: return \"Posible Redundancia (> 0.95)\"\n",
        "    elif val >= 0.70: return \"Bueno/Aceptable (0.70-0.95)\"\n",
        "    else: return \"Bajo (< 0.70)\"\n",
        "\n",
        "def interpretar_ave(val):\n",
        "    if val >= 0.50: return \"Cumple (≥ 0.50)\"\n",
        "    else: return \"No Cumple (< 0.50)\"\n",
        "\n",
        "# 5. Generación del Reporte\n",
        "rows = []\n",
        "\n",
        "for construct, items in constructos.items():\n",
        "    if not all(col in df.columns for col in items): continue\n",
        "\n",
        "    # Datos del bloque\n",
        "    block = df[items].dropna()\n",
        "\n",
        "    # Cálculos Matemáticos\n",
        "    # Alpha\n",
        "    alpha = calculate_cronbach_alpha(block)\n",
        "\n",
        "    # Loadings (PCA Componente 1)\n",
        "    pca = PCA(n_components=1)\n",
        "    latent_score = pca.fit_transform(block)\n",
        "    # Corregir signo si es necesario (PCA es arbitrario en dirección)\n",
        "    correlations = [np.corrcoef(block[col], latent_score[:, 0])[0, 1] for col in items]\n",
        "    if np.sum(correlations) < 0: latent_score = -latent_score\n",
        "\n",
        "    loadings = []\n",
        "    for col in items:\n",
        "        load = np.corrcoef(block[col], latent_score[:, 0])[0, 1]\n",
        "        loadings.append(load)\n",
        "    loadings = np.array(loadings)\n",
        "\n",
        "    # AVE y CR\n",
        "    ave = np.mean(loadings**2)\n",
        "    sum_lambda = np.sum(loadings)\n",
        "    sum_lambda_sq = sum_lambda**2\n",
        "    sum_errors = np.sum(1 - loadings**2)\n",
        "    cr = sum_lambda_sq / (sum_lambda_sq + sum_errors)\n",
        "\n",
        "    # --- FILAS PARA LA TABLA ---\n",
        "    # 1. Encabezado del Constructo y sus métricas globales\n",
        "    rows.append({'Constructo / Ítem': f\"**{construct.upper()}**\", 'Métrica': 'Alfa de Cronbach (α)', 'Valor': alpha, 'Interpretación': interpretar_alpha(alpha)})\n",
        "    rows.append({'Constructo / Ítem': \"\", 'Métrica': 'Fiabilidad Compuesta (CR)', 'Valor': cr, 'Interpretación': interpretar_cr(cr)})\n",
        "    rows.append({'Constructo / Ítem': \"\", 'Métrica': 'Varianza Media (AVE)', 'Valor': ave, 'Interpretación': interpretar_ave(ave)})\n",
        "\n",
        "    # 2. Filas de los Ítems (Loadings)\n",
        "    for item, load in zip(items, loadings):\n",
        "        rows.append({'Constructo / Ítem': item, 'Métrica': 'Outer Loading', 'Valor': load, 'Interpretación': interpretar_loading(load)})\n",
        "\n",
        "# 6. Visualización\n",
        "df_resultado = pd.DataFrame(rows)\n",
        "\n",
        "# Función para colorear la tabla (Estilo Semáforo)\n",
        "def colorear_celdas(val):\n",
        "    if isinstance(val, str):\n",
        "        if \"Ideal\" in val or \"Bueno\" in val or \"Cumple\" in val:\n",
        "            return 'background-color: #d4edda; color: #155724' # Verde\n",
        "        elif \"Aceptable\" in val or \"Redundancia\" in val:\n",
        "            return 'background-color: #fff3cd; color: #856404' # Amarillo\n",
        "        elif \"Bajo\" in val or \"No Cumple\" in val:\n",
        "            return 'background-color: #f8d7da; color: #721c24' # Rojo\n",
        "    return ''\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EVALUACIÓN DEL MODELO DE MEDICIÓN (CRITERIOS PERSONALIZADOS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "display(df_resultado.style\n",
        "        .applymap(colorear_celdas, subset=['Interpretación'])\n",
        "        .format({'Valor': '{:.3f}'})\n",
        "        .hide(axis='index')\n",
        "        .set_properties(**{'text-align': 'left'})\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "dcrMj5osyI03",
        "outputId": "8440fadd-202f-498e-bc6e-75401659a50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EVALUACIÓN DEL MODELO DE MEDICIÓN (CRITERIOS PERSONALIZADOS)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3153918324.py:123: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
            "  .applymap(colorear_celdas, subset=['Interpretación'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e5dea8c3d10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_74429_row0_col0, #T_74429_row0_col1, #T_74429_row0_col2, #T_74429_row1_col0, #T_74429_row1_col1, #T_74429_row1_col2, #T_74429_row2_col0, #T_74429_row2_col1, #T_74429_row2_col2, #T_74429_row3_col0, #T_74429_row3_col1, #T_74429_row3_col2, #T_74429_row4_col0, #T_74429_row4_col1, #T_74429_row4_col2, #T_74429_row5_col0, #T_74429_row5_col1, #T_74429_row5_col2, #T_74429_row6_col0, #T_74429_row6_col1, #T_74429_row6_col2, #T_74429_row7_col0, #T_74429_row7_col1, #T_74429_row7_col2, #T_74429_row8_col0, #T_74429_row8_col1, #T_74429_row8_col2, #T_74429_row9_col0, #T_74429_row9_col1, #T_74429_row9_col2, #T_74429_row10_col0, #T_74429_row10_col1, #T_74429_row10_col2, #T_74429_row11_col0, #T_74429_row11_col1, #T_74429_row11_col2, #T_74429_row12_col0, #T_74429_row12_col1, #T_74429_row12_col2, #T_74429_row13_col0, #T_74429_row13_col1, #T_74429_row13_col2, #T_74429_row14_col0, #T_74429_row14_col1, #T_74429_row14_col2, #T_74429_row15_col0, #T_74429_row15_col1, #T_74429_row15_col2, #T_74429_row16_col0, #T_74429_row16_col1, #T_74429_row16_col2, #T_74429_row17_col0, #T_74429_row17_col1, #T_74429_row17_col2, #T_74429_row18_col0, #T_74429_row18_col1, #T_74429_row18_col2, #T_74429_row19_col0, #T_74429_row19_col1, #T_74429_row19_col2, #T_74429_row20_col0, #T_74429_row20_col1, #T_74429_row20_col2, #T_74429_row21_col0, #T_74429_row21_col1, #T_74429_row21_col2, #T_74429_row22_col0, #T_74429_row22_col1, #T_74429_row22_col2, #T_74429_row23_col0, #T_74429_row23_col1, #T_74429_row23_col2, #T_74429_row24_col0, #T_74429_row24_col1, #T_74429_row24_col2, #T_74429_row25_col0, #T_74429_row25_col1, #T_74429_row25_col2, #T_74429_row26_col0, #T_74429_row26_col1, #T_74429_row26_col2, #T_74429_row27_col0, #T_74429_row27_col1, #T_74429_row27_col2, #T_74429_row28_col0, #T_74429_row28_col1, #T_74429_row28_col2, #T_74429_row29_col0, #T_74429_row29_col1, #T_74429_row29_col2, #T_74429_row30_col0, #T_74429_row30_col1, #T_74429_row30_col2, #T_74429_row31_col0, #T_74429_row31_col1, #T_74429_row31_col2, #T_74429_row32_col0, #T_74429_row32_col1, #T_74429_row32_col2, #T_74429_row33_col0, #T_74429_row33_col1, #T_74429_row33_col2, #T_74429_row34_col0, #T_74429_row34_col1, #T_74429_row34_col2, #T_74429_row35_col0, #T_74429_row35_col1, #T_74429_row35_col2, #T_74429_row36_col0, #T_74429_row36_col1, #T_74429_row36_col2, #T_74429_row37_col0, #T_74429_row37_col1, #T_74429_row37_col2, #T_74429_row38_col0, #T_74429_row38_col1, #T_74429_row38_col2, #T_74429_row39_col0, #T_74429_row39_col1, #T_74429_row39_col2, #T_74429_row40_col0, #T_74429_row40_col1, #T_74429_row40_col2, #T_74429_row41_col0, #T_74429_row41_col1, #T_74429_row41_col2, #T_74429_row42_col0, #T_74429_row42_col1, #T_74429_row42_col2, #T_74429_row43_col0, #T_74429_row43_col1, #T_74429_row43_col2, #T_74429_row44_col0, #T_74429_row44_col1, #T_74429_row44_col2, #T_74429_row45_col0, #T_74429_row45_col1, #T_74429_row45_col2, #T_74429_row46_col0, #T_74429_row46_col1, #T_74429_row46_col2, #T_74429_row47_col0, #T_74429_row47_col1, #T_74429_row47_col2, #T_74429_row48_col0, #T_74429_row48_col1, #T_74429_row48_col2, #T_74429_row49_col0, #T_74429_row49_col1, #T_74429_row49_col2, #T_74429_row50_col0, #T_74429_row50_col1, #T_74429_row50_col2, #T_74429_row51_col0, #T_74429_row51_col1, #T_74429_row51_col2, #T_74429_row52_col0, #T_74429_row52_col1, #T_74429_row52_col2, #T_74429_row53_col0, #T_74429_row53_col1, #T_74429_row53_col2, #T_74429_row54_col0, #T_74429_row54_col1, #T_74429_row54_col2, #T_74429_row55_col0, #T_74429_row55_col1, #T_74429_row55_col2, #T_74429_row56_col0, #T_74429_row56_col1, #T_74429_row56_col2, #T_74429_row57_col0, #T_74429_row57_col1, #T_74429_row57_col2, #T_74429_row58_col0, #T_74429_row58_col1, #T_74429_row58_col2, #T_74429_row59_col0, #T_74429_row59_col1, #T_74429_row59_col2, #T_74429_row60_col0, #T_74429_row60_col1, #T_74429_row60_col2, #T_74429_row61_col0, #T_74429_row61_col1, #T_74429_row61_col2, #T_74429_row62_col0, #T_74429_row62_col1, #T_74429_row62_col2, #T_74429_row63_col0, #T_74429_row63_col1, #T_74429_row63_col2, #T_74429_row64_col0, #T_74429_row64_col1, #T_74429_row64_col2, #T_74429_row65_col0, #T_74429_row65_col1, #T_74429_row65_col2, #T_74429_row66_col0, #T_74429_row66_col1, #T_74429_row66_col2, #T_74429_row67_col0, #T_74429_row67_col1, #T_74429_row67_col2, #T_74429_row68_col0, #T_74429_row68_col1, #T_74429_row68_col2, #T_74429_row69_col0, #T_74429_row69_col1, #T_74429_row69_col2, #T_74429_row70_col0, #T_74429_row70_col1, #T_74429_row70_col2, #T_74429_row71_col0, #T_74429_row71_col1, #T_74429_row71_col2, #T_74429_row72_col0, #T_74429_row72_col1, #T_74429_row72_col2, #T_74429_row73_col0, #T_74429_row73_col1, #T_74429_row73_col2, #T_74429_row74_col0, #T_74429_row74_col1, #T_74429_row74_col2, #T_74429_row75_col0, #T_74429_row75_col1, #T_74429_row75_col2, #T_74429_row76_col0, #T_74429_row76_col1, #T_74429_row76_col2, #T_74429_row77_col0, #T_74429_row77_col1, #T_74429_row77_col2, #T_74429_row78_col0, #T_74429_row78_col1, #T_74429_row78_col2, #T_74429_row79_col0, #T_74429_row79_col1, #T_74429_row79_col2, #T_74429_row80_col0, #T_74429_row80_col1, #T_74429_row80_col2, #T_74429_row81_col0, #T_74429_row81_col1, #T_74429_row81_col2, #T_74429_row82_col0, #T_74429_row82_col1, #T_74429_row82_col2, #T_74429_row83_col0, #T_74429_row83_col1, #T_74429_row83_col2, #T_74429_row84_col0, #T_74429_row84_col1, #T_74429_row84_col2, #T_74429_row85_col0, #T_74429_row85_col1, #T_74429_row85_col2 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_74429_row0_col3, #T_74429_row1_col3, #T_74429_row2_col3, #T_74429_row3_col3, #T_74429_row4_col3, #T_74429_row5_col3, #T_74429_row6_col3, #T_74429_row7_col3, #T_74429_row8_col3, #T_74429_row9_col3, #T_74429_row10_col3, #T_74429_row11_col3, #T_74429_row12_col3, #T_74429_row13_col3, #T_74429_row14_col3, #T_74429_row15_col3, #T_74429_row16_col3, #T_74429_row17_col3, #T_74429_row18_col3, #T_74429_row19_col3, #T_74429_row20_col3, #T_74429_row21_col3, #T_74429_row22_col3, #T_74429_row23_col3, #T_74429_row24_col3, #T_74429_row25_col3, #T_74429_row26_col3, #T_74429_row27_col3, #T_74429_row28_col3, #T_74429_row29_col3, #T_74429_row30_col3, #T_74429_row31_col3, #T_74429_row32_col3, #T_74429_row33_col3, #T_74429_row34_col3, #T_74429_row35_col3, #T_74429_row36_col3, #T_74429_row37_col3, #T_74429_row38_col3, #T_74429_row39_col3, #T_74429_row40_col3, #T_74429_row41_col3, #T_74429_row42_col3, #T_74429_row43_col3, #T_74429_row44_col3, #T_74429_row45_col3, #T_74429_row46_col3, #T_74429_row47_col3, #T_74429_row48_col3, #T_74429_row49_col3, #T_74429_row50_col3, #T_74429_row51_col3, #T_74429_row52_col3, #T_74429_row53_col3, #T_74429_row54_col3, #T_74429_row55_col3, #T_74429_row56_col3, #T_74429_row57_col3, #T_74429_row58_col3, #T_74429_row59_col3, #T_74429_row60_col3, #T_74429_row61_col3, #T_74429_row62_col3, #T_74429_row63_col3, #T_74429_row64_col3, #T_74429_row65_col3, #T_74429_row66_col3, #T_74429_row67_col3, #T_74429_row68_col3, #T_74429_row69_col3, #T_74429_row70_col3, #T_74429_row71_col3, #T_74429_row72_col3, #T_74429_row73_col3, #T_74429_row74_col3, #T_74429_row75_col3, #T_74429_row76_col3, #T_74429_row77_col3, #T_74429_row78_col3, #T_74429_row79_col3, #T_74429_row80_col3, #T_74429_row81_col3, #T_74429_row82_col3, #T_74429_row83_col3, #T_74429_row84_col3, #T_74429_row85_col3 {\n",
              "  background-color: #d4edda;\n",
              "  color: #155724;\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_74429\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_74429_level0_col0\" class=\"col_heading level0 col0\" >Constructo / Ítem</th>\n",
              "      <th id=\"T_74429_level0_col1\" class=\"col_heading level0 col1\" >Métrica</th>\n",
              "      <th id=\"T_74429_level0_col2\" class=\"col_heading level0 col2\" >Valor</th>\n",
              "      <th id=\"T_74429_level0_col3\" class=\"col_heading level0 col3\" >Interpretación</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row0_col0\" class=\"data row0 col0\" >**INTEGRIDAD**</td>\n",
              "      <td id=\"T_74429_row0_col1\" class=\"data row0 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row0_col2\" class=\"data row0 col2\" >0.876</td>\n",
              "      <td id=\"T_74429_row0_col3\" class=\"data row0 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row1_col0\" class=\"data row1 col0\" ></td>\n",
              "      <td id=\"T_74429_row1_col1\" class=\"data row1 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row1_col2\" class=\"data row1 col2\" >0.915</td>\n",
              "      <td id=\"T_74429_row1_col3\" class=\"data row1 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row2_col0\" class=\"data row2 col0\" ></td>\n",
              "      <td id=\"T_74429_row2_col1\" class=\"data row2 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row2_col2\" class=\"data row2 col2\" >0.729</td>\n",
              "      <td id=\"T_74429_row2_col3\" class=\"data row2 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row3_col0\" class=\"data row3 col0\" >int_1</td>\n",
              "      <td id=\"T_74429_row3_col1\" class=\"data row3 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row3_col2\" class=\"data row3 col2\" >0.879</td>\n",
              "      <td id=\"T_74429_row3_col3\" class=\"data row3 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row4_col0\" class=\"data row4 col0\" >int_2</td>\n",
              "      <td id=\"T_74429_row4_col1\" class=\"data row4 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row4_col2\" class=\"data row4 col2\" >0.864</td>\n",
              "      <td id=\"T_74429_row4_col3\" class=\"data row4 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row5_col0\" class=\"data row5 col0\" >int_3</td>\n",
              "      <td id=\"T_74429_row5_col1\" class=\"data row5 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row5_col2\" class=\"data row5 col2\" >0.827</td>\n",
              "      <td id=\"T_74429_row5_col3\" class=\"data row5 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row6_col0\" class=\"data row6 col0\" >int_4</td>\n",
              "      <td id=\"T_74429_row6_col1\" class=\"data row6 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row6_col2\" class=\"data row6 col2\" >0.846</td>\n",
              "      <td id=\"T_74429_row6_col3\" class=\"data row6 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row7_col0\" class=\"data row7 col0\" >**EXPERTIS**</td>\n",
              "      <td id=\"T_74429_row7_col1\" class=\"data row7 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row7_col2\" class=\"data row7 col2\" >0.813</td>\n",
              "      <td id=\"T_74429_row7_col3\" class=\"data row7 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row8_col0\" class=\"data row8 col0\" ></td>\n",
              "      <td id=\"T_74429_row8_col1\" class=\"data row8 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row8_col2\" class=\"data row8 col2\" >0.877</td>\n",
              "      <td id=\"T_74429_row8_col3\" class=\"data row8 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row9_col0\" class=\"data row9 col0\" ></td>\n",
              "      <td id=\"T_74429_row9_col1\" class=\"data row9 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row9_col2\" class=\"data row9 col2\" >0.642</td>\n",
              "      <td id=\"T_74429_row9_col3\" class=\"data row9 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row10_col0\" class=\"data row10 col0\" >exp_1</td>\n",
              "      <td id=\"T_74429_row10_col1\" class=\"data row10 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row10_col2\" class=\"data row10 col2\" >0.823</td>\n",
              "      <td id=\"T_74429_row10_col3\" class=\"data row10 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row11_col0\" class=\"data row11 col0\" >exp_2</td>\n",
              "      <td id=\"T_74429_row11_col1\" class=\"data row11 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row11_col2\" class=\"data row11 col2\" >0.796</td>\n",
              "      <td id=\"T_74429_row11_col3\" class=\"data row11 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row12_col0\" class=\"data row12 col0\" >exp_3</td>\n",
              "      <td id=\"T_74429_row12_col1\" class=\"data row12 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row12_col2\" class=\"data row12 col2\" >0.813</td>\n",
              "      <td id=\"T_74429_row12_col3\" class=\"data row12 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row13_col0\" class=\"data row13 col0\" >exp_4</td>\n",
              "      <td id=\"T_74429_row13_col1\" class=\"data row13 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row13_col2\" class=\"data row13 col2\" >0.771</td>\n",
              "      <td id=\"T_74429_row13_col3\" class=\"data row13 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row14_col0\" class=\"data row14 col0\" >**AUTENTICIDAD**</td>\n",
              "      <td id=\"T_74429_row14_col1\" class=\"data row14 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row14_col2\" class=\"data row14 col2\" >0.846</td>\n",
              "      <td id=\"T_74429_row14_col3\" class=\"data row14 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row15_col0\" class=\"data row15 col0\" ></td>\n",
              "      <td id=\"T_74429_row15_col1\" class=\"data row15 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row15_col2\" class=\"data row15 col2\" >0.907</td>\n",
              "      <td id=\"T_74429_row15_col3\" class=\"data row15 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row16_col0\" class=\"data row16 col0\" ></td>\n",
              "      <td id=\"T_74429_row16_col1\" class=\"data row16 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row16_col2\" class=\"data row16 col2\" >0.765</td>\n",
              "      <td id=\"T_74429_row16_col3\" class=\"data row16 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row17_col0\" class=\"data row17 col0\" >aut_1</td>\n",
              "      <td id=\"T_74429_row17_col1\" class=\"data row17 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row17_col2\" class=\"data row17 col2\" >0.848</td>\n",
              "      <td id=\"T_74429_row17_col3\" class=\"data row17 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row18_col0\" class=\"data row18 col0\" >aut_2</td>\n",
              "      <td id=\"T_74429_row18_col1\" class=\"data row18 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row18_col2\" class=\"data row18 col2\" >0.902</td>\n",
              "      <td id=\"T_74429_row18_col3\" class=\"data row18 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row19_col0\" class=\"data row19 col0\" >aut_3</td>\n",
              "      <td id=\"T_74429_row19_col1\" class=\"data row19 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row19_col2\" class=\"data row19 col2\" >0.873</td>\n",
              "      <td id=\"T_74429_row19_col3\" class=\"data row19 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row20_col0\" class=\"data row20 col0\" >**ATRACTIVIDAD**</td>\n",
              "      <td id=\"T_74429_row20_col1\" class=\"data row20 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row20_col2\" class=\"data row20 col2\" >0.883</td>\n",
              "      <td id=\"T_74429_row20_col3\" class=\"data row20 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row21_col0\" class=\"data row21 col0\" ></td>\n",
              "      <td id=\"T_74429_row21_col1\" class=\"data row21 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row21_col2\" class=\"data row21 col2\" >0.919</td>\n",
              "      <td id=\"T_74429_row21_col3\" class=\"data row21 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row22_col0\" class=\"data row22 col0\" ></td>\n",
              "      <td id=\"T_74429_row22_col1\" class=\"data row22 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row22_col2\" class=\"data row22 col2\" >0.741</td>\n",
              "      <td id=\"T_74429_row22_col3\" class=\"data row22 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row23_col0\" class=\"data row23 col0\" >att_1</td>\n",
              "      <td id=\"T_74429_row23_col1\" class=\"data row23 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row23_col2\" class=\"data row23 col2\" >0.852</td>\n",
              "      <td id=\"T_74429_row23_col3\" class=\"data row23 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row24_col0\" class=\"data row24 col0\" >att_2</td>\n",
              "      <td id=\"T_74429_row24_col1\" class=\"data row24 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row24_col2\" class=\"data row24 col2\" >0.849</td>\n",
              "      <td id=\"T_74429_row24_col3\" class=\"data row24 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row25_col0\" class=\"data row25 col0\" >att_3</td>\n",
              "      <td id=\"T_74429_row25_col1\" class=\"data row25 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row25_col2\" class=\"data row25 col2\" >0.861</td>\n",
              "      <td id=\"T_74429_row25_col3\" class=\"data row25 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row26_col0\" class=\"data row26 col0\" >att_4</td>\n",
              "      <td id=\"T_74429_row26_col1\" class=\"data row26 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row26_col2\" class=\"data row26 col2\" >0.880</td>\n",
              "      <td id=\"T_74429_row26_col3\" class=\"data row26 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row27_col0\" class=\"data row27 col0\" >**SIMILITUD**</td>\n",
              "      <td id=\"T_74429_row27_col1\" class=\"data row27 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row27_col2\" class=\"data row27 col2\" >0.875</td>\n",
              "      <td id=\"T_74429_row27_col3\" class=\"data row27 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row28_col0\" class=\"data row28 col0\" ></td>\n",
              "      <td id=\"T_74429_row28_col1\" class=\"data row28 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row28_col2\" class=\"data row28 col2\" >0.924</td>\n",
              "      <td id=\"T_74429_row28_col3\" class=\"data row28 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row29_col0\" class=\"data row29 col0\" ></td>\n",
              "      <td id=\"T_74429_row29_col1\" class=\"data row29 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row29_col2\" class=\"data row29 col2\" >0.801</td>\n",
              "      <td id=\"T_74429_row29_col3\" class=\"data row29 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row30_col0\" class=\"data row30 col0\" >sim_1</td>\n",
              "      <td id=\"T_74429_row30_col1\" class=\"data row30 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row30_col2\" class=\"data row30 col2\" >0.858</td>\n",
              "      <td id=\"T_74429_row30_col3\" class=\"data row30 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row31_col0\" class=\"data row31 col0\" >sim_2</td>\n",
              "      <td id=\"T_74429_row31_col1\" class=\"data row31 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row31_col2\" class=\"data row31 col2\" >0.923</td>\n",
              "      <td id=\"T_74429_row31_col3\" class=\"data row31 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row32_col0\" class=\"data row32 col0\" >sim_3</td>\n",
              "      <td id=\"T_74429_row32_col1\" class=\"data row32 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row32_col2\" class=\"data row32 col2\" >0.903</td>\n",
              "      <td id=\"T_74429_row32_col3\" class=\"data row32 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row33_col0\" class=\"data row33 col0\" >**LIDER_DE_OPINION**</td>\n",
              "      <td id=\"T_74429_row33_col1\" class=\"data row33 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row33_col2\" class=\"data row33 col2\" >0.878</td>\n",
              "      <td id=\"T_74429_row33_col3\" class=\"data row33 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row34_col0\" class=\"data row34 col0\" ></td>\n",
              "      <td id=\"T_74429_row34_col1\" class=\"data row34 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row34_col2\" class=\"data row34 col2\" >0.916</td>\n",
              "      <td id=\"T_74429_row34_col3\" class=\"data row34 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row35_col0\" class=\"data row35 col0\" ></td>\n",
              "      <td id=\"T_74429_row35_col1\" class=\"data row35 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row35_col2\" class=\"data row35 col2\" >0.732</td>\n",
              "      <td id=\"T_74429_row35_col3\" class=\"data row35 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row36_col0\" class=\"data row36 col0\" >lid_1</td>\n",
              "      <td id=\"T_74429_row36_col1\" class=\"data row36 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row36_col2\" class=\"data row36 col2\" >0.856</td>\n",
              "      <td id=\"T_74429_row36_col3\" class=\"data row36 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row37_col0\" class=\"data row37 col0\" >lid_2</td>\n",
              "      <td id=\"T_74429_row37_col1\" class=\"data row37 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row37_col2\" class=\"data row37 col2\" >0.813</td>\n",
              "      <td id=\"T_74429_row37_col3\" class=\"data row37 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row38_col0\" class=\"data row38 col0\" >lid_3</td>\n",
              "      <td id=\"T_74429_row38_col1\" class=\"data row38 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row38_col2\" class=\"data row38 col2\" >0.871</td>\n",
              "      <td id=\"T_74429_row38_col3\" class=\"data row38 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row39_col0\" class=\"data row39 col0\" >lid_4</td>\n",
              "      <td id=\"T_74429_row39_col1\" class=\"data row39 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row39_col2\" class=\"data row39 col2\" >0.882</td>\n",
              "      <td id=\"T_74429_row39_col3\" class=\"data row39 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row40_col0\" class=\"data row40 col0\" >**INFORMATIVIDAD_DEL_CONTENIDO**</td>\n",
              "      <td id=\"T_74429_row40_col1\" class=\"data row40 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row40_col2\" class=\"data row40 col2\" >0.843</td>\n",
              "      <td id=\"T_74429_row40_col3\" class=\"data row40 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row41_col0\" class=\"data row41 col0\" ></td>\n",
              "      <td id=\"T_74429_row41_col1\" class=\"data row41 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row41_col2\" class=\"data row41 col2\" >0.905</td>\n",
              "      <td id=\"T_74429_row41_col3\" class=\"data row41 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row42_col0\" class=\"data row42 col0\" ></td>\n",
              "      <td id=\"T_74429_row42_col1\" class=\"data row42 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row42_col2\" class=\"data row42 col2\" >0.761</td>\n",
              "      <td id=\"T_74429_row42_col3\" class=\"data row42 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row43_col0\" class=\"data row43 col0\" >inf_1</td>\n",
              "      <td id=\"T_74429_row43_col1\" class=\"data row43 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row43_col2\" class=\"data row43 col2\" >0.919</td>\n",
              "      <td id=\"T_74429_row43_col3\" class=\"data row43 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row44_col0\" class=\"data row44 col0\" >inf_2</td>\n",
              "      <td id=\"T_74429_row44_col1\" class=\"data row44 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row44_col2\" class=\"data row44 col2\" >0.875</td>\n",
              "      <td id=\"T_74429_row44_col3\" class=\"data row44 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row45_col0\" class=\"data row45 col0\" >inf_3</td>\n",
              "      <td id=\"T_74429_row45_col1\" class=\"data row45 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row45_col2\" class=\"data row45 col2\" >0.820</td>\n",
              "      <td id=\"T_74429_row45_col3\" class=\"data row45 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row46_col0\" class=\"data row46 col0\" >**CONGRUENCIA_INFLUENCER_FOLLOWER**</td>\n",
              "      <td id=\"T_74429_row46_col1\" class=\"data row46 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row46_col2\" class=\"data row46 col2\" >0.847</td>\n",
              "      <td id=\"T_74429_row46_col3\" class=\"data row46 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row47_col0\" class=\"data row47 col0\" ></td>\n",
              "      <td id=\"T_74429_row47_col1\" class=\"data row47 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row47_col2\" class=\"data row47 col2\" >0.907</td>\n",
              "      <td id=\"T_74429_row47_col3\" class=\"data row47 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row48_col0\" class=\"data row48 col0\" ></td>\n",
              "      <td id=\"T_74429_row48_col1\" class=\"data row48 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row48_col2\" class=\"data row48 col2\" >0.766</td>\n",
              "      <td id=\"T_74429_row48_col3\" class=\"data row48 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row49_col0\" class=\"data row49 col0\" >congf_1</td>\n",
              "      <td id=\"T_74429_row49_col1\" class=\"data row49 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row49_col2\" class=\"data row49 col2\" >0.931</td>\n",
              "      <td id=\"T_74429_row49_col3\" class=\"data row49 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row50_col0\" class=\"data row50 col0\" >congf_2</td>\n",
              "      <td id=\"T_74429_row50_col1\" class=\"data row50 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row50_col2\" class=\"data row50 col2\" >0.851</td>\n",
              "      <td id=\"T_74429_row50_col3\" class=\"data row50 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row51_col0\" class=\"data row51 col0\" >congf_3</td>\n",
              "      <td id=\"T_74429_row51_col1\" class=\"data row51 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row51_col2\" class=\"data row51 col2\" >0.840</td>\n",
              "      <td id=\"T_74429_row51_col3\" class=\"data row51 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row52_col0\" class=\"data row52 col0\" >**CONGRUENCIA_INFLUENCER_PRODUCTO**</td>\n",
              "      <td id=\"T_74429_row52_col1\" class=\"data row52 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row52_col2\" class=\"data row52 col2\" >0.850</td>\n",
              "      <td id=\"T_74429_row52_col3\" class=\"data row52 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row53_col0\" class=\"data row53 col0\" ></td>\n",
              "      <td id=\"T_74429_row53_col1\" class=\"data row53 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row53_col2\" class=\"data row53 col2\" >0.910</td>\n",
              "      <td id=\"T_74429_row53_col3\" class=\"data row53 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row54_col0\" class=\"data row54 col0\" ></td>\n",
              "      <td id=\"T_74429_row54_col1\" class=\"data row54 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row54_col2\" class=\"data row54 col2\" >0.771</td>\n",
              "      <td id=\"T_74429_row54_col3\" class=\"data row54 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row55_col0\" class=\"data row55 col0\" >congp_1</td>\n",
              "      <td id=\"T_74429_row55_col1\" class=\"data row55 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row55_col2\" class=\"data row55 col2\" >0.894</td>\n",
              "      <td id=\"T_74429_row55_col3\" class=\"data row55 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row56_col0\" class=\"data row56 col0\" >congp_2</td>\n",
              "      <td id=\"T_74429_row56_col1\" class=\"data row56 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row56_col2\" class=\"data row56 col2\" >0.883</td>\n",
              "      <td id=\"T_74429_row56_col3\" class=\"data row56 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row57_col0\" class=\"data row57 col0\" >congp_3</td>\n",
              "      <td id=\"T_74429_row57_col1\" class=\"data row57 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row57_col2\" class=\"data row57 col2\" >0.857</td>\n",
              "      <td id=\"T_74429_row57_col3\" class=\"data row57 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row58_col0\" class=\"data row58 col0\" >**CONCIENCIA_DE_LA_PERSUASION**</td>\n",
              "      <td id=\"T_74429_row58_col1\" class=\"data row58 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row58_col2\" class=\"data row58 col2\" >0.853</td>\n",
              "      <td id=\"T_74429_row58_col3\" class=\"data row58 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row59_col0\" class=\"data row59 col0\" ></td>\n",
              "      <td id=\"T_74429_row59_col1\" class=\"data row59 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row59_col2\" class=\"data row59 col2\" >0.895</td>\n",
              "      <td id=\"T_74429_row59_col3\" class=\"data row59 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row60_col0\" class=\"data row60 col0\" ></td>\n",
              "      <td id=\"T_74429_row60_col1\" class=\"data row60 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row60_col2\" class=\"data row60 col2\" >0.630</td>\n",
              "      <td id=\"T_74429_row60_col3\" class=\"data row60 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row61_col0\" class=\"data row61 col0\" >concp_1</td>\n",
              "      <td id=\"T_74429_row61_col1\" class=\"data row61 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row61_col2\" class=\"data row61 col2\" >0.883</td>\n",
              "      <td id=\"T_74429_row61_col3\" class=\"data row61 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row62_col0\" class=\"data row62 col0\" >concp_2</td>\n",
              "      <td id=\"T_74429_row62_col1\" class=\"data row62 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row62_col2\" class=\"data row62 col2\" >0.844</td>\n",
              "      <td id=\"T_74429_row62_col3\" class=\"data row62 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row63_col0\" class=\"data row63 col0\" >concp_3</td>\n",
              "      <td id=\"T_74429_row63_col1\" class=\"data row63 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row63_col2\" class=\"data row63 col2\" >0.750</td>\n",
              "      <td id=\"T_74429_row63_col3\" class=\"data row63 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row64_col0\" class=\"data row64 col0\" >concp_4</td>\n",
              "      <td id=\"T_74429_row64_col1\" class=\"data row64 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row64_col2\" class=\"data row64 col2\" >0.735</td>\n",
              "      <td id=\"T_74429_row64_col3\" class=\"data row64 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row65_col0\" class=\"data row65 col0\" >concp_5</td>\n",
              "      <td id=\"T_74429_row65_col1\" class=\"data row65 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row65_col2\" class=\"data row65 col2\" >0.747</td>\n",
              "      <td id=\"T_74429_row65_col3\" class=\"data row65 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row66_col0\" class=\"data row66 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_74429_row66_col1\" class=\"data row66 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row66_col2\" class=\"data row66 col2\" >0.845</td>\n",
              "      <td id=\"T_74429_row66_col3\" class=\"data row66 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row67_col0\" class=\"data row67 col0\" ></td>\n",
              "      <td id=\"T_74429_row67_col1\" class=\"data row67 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row67_col2\" class=\"data row67 col2\" >0.906</td>\n",
              "      <td id=\"T_74429_row67_col3\" class=\"data row67 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row68_col0\" class=\"data row68 col0\" ></td>\n",
              "      <td id=\"T_74429_row68_col1\" class=\"data row68 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row68_col2\" class=\"data row68 col2\" >0.764</td>\n",
              "      <td id=\"T_74429_row68_col3\" class=\"data row68 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row69_col0\" class=\"data row69 col0\" >act_1</td>\n",
              "      <td id=\"T_74429_row69_col1\" class=\"data row69 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row69_col2\" class=\"data row69 col2\" >0.883</td>\n",
              "      <td id=\"T_74429_row69_col3\" class=\"data row69 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row70_col0\" class=\"data row70 col0\" >act_2</td>\n",
              "      <td id=\"T_74429_row70_col1\" class=\"data row70 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row70_col2\" class=\"data row70 col2\" >0.833</td>\n",
              "      <td id=\"T_74429_row70_col3\" class=\"data row70 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row71_col0\" class=\"data row71 col0\" >act_3</td>\n",
              "      <td id=\"T_74429_row71_col1\" class=\"data row71 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row71_col2\" class=\"data row71 col2\" >0.905</td>\n",
              "      <td id=\"T_74429_row71_col3\" class=\"data row71 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row72_col0\" class=\"data row72 col0\" >**PREDISPOSICION_A_COMPRAR_UN_PRODUCTO**</td>\n",
              "      <td id=\"T_74429_row72_col1\" class=\"data row72 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row72_col2\" class=\"data row72 col2\" >0.854</td>\n",
              "      <td id=\"T_74429_row72_col3\" class=\"data row72 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row73_col0\" class=\"data row73 col0\" ></td>\n",
              "      <td id=\"T_74429_row73_col1\" class=\"data row73 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row73_col2\" class=\"data row73 col2\" >0.911</td>\n",
              "      <td id=\"T_74429_row73_col3\" class=\"data row73 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row74_col0\" class=\"data row74 col0\" ></td>\n",
              "      <td id=\"T_74429_row74_col1\" class=\"data row74 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row74_col2\" class=\"data row74 col2\" >0.774</td>\n",
              "      <td id=\"T_74429_row74_col3\" class=\"data row74 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row75_col0\" class=\"data row75 col0\" >pred_1</td>\n",
              "      <td id=\"T_74429_row75_col1\" class=\"data row75 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row75_col2\" class=\"data row75 col2\" >0.917</td>\n",
              "      <td id=\"T_74429_row75_col3\" class=\"data row75 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row76_col0\" class=\"data row76 col0\" >pred_2</td>\n",
              "      <td id=\"T_74429_row76_col1\" class=\"data row76 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row76_col2\" class=\"data row76 col2\" >0.872</td>\n",
              "      <td id=\"T_74429_row76_col3\" class=\"data row76 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row77_col0\" class=\"data row77 col0\" >pred_3</td>\n",
              "      <td id=\"T_74429_row77_col1\" class=\"data row77 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row77_col2\" class=\"data row77 col2\" >0.850</td>\n",
              "      <td id=\"T_74429_row77_col3\" class=\"data row77 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row78_col0\" class=\"data row78 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_74429_row78_col1\" class=\"data row78 col1\" >Alfa de Cronbach (α)</td>\n",
              "      <td id=\"T_74429_row78_col2\" class=\"data row78 col2\" >0.831</td>\n",
              "      <td id=\"T_74429_row78_col3\" class=\"data row78 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row79_col0\" class=\"data row79 col0\" ></td>\n",
              "      <td id=\"T_74429_row79_col1\" class=\"data row79 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_74429_row79_col2\" class=\"data row79 col2\" >0.881</td>\n",
              "      <td id=\"T_74429_row79_col3\" class=\"data row79 col3\" >Bueno/Aceptable (0.70-0.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row80_col0\" class=\"data row80 col0\" ></td>\n",
              "      <td id=\"T_74429_row80_col1\" class=\"data row80 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_74429_row80_col2\" class=\"data row80 col2\" >0.598</td>\n",
              "      <td id=\"T_74429_row80_col3\" class=\"data row80 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row81_col0\" class=\"data row81 col0\" >eng_1</td>\n",
              "      <td id=\"T_74429_row81_col1\" class=\"data row81 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row81_col2\" class=\"data row81 col2\" >0.723</td>\n",
              "      <td id=\"T_74429_row81_col3\" class=\"data row81 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row82_col0\" class=\"data row82 col0\" >eng_2</td>\n",
              "      <td id=\"T_74429_row82_col1\" class=\"data row82 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row82_col2\" class=\"data row82 col2\" >0.817</td>\n",
              "      <td id=\"T_74429_row82_col3\" class=\"data row82 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row83_col0\" class=\"data row83 col0\" >eng_3</td>\n",
              "      <td id=\"T_74429_row83_col1\" class=\"data row83 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row83_col2\" class=\"data row83 col2\" >0.711</td>\n",
              "      <td id=\"T_74429_row83_col3\" class=\"data row83 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row84_col0\" class=\"data row84 col0\" >eng_4</td>\n",
              "      <td id=\"T_74429_row84_col1\" class=\"data row84 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row84_col2\" class=\"data row84 col2\" >0.817</td>\n",
              "      <td id=\"T_74429_row84_col3\" class=\"data row84 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_74429_row85_col0\" class=\"data row85 col0\" >eng_5</td>\n",
              "      <td id=\"T_74429_row85_col1\" class=\"data row85 col1\" >Outer Loading</td>\n",
              "      <td id=\"T_74429_row85_col2\" class=\"data row85 col2\" >0.791</td>\n",
              "      <td id=\"T_74429_row85_col3\" class=\"data row85 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading, CR y AVE  \n",
        "Constructos de primer y segundo orden"
      ],
      "metadata": {
        "id": "pHqLU34Tl3k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tu diccionario base (Primer Orden)\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# 2. Creación del Diccionario de Segundo Orden\n",
        "# Unimos las listas de ítems de los constructos hijos para formar el padre\n",
        "constructos_2do_orden = {\n",
        "    # --- Nuevos Constructos Agrupados ---\n",
        "    \n",
        "    # 1) Credibilidad = Integridad + Expertis + Autenticidad\n",
        "    'Credibilidad': (constructos_1er_orden['integridad'] +\n",
        "                     constructos_1er_orden['expertis'] +\n",
        "                     constructos_1er_orden['autenticidad']),\n",
        "\n",
        "    # 2) Semejanza = Atractividad + Similitud\n",
        "    'Semejanza': (constructos_1er_orden['atractividad'] +\n",
        "                  constructos_1er_orden['similitud']),\n",
        "\n",
        "    # 3) Flujo de información = Líder de opinión + Informatividad\n",
        "    'Flujo_de_informacion': (constructos_1er_orden['lider_de_opinion'] +\n",
        "                             constructos_1er_orden['informatividad_del_contenido']),\n",
        "\n",
        "    # 4) Congruencia = Congruencia I-F + Congruencia I-P\n",
        "    'Congruencia': (constructos_1er_orden['congruencia_influencer_follower'] +\n",
        "                    constructos_1er_orden['congruencia_influencer_producto']),\n",
        "\n",
        "    # --- Constructos que mantienen su nombre original ---\n",
        "    'conciencia_de_la_persuasion': constructos_1er_orden['conciencia_de_la_persuasion'],\n",
        "    'actitud': constructos_1er_orden['actitud'],\n",
        "    'predisposicion_a_comprar_un_producto': constructos_1er_orden['predisposicion_a_comprar_un_producto'],\n",
        "    'engagement': constructos_1er_orden['engagement']\n",
        "}"
      ],
      "metadata": {
        "id": "vUFGDnOqvquj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. CARGA DE DATOS\n",
        "# -----------------------------------------------------------------------------\n",
        "try:\n",
        "    df = pd.read_excel('datos_codificados_ajustados (1).xlsx')\n",
        "except:\n",
        "    try:\n",
        "        df = pd.read_csv('datos_codificados_ajustados (1).xlsx - Sheet1.csv')\n",
        "    except:\n",
        "        print(\"Error: Asegúrate de haber subido el archivo de datos.\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. DEFINICIÓN DE CONSTRUCTOS\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# A) Constructos de Primer Orden (Base)\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# B) Constructos de Segundo Orden (Agrupación para Análisis)\n",
        "constructos_2do_orden = {\n",
        "    # Agrupados\n",
        "    'Credibilidad': (constructos_1er_orden['integridad'] +\n",
        "                     constructos_1er_orden['expertis'] +\n",
        "                     constructos_1er_orden['autenticidad']),\n",
        "\n",
        "    'Semejanza': (constructos_1er_orden['atractividad'] +\n",
        "                  constructos_1er_orden['similitud']),\n",
        "\n",
        "    'Flujo_de_informacion': (constructos_1er_orden['lider_de_opinion'] +\n",
        "                             constructos_1er_orden['informatividad_del_contenido']),\n",
        "\n",
        "    'Congruencia': (constructos_1er_orden['congruencia_influencer_follower'] +\n",
        "                    constructos_1er_orden['congruencia_influencer_producto']),\n",
        "\n",
        "    # Mantenidos\n",
        "    'Conciencia_de_la_persuasion': constructos_1er_orden['conciencia_de_la_persuasion'],\n",
        "    'Actitud': constructos_1er_orden['actitud'],\n",
        "    'Predisposicion_compra': constructos_1er_orden['predisposicion_a_comprar_un_producto'],\n",
        "    'Engagement': constructos_1er_orden['engagement']\n",
        "}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. FUNCIONES DE CÁLCULO\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_cronbach_alpha(itemscores):\n",
        "    itemscores = np.asarray(itemscores)\n",
        "    itemvars = itemscores.var(axis=0, ddof=1)\n",
        "    tscores = itemscores.sum(axis=1)\n",
        "    nitems = itemscores.shape[1]\n",
        "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. PROCESAMIENTO Y GENERACIÓN DE TABLA\n",
        "# -----------------------------------------------------------------------------\n",
        "output_rows = []\n",
        "\n",
        "for construct, items in constructos_2do_orden.items():\n",
        "    # Validar que existan las columnas\n",
        "    valid_items = [col for col in items if col in df.columns]\n",
        "    if not valid_items:\n",
        "        continue\n",
        "\n",
        "    # Extraer datos sin nulos para este bloque\n",
        "    block = df[valid_items].dropna()\n",
        "\n",
        "    if block.empty: continue\n",
        "\n",
        "    # A) Alfa de Cronbach\n",
        "    alpha = calculate_cronbach_alpha(block)\n",
        "\n",
        "    # B) PCA para obtener Loadings (Modelo Reflectivo)\n",
        "    pca = PCA(n_components=1)\n",
        "    latent_score = pca.fit_transform(block)\n",
        "\n",
        "    # Calcular correlaciones (Loadings)\n",
        "    loadings = []\n",
        "    for col in valid_items:\n",
        "        corr = np.corrcoef(block[col], latent_score[:, 0])[0, 1]\n",
        "        loadings.append(corr)\n",
        "    loadings = np.array(loadings)\n",
        "\n",
        "    # Ajuste de signo (si la mayoría son negativos, invertimos)\n",
        "    if np.mean(loadings) < 0:\n",
        "        loadings = -loadings\n",
        "\n",
        "    # C) AVE (Average Variance Extracted)\n",
        "    ave = np.mean(loadings**2)\n",
        "\n",
        "    # D) CR (Composite Reliability)\n",
        "    sum_lambda_sq = np.sum(loadings)**2\n",
        "    sum_error = np.sum(1 - loadings**2)\n",
        "    cr = sum_lambda_sq / (sum_lambda_sq + sum_error)\n",
        "\n",
        "    # --- AGREGAR A LA TABLA ---\n",
        "\n",
        "    # 1. Fila de Encabezado del Constructo (Con métricas globales)\n",
        "    output_rows.append({\n",
        "        'Constructo / Ítem': f\"**{construct.upper()}**\",\n",
        "        'Loading': \"\",  # Vacio en la fila del título\n",
        "        'α (Cronbach)': f\"{alpha:.3f}\",\n",
        "        'CR (Fiabilidad)': f\"{cr:.3f}\",\n",
        "        'AVE': f\"{ave:.3f}\"\n",
        "    })\n",
        "\n",
        "    # 2. Filas de los Ítems individuales\n",
        "    for item_name, val in zip(valid_items, loadings):\n",
        "        output_rows.append({\n",
        "            'Constructo / Ítem': f\"   {item_name}\",\n",
        "            'Loading': f\"{val:.3f}\",\n",
        "            'α (Cronbach)': \"\",\n",
        "            'CR (Fiabilidad)': \"\",\n",
        "            'AVE': \"\"\n",
        "        })\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. VISUALIZACIÓN\n",
        "# -----------------------------------------------------------------------------\n",
        "df_resultado = pd.DataFrame(output_rows)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EVALUACIÓN DEL MODELO DE MEDICIÓN (CONSTRUCTOS DE 2DO ORDEN)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Estilizar la tabla para mejor lectura (negrita en constructos, alineación)\n",
        "def highlight_constructs(s):\n",
        "    return ['font-weight: bold; background-color: #f0f0f0' if \"**\" in str(val) else '' for val in s]\n",
        "\n",
        "display(df_resultado.style\n",
        "    .set_properties(**{'text-align': 'left'})\n",
        "    .hide(axis='index')\n",
        ")\n",
        "\n",
        "# Opcional: Guardar en Excel\n",
        "# df_resultado.to_excel(\"Analisis_2do_Orden.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uFa2GIJ84JTv",
        "outputId": "71ea35bb-3122-40a3-d466-f853084eb02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EVALUACIÓN DEL MODELO DE MEDICIÓN (CONSTRUCTOS DE 2DO ORDEN)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79727d18bb90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_47630_row0_col0, #T_47630_row0_col1, #T_47630_row0_col2, #T_47630_row0_col3, #T_47630_row0_col4, #T_47630_row1_col0, #T_47630_row1_col1, #T_47630_row1_col2, #T_47630_row1_col3, #T_47630_row1_col4, #T_47630_row2_col0, #T_47630_row2_col1, #T_47630_row2_col2, #T_47630_row2_col3, #T_47630_row2_col4, #T_47630_row3_col0, #T_47630_row3_col1, #T_47630_row3_col2, #T_47630_row3_col3, #T_47630_row3_col4, #T_47630_row4_col0, #T_47630_row4_col1, #T_47630_row4_col2, #T_47630_row4_col3, #T_47630_row4_col4, #T_47630_row5_col0, #T_47630_row5_col1, #T_47630_row5_col2, #T_47630_row5_col3, #T_47630_row5_col4, #T_47630_row6_col0, #T_47630_row6_col1, #T_47630_row6_col2, #T_47630_row6_col3, #T_47630_row6_col4, #T_47630_row7_col0, #T_47630_row7_col1, #T_47630_row7_col2, #T_47630_row7_col3, #T_47630_row7_col4, #T_47630_row8_col0, #T_47630_row8_col1, #T_47630_row8_col2, #T_47630_row8_col3, #T_47630_row8_col4, #T_47630_row9_col0, #T_47630_row9_col1, #T_47630_row9_col2, #T_47630_row9_col3, #T_47630_row9_col4, #T_47630_row10_col0, #T_47630_row10_col1, #T_47630_row10_col2, #T_47630_row10_col3, #T_47630_row10_col4, #T_47630_row11_col0, #T_47630_row11_col1, #T_47630_row11_col2, #T_47630_row11_col3, #T_47630_row11_col4, #T_47630_row12_col0, #T_47630_row12_col1, #T_47630_row12_col2, #T_47630_row12_col3, #T_47630_row12_col4, #T_47630_row13_col0, #T_47630_row13_col1, #T_47630_row13_col2, #T_47630_row13_col3, #T_47630_row13_col4, #T_47630_row14_col0, #T_47630_row14_col1, #T_47630_row14_col2, #T_47630_row14_col3, #T_47630_row14_col4, #T_47630_row15_col0, #T_47630_row15_col1, #T_47630_row15_col2, #T_47630_row15_col3, #T_47630_row15_col4, #T_47630_row16_col0, #T_47630_row16_col1, #T_47630_row16_col2, #T_47630_row16_col3, #T_47630_row16_col4, #T_47630_row17_col0, #T_47630_row17_col1, #T_47630_row17_col2, #T_47630_row17_col3, #T_47630_row17_col4, #T_47630_row18_col0, #T_47630_row18_col1, #T_47630_row18_col2, #T_47630_row18_col3, #T_47630_row18_col4, #T_47630_row19_col0, #T_47630_row19_col1, #T_47630_row19_col2, #T_47630_row19_col3, #T_47630_row19_col4, #T_47630_row20_col0, #T_47630_row20_col1, #T_47630_row20_col2, #T_47630_row20_col3, #T_47630_row20_col4, #T_47630_row21_col0, #T_47630_row21_col1, #T_47630_row21_col2, #T_47630_row21_col3, #T_47630_row21_col4, #T_47630_row22_col0, #T_47630_row22_col1, #T_47630_row22_col2, #T_47630_row22_col3, #T_47630_row22_col4, #T_47630_row23_col0, #T_47630_row23_col1, #T_47630_row23_col2, #T_47630_row23_col3, #T_47630_row23_col4, #T_47630_row24_col0, #T_47630_row24_col1, #T_47630_row24_col2, #T_47630_row24_col3, #T_47630_row24_col4, #T_47630_row25_col0, #T_47630_row25_col1, #T_47630_row25_col2, #T_47630_row25_col3, #T_47630_row25_col4, #T_47630_row26_col0, #T_47630_row26_col1, #T_47630_row26_col2, #T_47630_row26_col3, #T_47630_row26_col4, #T_47630_row27_col0, #T_47630_row27_col1, #T_47630_row27_col2, #T_47630_row27_col3, #T_47630_row27_col4, #T_47630_row28_col0, #T_47630_row28_col1, #T_47630_row28_col2, #T_47630_row28_col3, #T_47630_row28_col4, #T_47630_row29_col0, #T_47630_row29_col1, #T_47630_row29_col2, #T_47630_row29_col3, #T_47630_row29_col4, #T_47630_row30_col0, #T_47630_row30_col1, #T_47630_row30_col2, #T_47630_row30_col3, #T_47630_row30_col4, #T_47630_row31_col0, #T_47630_row31_col1, #T_47630_row31_col2, #T_47630_row31_col3, #T_47630_row31_col4, #T_47630_row32_col0, #T_47630_row32_col1, #T_47630_row32_col2, #T_47630_row32_col3, #T_47630_row32_col4, #T_47630_row33_col0, #T_47630_row33_col1, #T_47630_row33_col2, #T_47630_row33_col3, #T_47630_row33_col4, #T_47630_row34_col0, #T_47630_row34_col1, #T_47630_row34_col2, #T_47630_row34_col3, #T_47630_row34_col4, #T_47630_row35_col0, #T_47630_row35_col1, #T_47630_row35_col2, #T_47630_row35_col3, #T_47630_row35_col4, #T_47630_row36_col0, #T_47630_row36_col1, #T_47630_row36_col2, #T_47630_row36_col3, #T_47630_row36_col4, #T_47630_row37_col0, #T_47630_row37_col1, #T_47630_row37_col2, #T_47630_row37_col3, #T_47630_row37_col4, #T_47630_row38_col0, #T_47630_row38_col1, #T_47630_row38_col2, #T_47630_row38_col3, #T_47630_row38_col4, #T_47630_row39_col0, #T_47630_row39_col1, #T_47630_row39_col2, #T_47630_row39_col3, #T_47630_row39_col4, #T_47630_row40_col0, #T_47630_row40_col1, #T_47630_row40_col2, #T_47630_row40_col3, #T_47630_row40_col4, #T_47630_row41_col0, #T_47630_row41_col1, #T_47630_row41_col2, #T_47630_row41_col3, #T_47630_row41_col4, #T_47630_row42_col0, #T_47630_row42_col1, #T_47630_row42_col2, #T_47630_row42_col3, #T_47630_row42_col4, #T_47630_row43_col0, #T_47630_row43_col1, #T_47630_row43_col2, #T_47630_row43_col3, #T_47630_row43_col4, #T_47630_row44_col0, #T_47630_row44_col1, #T_47630_row44_col2, #T_47630_row44_col3, #T_47630_row44_col4, #T_47630_row45_col0, #T_47630_row45_col1, #T_47630_row45_col2, #T_47630_row45_col3, #T_47630_row45_col4, #T_47630_row46_col0, #T_47630_row46_col1, #T_47630_row46_col2, #T_47630_row46_col3, #T_47630_row46_col4, #T_47630_row47_col0, #T_47630_row47_col1, #T_47630_row47_col2, #T_47630_row47_col3, #T_47630_row47_col4, #T_47630_row48_col0, #T_47630_row48_col1, #T_47630_row48_col2, #T_47630_row48_col3, #T_47630_row48_col4, #T_47630_row49_col0, #T_47630_row49_col1, #T_47630_row49_col2, #T_47630_row49_col3, #T_47630_row49_col4, #T_47630_row50_col0, #T_47630_row50_col1, #T_47630_row50_col2, #T_47630_row50_col3, #T_47630_row50_col4, #T_47630_row51_col0, #T_47630_row51_col1, #T_47630_row51_col2, #T_47630_row51_col3, #T_47630_row51_col4, #T_47630_row52_col0, #T_47630_row52_col1, #T_47630_row52_col2, #T_47630_row52_col3, #T_47630_row52_col4, #T_47630_row53_col0, #T_47630_row53_col1, #T_47630_row53_col2, #T_47630_row53_col3, #T_47630_row53_col4, #T_47630_row54_col0, #T_47630_row54_col1, #T_47630_row54_col2, #T_47630_row54_col3, #T_47630_row54_col4 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_47630\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_47630_level0_col0\" class=\"col_heading level0 col0\" >Constructo / Ítem</th>\n",
              "      <th id=\"T_47630_level0_col1\" class=\"col_heading level0 col1\" >Loading</th>\n",
              "      <th id=\"T_47630_level0_col2\" class=\"col_heading level0 col2\" >α (Cronbach)</th>\n",
              "      <th id=\"T_47630_level0_col3\" class=\"col_heading level0 col3\" >CR (Fiabilidad)</th>\n",
              "      <th id=\"T_47630_level0_col4\" class=\"col_heading level0 col4\" >AVE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row0_col0\" class=\"data row0 col0\" >**CREDIBILIDAD**</td>\n",
              "      <td id=\"T_47630_row0_col1\" class=\"data row0 col1\" ></td>\n",
              "      <td id=\"T_47630_row0_col2\" class=\"data row0 col2\" >0.727</td>\n",
              "      <td id=\"T_47630_row0_col3\" class=\"data row0 col3\" >0.776</td>\n",
              "      <td id=\"T_47630_row0_col4\" class=\"data row0 col4\" >0.279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row1_col0\" class=\"data row1 col0\" >   int_1</td>\n",
              "      <td id=\"T_47630_row1_col1\" class=\"data row1 col1\" >0.812</td>\n",
              "      <td id=\"T_47630_row1_col2\" class=\"data row1 col2\" ></td>\n",
              "      <td id=\"T_47630_row1_col3\" class=\"data row1 col3\" ></td>\n",
              "      <td id=\"T_47630_row1_col4\" class=\"data row1 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row2_col0\" class=\"data row2 col0\" >   int_2</td>\n",
              "      <td id=\"T_47630_row2_col1\" class=\"data row2 col1\" >0.781</td>\n",
              "      <td id=\"T_47630_row2_col2\" class=\"data row2 col2\" ></td>\n",
              "      <td id=\"T_47630_row2_col3\" class=\"data row2 col3\" ></td>\n",
              "      <td id=\"T_47630_row2_col4\" class=\"data row2 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row3_col0\" class=\"data row3 col0\" >   int_3</td>\n",
              "      <td id=\"T_47630_row3_col1\" class=\"data row3 col1\" >0.762</td>\n",
              "      <td id=\"T_47630_row3_col2\" class=\"data row3 col2\" ></td>\n",
              "      <td id=\"T_47630_row3_col3\" class=\"data row3 col3\" ></td>\n",
              "      <td id=\"T_47630_row3_col4\" class=\"data row3 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row4_col0\" class=\"data row4 col0\" >   int_4</td>\n",
              "      <td id=\"T_47630_row4_col1\" class=\"data row4 col1\" >0.747</td>\n",
              "      <td id=\"T_47630_row4_col2\" class=\"data row4 col2\" ></td>\n",
              "      <td id=\"T_47630_row4_col3\" class=\"data row4 col3\" ></td>\n",
              "      <td id=\"T_47630_row4_col4\" class=\"data row4 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row5_col0\" class=\"data row5 col0\" >   exp_1</td>\n",
              "      <td id=\"T_47630_row5_col1\" class=\"data row5 col1\" >0.387</td>\n",
              "      <td id=\"T_47630_row5_col2\" class=\"data row5 col2\" ></td>\n",
              "      <td id=\"T_47630_row5_col3\" class=\"data row5 col3\" ></td>\n",
              "      <td id=\"T_47630_row5_col4\" class=\"data row5 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row6_col0\" class=\"data row6 col0\" >   exp_2</td>\n",
              "      <td id=\"T_47630_row6_col1\" class=\"data row6 col1\" >0.315</td>\n",
              "      <td id=\"T_47630_row6_col2\" class=\"data row6 col2\" ></td>\n",
              "      <td id=\"T_47630_row6_col3\" class=\"data row6 col3\" ></td>\n",
              "      <td id=\"T_47630_row6_col4\" class=\"data row6 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row7_col0\" class=\"data row7 col0\" >   exp_3</td>\n",
              "      <td id=\"T_47630_row7_col1\" class=\"data row7 col1\" >0.280</td>\n",
              "      <td id=\"T_47630_row7_col2\" class=\"data row7 col2\" ></td>\n",
              "      <td id=\"T_47630_row7_col3\" class=\"data row7 col3\" ></td>\n",
              "      <td id=\"T_47630_row7_col4\" class=\"data row7 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row8_col0\" class=\"data row8 col0\" >   exp_4</td>\n",
              "      <td id=\"T_47630_row8_col1\" class=\"data row8 col1\" >0.322</td>\n",
              "      <td id=\"T_47630_row8_col2\" class=\"data row8 col2\" ></td>\n",
              "      <td id=\"T_47630_row8_col3\" class=\"data row8 col3\" ></td>\n",
              "      <td id=\"T_47630_row8_col4\" class=\"data row8 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row9_col0\" class=\"data row9 col0\" >   aut_1</td>\n",
              "      <td id=\"T_47630_row9_col1\" class=\"data row9 col1\" >0.280</td>\n",
              "      <td id=\"T_47630_row9_col2\" class=\"data row9 col2\" ></td>\n",
              "      <td id=\"T_47630_row9_col3\" class=\"data row9 col3\" ></td>\n",
              "      <td id=\"T_47630_row9_col4\" class=\"data row9 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row10_col0\" class=\"data row10 col0\" >   aut_2</td>\n",
              "      <td id=\"T_47630_row10_col1\" class=\"data row10 col1\" >0.300</td>\n",
              "      <td id=\"T_47630_row10_col2\" class=\"data row10 col2\" ></td>\n",
              "      <td id=\"T_47630_row10_col3\" class=\"data row10 col3\" ></td>\n",
              "      <td id=\"T_47630_row10_col4\" class=\"data row10 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row11_col0\" class=\"data row11 col0\" >   aut_3</td>\n",
              "      <td id=\"T_47630_row11_col1\" class=\"data row11 col1\" >0.257</td>\n",
              "      <td id=\"T_47630_row11_col2\" class=\"data row11 col2\" ></td>\n",
              "      <td id=\"T_47630_row11_col3\" class=\"data row11 col3\" ></td>\n",
              "      <td id=\"T_47630_row11_col4\" class=\"data row11 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row12_col0\" class=\"data row12 col0\" >**SEMEJANZA**</td>\n",
              "      <td id=\"T_47630_row12_col1\" class=\"data row12 col1\" ></td>\n",
              "      <td id=\"T_47630_row12_col2\" class=\"data row12 col2\" >0.757</td>\n",
              "      <td id=\"T_47630_row12_col3\" class=\"data row12 col3\" >0.806</td>\n",
              "      <td id=\"T_47630_row12_col4\" class=\"data row12 col4\" >0.387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row13_col0\" class=\"data row13 col0\" >   att_1</td>\n",
              "      <td id=\"T_47630_row13_col1\" class=\"data row13 col1\" >0.456</td>\n",
              "      <td id=\"T_47630_row13_col2\" class=\"data row13 col2\" ></td>\n",
              "      <td id=\"T_47630_row13_col3\" class=\"data row13 col3\" ></td>\n",
              "      <td id=\"T_47630_row13_col4\" class=\"data row13 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row14_col0\" class=\"data row14 col0\" >   att_2</td>\n",
              "      <td id=\"T_47630_row14_col1\" class=\"data row14 col1\" >0.488</td>\n",
              "      <td id=\"T_47630_row14_col2\" class=\"data row14 col2\" ></td>\n",
              "      <td id=\"T_47630_row14_col3\" class=\"data row14 col3\" ></td>\n",
              "      <td id=\"T_47630_row14_col4\" class=\"data row14 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row15_col0\" class=\"data row15 col0\" >   att_3</td>\n",
              "      <td id=\"T_47630_row15_col1\" class=\"data row15 col1\" >0.447</td>\n",
              "      <td id=\"T_47630_row15_col2\" class=\"data row15 col2\" ></td>\n",
              "      <td id=\"T_47630_row15_col3\" class=\"data row15 col3\" ></td>\n",
              "      <td id=\"T_47630_row15_col4\" class=\"data row15 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row16_col0\" class=\"data row16 col0\" >   att_4</td>\n",
              "      <td id=\"T_47630_row16_col1\" class=\"data row16 col1\" >0.527</td>\n",
              "      <td id=\"T_47630_row16_col2\" class=\"data row16 col2\" ></td>\n",
              "      <td id=\"T_47630_row16_col3\" class=\"data row16 col3\" ></td>\n",
              "      <td id=\"T_47630_row16_col4\" class=\"data row16 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row17_col0\" class=\"data row17 col0\" >   sim_1</td>\n",
              "      <td id=\"T_47630_row17_col1\" class=\"data row17 col1\" >0.719</td>\n",
              "      <td id=\"T_47630_row17_col2\" class=\"data row17 col2\" ></td>\n",
              "      <td id=\"T_47630_row17_col3\" class=\"data row17 col3\" ></td>\n",
              "      <td id=\"T_47630_row17_col4\" class=\"data row17 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row18_col0\" class=\"data row18 col0\" >   sim_2</td>\n",
              "      <td id=\"T_47630_row18_col1\" class=\"data row18 col1\" >0.813</td>\n",
              "      <td id=\"T_47630_row18_col2\" class=\"data row18 col2\" ></td>\n",
              "      <td id=\"T_47630_row18_col3\" class=\"data row18 col3\" ></td>\n",
              "      <td id=\"T_47630_row18_col4\" class=\"data row18 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row19_col0\" class=\"data row19 col0\" >   sim_3</td>\n",
              "      <td id=\"T_47630_row19_col1\" class=\"data row19 col1\" >0.777</td>\n",
              "      <td id=\"T_47630_row19_col2\" class=\"data row19 col2\" ></td>\n",
              "      <td id=\"T_47630_row19_col3\" class=\"data row19 col3\" ></td>\n",
              "      <td id=\"T_47630_row19_col4\" class=\"data row19 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row20_col0\" class=\"data row20 col0\" >**FLUJO_DE_INFORMACION**</td>\n",
              "      <td id=\"T_47630_row20_col1\" class=\"data row20 col1\" ></td>\n",
              "      <td id=\"T_47630_row20_col2\" class=\"data row20 col2\" >0.738</td>\n",
              "      <td id=\"T_47630_row20_col3\" class=\"data row20 col3\" >0.768</td>\n",
              "      <td id=\"T_47630_row20_col4\" class=\"data row20 col4\" >0.420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row21_col0\" class=\"data row21 col0\" >   lid_1</td>\n",
              "      <td id=\"T_47630_row21_col1\" class=\"data row21 col1\" >0.852</td>\n",
              "      <td id=\"T_47630_row21_col2\" class=\"data row21 col2\" ></td>\n",
              "      <td id=\"T_47630_row21_col3\" class=\"data row21 col3\" ></td>\n",
              "      <td id=\"T_47630_row21_col4\" class=\"data row21 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row22_col0\" class=\"data row22 col0\" >   lid_2</td>\n",
              "      <td id=\"T_47630_row22_col1\" class=\"data row22 col1\" >0.808</td>\n",
              "      <td id=\"T_47630_row22_col2\" class=\"data row22 col2\" ></td>\n",
              "      <td id=\"T_47630_row22_col3\" class=\"data row22 col3\" ></td>\n",
              "      <td id=\"T_47630_row22_col4\" class=\"data row22 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row23_col0\" class=\"data row23 col0\" >   lid_3</td>\n",
              "      <td id=\"T_47630_row23_col1\" class=\"data row23 col1\" >0.869</td>\n",
              "      <td id=\"T_47630_row23_col2\" class=\"data row23 col2\" ></td>\n",
              "      <td id=\"T_47630_row23_col3\" class=\"data row23 col3\" ></td>\n",
              "      <td id=\"T_47630_row23_col4\" class=\"data row23 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row24_col0\" class=\"data row24 col0\" >   lid_4</td>\n",
              "      <td id=\"T_47630_row24_col1\" class=\"data row24 col1\" >0.884</td>\n",
              "      <td id=\"T_47630_row24_col2\" class=\"data row24 col2\" ></td>\n",
              "      <td id=\"T_47630_row24_col3\" class=\"data row24 col3\" ></td>\n",
              "      <td id=\"T_47630_row24_col4\" class=\"data row24 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row25_col0\" class=\"data row25 col0\" >   inf_1</td>\n",
              "      <td id=\"T_47630_row25_col1\" class=\"data row25 col1\" >0.040</td>\n",
              "      <td id=\"T_47630_row25_col2\" class=\"data row25 col2\" ></td>\n",
              "      <td id=\"T_47630_row25_col3\" class=\"data row25 col3\" ></td>\n",
              "      <td id=\"T_47630_row25_col4\" class=\"data row25 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row26_col0\" class=\"data row26 col0\" >   inf_2</td>\n",
              "      <td id=\"T_47630_row26_col1\" class=\"data row26 col1\" >0.115</td>\n",
              "      <td id=\"T_47630_row26_col2\" class=\"data row26 col2\" ></td>\n",
              "      <td id=\"T_47630_row26_col3\" class=\"data row26 col3\" ></td>\n",
              "      <td id=\"T_47630_row26_col4\" class=\"data row26 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row27_col0\" class=\"data row27 col0\" >   inf_3</td>\n",
              "      <td id=\"T_47630_row27_col1\" class=\"data row27 col1\" >0.097</td>\n",
              "      <td id=\"T_47630_row27_col2\" class=\"data row27 col2\" ></td>\n",
              "      <td id=\"T_47630_row27_col3\" class=\"data row27 col3\" ></td>\n",
              "      <td id=\"T_47630_row27_col4\" class=\"data row27 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row28_col0\" class=\"data row28 col0\" >**CONGRUENCIA**</td>\n",
              "      <td id=\"T_47630_row28_col1\" class=\"data row28 col1\" ></td>\n",
              "      <td id=\"T_47630_row28_col2\" class=\"data row28 col2\" >0.676</td>\n",
              "      <td id=\"T_47630_row28_col3\" class=\"data row28 col3\" >0.643</td>\n",
              "      <td id=\"T_47630_row28_col4\" class=\"data row28 col4\" >0.383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row29_col0\" class=\"data row29 col0\" >   congf_1</td>\n",
              "      <td id=\"T_47630_row29_col1\" class=\"data row29 col1\" >0.931</td>\n",
              "      <td id=\"T_47630_row29_col2\" class=\"data row29 col2\" ></td>\n",
              "      <td id=\"T_47630_row29_col3\" class=\"data row29 col3\" ></td>\n",
              "      <td id=\"T_47630_row29_col4\" class=\"data row29 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row30_col0\" class=\"data row30 col0\" >   congf_2</td>\n",
              "      <td id=\"T_47630_row30_col1\" class=\"data row30 col1\" >0.851</td>\n",
              "      <td id=\"T_47630_row30_col2\" class=\"data row30 col2\" ></td>\n",
              "      <td id=\"T_47630_row30_col3\" class=\"data row30 col3\" ></td>\n",
              "      <td id=\"T_47630_row30_col4\" class=\"data row30 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row31_col0\" class=\"data row31 col0\" >   congf_3</td>\n",
              "      <td id=\"T_47630_row31_col1\" class=\"data row31 col1\" >0.840</td>\n",
              "      <td id=\"T_47630_row31_col2\" class=\"data row31 col2\" ></td>\n",
              "      <td id=\"T_47630_row31_col3\" class=\"data row31 col3\" ></td>\n",
              "      <td id=\"T_47630_row31_col4\" class=\"data row31 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row32_col0\" class=\"data row32 col0\" >   congp_1</td>\n",
              "      <td id=\"T_47630_row32_col1\" class=\"data row32 col1\" >-0.002</td>\n",
              "      <td id=\"T_47630_row32_col2\" class=\"data row32 col2\" ></td>\n",
              "      <td id=\"T_47630_row32_col3\" class=\"data row32 col3\" ></td>\n",
              "      <td id=\"T_47630_row32_col4\" class=\"data row32 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row33_col0\" class=\"data row33 col0\" >   congp_2</td>\n",
              "      <td id=\"T_47630_row33_col1\" class=\"data row33 col1\" >-0.015</td>\n",
              "      <td id=\"T_47630_row33_col2\" class=\"data row33 col2\" ></td>\n",
              "      <td id=\"T_47630_row33_col3\" class=\"data row33 col3\" ></td>\n",
              "      <td id=\"T_47630_row33_col4\" class=\"data row33 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row34_col0\" class=\"data row34 col0\" >   congp_3</td>\n",
              "      <td id=\"T_47630_row34_col1\" class=\"data row34 col1\" >-0.025</td>\n",
              "      <td id=\"T_47630_row34_col2\" class=\"data row34 col2\" ></td>\n",
              "      <td id=\"T_47630_row34_col3\" class=\"data row34 col3\" ></td>\n",
              "      <td id=\"T_47630_row34_col4\" class=\"data row34 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row35_col0\" class=\"data row35 col0\" >**CONCIENCIA_DE_LA_PERSUASION**</td>\n",
              "      <td id=\"T_47630_row35_col1\" class=\"data row35 col1\" ></td>\n",
              "      <td id=\"T_47630_row35_col2\" class=\"data row35 col2\" >0.853</td>\n",
              "      <td id=\"T_47630_row35_col3\" class=\"data row35 col3\" >0.895</td>\n",
              "      <td id=\"T_47630_row35_col4\" class=\"data row35 col4\" >0.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row36_col0\" class=\"data row36 col0\" >   concp_1</td>\n",
              "      <td id=\"T_47630_row36_col1\" class=\"data row36 col1\" >0.883</td>\n",
              "      <td id=\"T_47630_row36_col2\" class=\"data row36 col2\" ></td>\n",
              "      <td id=\"T_47630_row36_col3\" class=\"data row36 col3\" ></td>\n",
              "      <td id=\"T_47630_row36_col4\" class=\"data row36 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row37_col0\" class=\"data row37 col0\" >   concp_2</td>\n",
              "      <td id=\"T_47630_row37_col1\" class=\"data row37 col1\" >0.844</td>\n",
              "      <td id=\"T_47630_row37_col2\" class=\"data row37 col2\" ></td>\n",
              "      <td id=\"T_47630_row37_col3\" class=\"data row37 col3\" ></td>\n",
              "      <td id=\"T_47630_row37_col4\" class=\"data row37 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row38_col0\" class=\"data row38 col0\" >   concp_3</td>\n",
              "      <td id=\"T_47630_row38_col1\" class=\"data row38 col1\" >0.750</td>\n",
              "      <td id=\"T_47630_row38_col2\" class=\"data row38 col2\" ></td>\n",
              "      <td id=\"T_47630_row38_col3\" class=\"data row38 col3\" ></td>\n",
              "      <td id=\"T_47630_row38_col4\" class=\"data row38 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row39_col0\" class=\"data row39 col0\" >   concp_4</td>\n",
              "      <td id=\"T_47630_row39_col1\" class=\"data row39 col1\" >0.735</td>\n",
              "      <td id=\"T_47630_row39_col2\" class=\"data row39 col2\" ></td>\n",
              "      <td id=\"T_47630_row39_col3\" class=\"data row39 col3\" ></td>\n",
              "      <td id=\"T_47630_row39_col4\" class=\"data row39 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row40_col0\" class=\"data row40 col0\" >   concp_5</td>\n",
              "      <td id=\"T_47630_row40_col1\" class=\"data row40 col1\" >0.747</td>\n",
              "      <td id=\"T_47630_row40_col2\" class=\"data row40 col2\" ></td>\n",
              "      <td id=\"T_47630_row40_col3\" class=\"data row40 col3\" ></td>\n",
              "      <td id=\"T_47630_row40_col4\" class=\"data row40 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row41_col0\" class=\"data row41 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_47630_row41_col1\" class=\"data row41 col1\" ></td>\n",
              "      <td id=\"T_47630_row41_col2\" class=\"data row41 col2\" >0.845</td>\n",
              "      <td id=\"T_47630_row41_col3\" class=\"data row41 col3\" >0.906</td>\n",
              "      <td id=\"T_47630_row41_col4\" class=\"data row41 col4\" >0.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row42_col0\" class=\"data row42 col0\" >   act_1</td>\n",
              "      <td id=\"T_47630_row42_col1\" class=\"data row42 col1\" >0.883</td>\n",
              "      <td id=\"T_47630_row42_col2\" class=\"data row42 col2\" ></td>\n",
              "      <td id=\"T_47630_row42_col3\" class=\"data row42 col3\" ></td>\n",
              "      <td id=\"T_47630_row42_col4\" class=\"data row42 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row43_col0\" class=\"data row43 col0\" >   act_2</td>\n",
              "      <td id=\"T_47630_row43_col1\" class=\"data row43 col1\" >0.833</td>\n",
              "      <td id=\"T_47630_row43_col2\" class=\"data row43 col2\" ></td>\n",
              "      <td id=\"T_47630_row43_col3\" class=\"data row43 col3\" ></td>\n",
              "      <td id=\"T_47630_row43_col4\" class=\"data row43 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row44_col0\" class=\"data row44 col0\" >   act_3</td>\n",
              "      <td id=\"T_47630_row44_col1\" class=\"data row44 col1\" >0.905</td>\n",
              "      <td id=\"T_47630_row44_col2\" class=\"data row44 col2\" ></td>\n",
              "      <td id=\"T_47630_row44_col3\" class=\"data row44 col3\" ></td>\n",
              "      <td id=\"T_47630_row44_col4\" class=\"data row44 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row45_col0\" class=\"data row45 col0\" >**PREDISPOSICION_COMPRA**</td>\n",
              "      <td id=\"T_47630_row45_col1\" class=\"data row45 col1\" ></td>\n",
              "      <td id=\"T_47630_row45_col2\" class=\"data row45 col2\" >0.854</td>\n",
              "      <td id=\"T_47630_row45_col3\" class=\"data row45 col3\" >0.911</td>\n",
              "      <td id=\"T_47630_row45_col4\" class=\"data row45 col4\" >0.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row46_col0\" class=\"data row46 col0\" >   pred_1</td>\n",
              "      <td id=\"T_47630_row46_col1\" class=\"data row46 col1\" >0.917</td>\n",
              "      <td id=\"T_47630_row46_col2\" class=\"data row46 col2\" ></td>\n",
              "      <td id=\"T_47630_row46_col3\" class=\"data row46 col3\" ></td>\n",
              "      <td id=\"T_47630_row46_col4\" class=\"data row46 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row47_col0\" class=\"data row47 col0\" >   pred_2</td>\n",
              "      <td id=\"T_47630_row47_col1\" class=\"data row47 col1\" >0.872</td>\n",
              "      <td id=\"T_47630_row47_col2\" class=\"data row47 col2\" ></td>\n",
              "      <td id=\"T_47630_row47_col3\" class=\"data row47 col3\" ></td>\n",
              "      <td id=\"T_47630_row47_col4\" class=\"data row47 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row48_col0\" class=\"data row48 col0\" >   pred_3</td>\n",
              "      <td id=\"T_47630_row48_col1\" class=\"data row48 col1\" >0.850</td>\n",
              "      <td id=\"T_47630_row48_col2\" class=\"data row48 col2\" ></td>\n",
              "      <td id=\"T_47630_row48_col3\" class=\"data row48 col3\" ></td>\n",
              "      <td id=\"T_47630_row48_col4\" class=\"data row48 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row49_col0\" class=\"data row49 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_47630_row49_col1\" class=\"data row49 col1\" ></td>\n",
              "      <td id=\"T_47630_row49_col2\" class=\"data row49 col2\" >0.831</td>\n",
              "      <td id=\"T_47630_row49_col3\" class=\"data row49 col3\" >0.881</td>\n",
              "      <td id=\"T_47630_row49_col4\" class=\"data row49 col4\" >0.598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row50_col0\" class=\"data row50 col0\" >   eng_1</td>\n",
              "      <td id=\"T_47630_row50_col1\" class=\"data row50 col1\" >0.723</td>\n",
              "      <td id=\"T_47630_row50_col2\" class=\"data row50 col2\" ></td>\n",
              "      <td id=\"T_47630_row50_col3\" class=\"data row50 col3\" ></td>\n",
              "      <td id=\"T_47630_row50_col4\" class=\"data row50 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row51_col0\" class=\"data row51 col0\" >   eng_2</td>\n",
              "      <td id=\"T_47630_row51_col1\" class=\"data row51 col1\" >0.817</td>\n",
              "      <td id=\"T_47630_row51_col2\" class=\"data row51 col2\" ></td>\n",
              "      <td id=\"T_47630_row51_col3\" class=\"data row51 col3\" ></td>\n",
              "      <td id=\"T_47630_row51_col4\" class=\"data row51 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row52_col0\" class=\"data row52 col0\" >   eng_3</td>\n",
              "      <td id=\"T_47630_row52_col1\" class=\"data row52 col1\" >0.711</td>\n",
              "      <td id=\"T_47630_row52_col2\" class=\"data row52 col2\" ></td>\n",
              "      <td id=\"T_47630_row52_col3\" class=\"data row52 col3\" ></td>\n",
              "      <td id=\"T_47630_row52_col4\" class=\"data row52 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row53_col0\" class=\"data row53 col0\" >   eng_4</td>\n",
              "      <td id=\"T_47630_row53_col1\" class=\"data row53 col1\" >0.817</td>\n",
              "      <td id=\"T_47630_row53_col2\" class=\"data row53 col2\" ></td>\n",
              "      <td id=\"T_47630_row53_col3\" class=\"data row53 col3\" ></td>\n",
              "      <td id=\"T_47630_row53_col4\" class=\"data row53 col4\" ></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_47630_row54_col0\" class=\"data row54 col0\" >   eng_5</td>\n",
              "      <td id=\"T_47630_row54_col1\" class=\"data row54 col1\" >0.791</td>\n",
              "      <td id=\"T_47630_row54_col2\" class=\"data row54 col2\" ></td>\n",
              "      <td id=\"T_47630_row54_col3\" class=\"data row54 col3\" ></td>\n",
              "      <td id=\"T_47630_row54_col4\" class=\"data row54 col4\" ></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tabla interpretativa **\n",
        "\n",
        "**Enfoque 1 (Indicadores Repetidos):**"
      ],
      "metadata": {
        "id": "JpiOR-0BFzfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. CARGA DE DATOS\n",
        "# -----------------------------------------------------------------------------\n",
        "try:\n",
        "    df = pd.read_excel('datos_codificados_ajustados (1).xlsx')\n",
        "except:\n",
        "    try:\n",
        "        df = pd.read_csv('datos_codificados_ajustados (1).xlsx - Sheet1.csv')\n",
        "    except:\n",
        "        print(\"Error: Asegúrate de cargar tu archivo de datos primero.\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. DEFINICIÓN DE CONSTRUCTOS (1er y 2do Orden)\n",
        "# -----------------------------------------------------------------------------\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# Agrupación de 2do Orden\n",
        "constructos_2do_orden = {\n",
        "    'CREDIBILIDAD': (constructos_1er_orden['integridad'] +\n",
        "                     constructos_1er_orden['expertis'] +\n",
        "                     constructos_1er_orden['autenticidad']),\n",
        "\n",
        "    'SEMEJANZA': (constructos_1er_orden['atractividad'] +\n",
        "                  constructos_1er_orden['similitud']),\n",
        "\n",
        "    'FLUJO DE INFORMACIÓN': (constructos_1er_orden['lider_de_opinion'] +\n",
        "                             constructos_1er_orden['informatividad_del_contenido']),\n",
        "\n",
        "    'CONGRUENCIA': (constructos_1er_orden['congruencia_influencer_follower'] +\n",
        "                    constructos_1er_orden['congruencia_influencer_producto']),\n",
        "\n",
        "    'CONCIENCIA PERSUASIÓN': constructos_1er_orden['conciencia_de_la_persuasion'],\n",
        "    'ACTITUD': constructos_1er_orden['actitud'],\n",
        "    'INTENCIÓN DE COMPRA': constructos_1er_orden['predisposicion_a_comprar_un_producto'],\n",
        "    'ENGAGEMENT': constructos_1er_orden['engagement']\n",
        "}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. FUNCIONES DE CÁLCULO E INTERPRETACIÓN\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_cronbach_alpha(itemscores):\n",
        "    itemscores = np.asarray(itemscores)\n",
        "    itemvars = itemscores.var(axis=0, ddof=1)\n",
        "    tscores = itemscores.sum(axis=1)\n",
        "    nitems = itemscores.shape[1]\n",
        "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))\n",
        "\n",
        "# Reglas de Interpretación (Basadas en Hair et al.)\n",
        "def interpretar_loading(val):\n",
        "    if val >= 0.70: return \"Ideal (≥ 0.70)\"\n",
        "    elif val >= 0.60: return \"Aceptable (0.60-0.70)\"\n",
        "    else: return \"Bajo (< 0.60)\"\n",
        "\n",
        "def interpretar_alpha_cr(val, tipo=\"Alpha\"):\n",
        "    if tipo == \"CR\" and val > 0.95: return \"Posible Redundancia (> 0.95)\"\n",
        "    if val >= 0.80: return \"Bueno (≥ 0.80)\"\n",
        "    elif val >= 0.70: return \"Aceptable (0.70-0.80)\"\n",
        "    else: return \"Bajo (< 0.70)\"\n",
        "\n",
        "def interpretar_ave(val):\n",
        "    if val >= 0.50: return \"Cumple (≥ 0.50)\"\n",
        "    else: return \"No Cumple (< 0.50)\"\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. PROCESAMIENTO\n",
        "# -----------------------------------------------------------------------------\n",
        "rows = []\n",
        "\n",
        "for construct, items in constructos_2do_orden.items():\n",
        "    # Validar existencia de columnas\n",
        "    valid_items = [col for col in items if col in df.columns]\n",
        "    if not valid_items: continue\n",
        "\n",
        "    block = df[valid_items].dropna()\n",
        "    if block.empty: continue\n",
        "\n",
        "    # --- CÁLCULOS ---\n",
        "    # 1. Alpha\n",
        "    alpha = calculate_cronbach_alpha(block)\n",
        "\n",
        "    # 2. PCA para Loadings\n",
        "    pca = PCA(n_components=1)\n",
        "    latent_score = pca.fit_transform(block)\n",
        "    # Corregir orientación si es necesaria\n",
        "    corrs = [np.corrcoef(block[col], latent_score[:, 0])[0, 1] for col in valid_items]\n",
        "    if np.mean(corrs) < 0: latent_score = -latent_score\n",
        "\n",
        "    loadings = []\n",
        "    for col in valid_items:\n",
        "        l = np.corrcoef(block[col], latent_score[:, 0])[0, 1]\n",
        "        loadings.append(l)\n",
        "    loadings = np.array(loadings)\n",
        "\n",
        "    # 3. AVE y CR\n",
        "    ave = np.mean(loadings**2)\n",
        "    sum_l = np.sum(loadings)\n",
        "    cr = (sum_l**2) / ((sum_l**2) + np.sum(1 - loadings**2))\n",
        "\n",
        "    # --- LLENADO DE FILAS ---\n",
        "    # Filas del Constructo (Métricas Globales)\n",
        "    rows.append({\n",
        "        'Variable': f\"**{construct}**\",\n",
        "        'Tipo de Dato': 'Alfa de Cronbach',\n",
        "        'Valor': alpha,\n",
        "        'Interpretación': interpretar_alpha_cr(alpha, \"Alpha\")\n",
        "    })\n",
        "    rows.append({\n",
        "        'Variable': \"\",\n",
        "        'Tipo de Dato': 'Fiabilidad Compuesta (CR)',\n",
        "        'Valor': cr,\n",
        "        'Interpretación': interpretar_alpha_cr(cr, \"CR\")\n",
        "    })\n",
        "    rows.append({\n",
        "        'Variable': \"\",\n",
        "        'Tipo de Dato': 'Varianza Media (AVE)',\n",
        "        'Valor': ave,\n",
        "        'Interpretación': interpretar_ave(ave)\n",
        "    })\n",
        "\n",
        "    # Filas de los Ítems (Loadings)\n",
        "    for item, load in zip(valid_items, loadings):\n",
        "        rows.append({\n",
        "            'Variable': f\"   - {item}\",\n",
        "            'Tipo de Dato': 'Carga Factorial (Loading)',\n",
        "            'Valor': load,\n",
        "            'Interpretación': interpretar_loading(load)\n",
        "        })\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. GENERACIÓN DE TABLA ESTILIZADA\n",
        "# -----------------------------------------------------------------------------\n",
        "df_res = pd.DataFrame(rows)\n",
        "\n",
        "# Función de Colores (Semáforo)\n",
        "def color_semaforo(val):\n",
        "    if isinstance(val, str):\n",
        "        if \"Ideal\" in val or \"Bueno\" in val or \"Cumple\" in val:\n",
        "            return 'background-color: #d4edda; color: #155724' # Verde\n",
        "        elif \"Aceptable\" in val or \"Redundancia\" in val:\n",
        "            return 'background-color: #fff3cd; color: #856404' # Amarillo\n",
        "        elif \"Bajo\" in val or \"No Cumple\" in val:\n",
        "            return 'background-color: #f8d7da; color: #721c24' # Rojo\n",
        "    return ''\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TABLA INTERPRETATIVA DE MODELO DE MEDICIÓN (2DO ORDEN)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mostrar Tabla\n",
        "display(df_res.style\n",
        "    .applymap(color_semaforo, subset=['Interpretación'])\n",
        "    .format({'Valor': '{:.3f}'})\n",
        "    .hide(axis='index')\n",
        "    .set_properties(**{'text-align': 'left'})\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_NVnCUTtF2dL",
        "outputId": "792e98b5-490f-413c-8670-dea8bb9c7dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TABLA INTERPRETATIVA DE MODELO DE MEDICIÓN (2DO ORDEN)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-990151379.py:170: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
            "  .applymap(color_semaforo, subset=['Interpretación'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79727ac74500>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_fa515_row0_col0, #T_fa515_row0_col1, #T_fa515_row0_col2, #T_fa515_row1_col0, #T_fa515_row1_col1, #T_fa515_row1_col2, #T_fa515_row2_col0, #T_fa515_row2_col1, #T_fa515_row2_col2, #T_fa515_row3_col0, #T_fa515_row3_col1, #T_fa515_row3_col2, #T_fa515_row4_col0, #T_fa515_row4_col1, #T_fa515_row4_col2, #T_fa515_row5_col0, #T_fa515_row5_col1, #T_fa515_row5_col2, #T_fa515_row6_col0, #T_fa515_row6_col1, #T_fa515_row6_col2, #T_fa515_row7_col0, #T_fa515_row7_col1, #T_fa515_row7_col2, #T_fa515_row8_col0, #T_fa515_row8_col1, #T_fa515_row8_col2, #T_fa515_row9_col0, #T_fa515_row9_col1, #T_fa515_row9_col2, #T_fa515_row10_col0, #T_fa515_row10_col1, #T_fa515_row10_col2, #T_fa515_row11_col0, #T_fa515_row11_col1, #T_fa515_row11_col2, #T_fa515_row12_col0, #T_fa515_row12_col1, #T_fa515_row12_col2, #T_fa515_row13_col0, #T_fa515_row13_col1, #T_fa515_row13_col2, #T_fa515_row14_col0, #T_fa515_row14_col1, #T_fa515_row14_col2, #T_fa515_row15_col0, #T_fa515_row15_col1, #T_fa515_row15_col2, #T_fa515_row16_col0, #T_fa515_row16_col1, #T_fa515_row16_col2, #T_fa515_row17_col0, #T_fa515_row17_col1, #T_fa515_row17_col2, #T_fa515_row18_col0, #T_fa515_row18_col1, #T_fa515_row18_col2, #T_fa515_row19_col0, #T_fa515_row19_col1, #T_fa515_row19_col2, #T_fa515_row20_col0, #T_fa515_row20_col1, #T_fa515_row20_col2, #T_fa515_row21_col0, #T_fa515_row21_col1, #T_fa515_row21_col2, #T_fa515_row22_col0, #T_fa515_row22_col1, #T_fa515_row22_col2, #T_fa515_row23_col0, #T_fa515_row23_col1, #T_fa515_row23_col2, #T_fa515_row24_col0, #T_fa515_row24_col1, #T_fa515_row24_col2, #T_fa515_row25_col0, #T_fa515_row25_col1, #T_fa515_row25_col2, #T_fa515_row26_col0, #T_fa515_row26_col1, #T_fa515_row26_col2, #T_fa515_row27_col0, #T_fa515_row27_col1, #T_fa515_row27_col2, #T_fa515_row28_col0, #T_fa515_row28_col1, #T_fa515_row28_col2, #T_fa515_row29_col0, #T_fa515_row29_col1, #T_fa515_row29_col2, #T_fa515_row30_col0, #T_fa515_row30_col1, #T_fa515_row30_col2, #T_fa515_row31_col0, #T_fa515_row31_col1, #T_fa515_row31_col2, #T_fa515_row32_col0, #T_fa515_row32_col1, #T_fa515_row32_col2, #T_fa515_row33_col0, #T_fa515_row33_col1, #T_fa515_row33_col2, #T_fa515_row34_col0, #T_fa515_row34_col1, #T_fa515_row34_col2, #T_fa515_row35_col0, #T_fa515_row35_col1, #T_fa515_row35_col2, #T_fa515_row36_col0, #T_fa515_row36_col1, #T_fa515_row36_col2, #T_fa515_row37_col0, #T_fa515_row37_col1, #T_fa515_row37_col2, #T_fa515_row38_col0, #T_fa515_row38_col1, #T_fa515_row38_col2, #T_fa515_row39_col0, #T_fa515_row39_col1, #T_fa515_row39_col2, #T_fa515_row40_col0, #T_fa515_row40_col1, #T_fa515_row40_col2, #T_fa515_row41_col0, #T_fa515_row41_col1, #T_fa515_row41_col2, #T_fa515_row42_col0, #T_fa515_row42_col1, #T_fa515_row42_col2, #T_fa515_row43_col0, #T_fa515_row43_col1, #T_fa515_row43_col2, #T_fa515_row44_col0, #T_fa515_row44_col1, #T_fa515_row44_col2, #T_fa515_row45_col0, #T_fa515_row45_col1, #T_fa515_row45_col2, #T_fa515_row46_col0, #T_fa515_row46_col1, #T_fa515_row46_col2, #T_fa515_row47_col0, #T_fa515_row47_col1, #T_fa515_row47_col2, #T_fa515_row48_col0, #T_fa515_row48_col1, #T_fa515_row48_col2, #T_fa515_row49_col0, #T_fa515_row49_col1, #T_fa515_row49_col2, #T_fa515_row50_col0, #T_fa515_row50_col1, #T_fa515_row50_col2, #T_fa515_row51_col0, #T_fa515_row51_col1, #T_fa515_row51_col2, #T_fa515_row52_col0, #T_fa515_row52_col1, #T_fa515_row52_col2, #T_fa515_row53_col0, #T_fa515_row53_col1, #T_fa515_row53_col2, #T_fa515_row54_col0, #T_fa515_row54_col1, #T_fa515_row54_col2, #T_fa515_row55_col0, #T_fa515_row55_col1, #T_fa515_row55_col2, #T_fa515_row56_col0, #T_fa515_row56_col1, #T_fa515_row56_col2, #T_fa515_row57_col0, #T_fa515_row57_col1, #T_fa515_row57_col2, #T_fa515_row58_col0, #T_fa515_row58_col1, #T_fa515_row58_col2, #T_fa515_row59_col0, #T_fa515_row59_col1, #T_fa515_row59_col2, #T_fa515_row60_col0, #T_fa515_row60_col1, #T_fa515_row60_col2, #T_fa515_row61_col0, #T_fa515_row61_col1, #T_fa515_row61_col2, #T_fa515_row62_col0, #T_fa515_row62_col1, #T_fa515_row62_col2, #T_fa515_row63_col0, #T_fa515_row63_col1, #T_fa515_row63_col2, #T_fa515_row64_col0, #T_fa515_row64_col1, #T_fa515_row64_col2, #T_fa515_row65_col0, #T_fa515_row65_col1, #T_fa515_row65_col2, #T_fa515_row66_col0, #T_fa515_row66_col1, #T_fa515_row66_col2, #T_fa515_row67_col0, #T_fa515_row67_col1, #T_fa515_row67_col2, #T_fa515_row68_col0, #T_fa515_row68_col1, #T_fa515_row68_col2, #T_fa515_row69_col0, #T_fa515_row69_col1, #T_fa515_row69_col2, #T_fa515_row70_col0, #T_fa515_row70_col1, #T_fa515_row70_col2 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_fa515_row0_col3, #T_fa515_row1_col3, #T_fa515_row14_col3, #T_fa515_row24_col3, #T_fa515_row25_col3 {\n",
              "  background-color: #fff3cd;\n",
              "  color: #856404;\n",
              "  text-align: left;\n",
              "}\n",
              "#T_fa515_row2_col3, #T_fa515_row3_col3, #T_fa515_row4_col3, #T_fa515_row5_col3, #T_fa515_row6_col3, #T_fa515_row15_col3, #T_fa515_row16_col3, #T_fa515_row21_col3, #T_fa515_row22_col3, #T_fa515_row23_col3, #T_fa515_row26_col3, #T_fa515_row27_col3, #T_fa515_row28_col3, #T_fa515_row29_col3, #T_fa515_row30_col3, #T_fa515_row36_col3, #T_fa515_row37_col3, #T_fa515_row38_col3, #T_fa515_row39_col3, #T_fa515_row43_col3, #T_fa515_row44_col3, #T_fa515_row45_col3, #T_fa515_row46_col3, #T_fa515_row47_col3, #T_fa515_row48_col3, #T_fa515_row49_col3, #T_fa515_row50_col3, #T_fa515_row51_col3, #T_fa515_row52_col3, #T_fa515_row53_col3, #T_fa515_row54_col3, #T_fa515_row55_col3, #T_fa515_row56_col3, #T_fa515_row57_col3, #T_fa515_row58_col3, #T_fa515_row59_col3, #T_fa515_row60_col3, #T_fa515_row61_col3, #T_fa515_row62_col3, #T_fa515_row63_col3, #T_fa515_row64_col3, #T_fa515_row65_col3, #T_fa515_row66_col3, #T_fa515_row67_col3, #T_fa515_row68_col3, #T_fa515_row69_col3, #T_fa515_row70_col3 {\n",
              "  background-color: #d4edda;\n",
              "  color: #155724;\n",
              "  text-align: left;\n",
              "}\n",
              "#T_fa515_row7_col3, #T_fa515_row8_col3, #T_fa515_row9_col3, #T_fa515_row10_col3, #T_fa515_row11_col3, #T_fa515_row12_col3, #T_fa515_row13_col3, #T_fa515_row17_col3, #T_fa515_row18_col3, #T_fa515_row19_col3, #T_fa515_row20_col3, #T_fa515_row31_col3, #T_fa515_row32_col3, #T_fa515_row33_col3, #T_fa515_row34_col3, #T_fa515_row35_col3, #T_fa515_row40_col3, #T_fa515_row41_col3, #T_fa515_row42_col3 {\n",
              "  background-color: #f8d7da;\n",
              "  color: #721c24;\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_fa515\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_fa515_level0_col0\" class=\"col_heading level0 col0\" >Variable</th>\n",
              "      <th id=\"T_fa515_level0_col1\" class=\"col_heading level0 col1\" >Tipo de Dato</th>\n",
              "      <th id=\"T_fa515_level0_col2\" class=\"col_heading level0 col2\" >Valor</th>\n",
              "      <th id=\"T_fa515_level0_col3\" class=\"col_heading level0 col3\" >Interpretación</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row0_col0\" class=\"data row0 col0\" >**CREDIBILIDAD**</td>\n",
              "      <td id=\"T_fa515_row0_col1\" class=\"data row0 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row0_col2\" class=\"data row0 col2\" >0.727</td>\n",
              "      <td id=\"T_fa515_row0_col3\" class=\"data row0 col3\" >Aceptable (0.70-0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row1_col0\" class=\"data row1 col0\" ></td>\n",
              "      <td id=\"T_fa515_row1_col1\" class=\"data row1 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row1_col2\" class=\"data row1 col2\" >0.776</td>\n",
              "      <td id=\"T_fa515_row1_col3\" class=\"data row1 col3\" >Aceptable (0.70-0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row2_col0\" class=\"data row2 col0\" ></td>\n",
              "      <td id=\"T_fa515_row2_col1\" class=\"data row2 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row2_col2\" class=\"data row2 col2\" >0.279</td>\n",
              "      <td id=\"T_fa515_row2_col3\" class=\"data row2 col3\" >No Cumple (< 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row3_col0\" class=\"data row3 col0\" >   - int_1</td>\n",
              "      <td id=\"T_fa515_row3_col1\" class=\"data row3 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row3_col2\" class=\"data row3 col2\" >0.812</td>\n",
              "      <td id=\"T_fa515_row3_col3\" class=\"data row3 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row4_col0\" class=\"data row4 col0\" >   - int_2</td>\n",
              "      <td id=\"T_fa515_row4_col1\" class=\"data row4 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row4_col2\" class=\"data row4 col2\" >0.781</td>\n",
              "      <td id=\"T_fa515_row4_col3\" class=\"data row4 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row5_col0\" class=\"data row5 col0\" >   - int_3</td>\n",
              "      <td id=\"T_fa515_row5_col1\" class=\"data row5 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row5_col2\" class=\"data row5 col2\" >0.762</td>\n",
              "      <td id=\"T_fa515_row5_col3\" class=\"data row5 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row6_col0\" class=\"data row6 col0\" >   - int_4</td>\n",
              "      <td id=\"T_fa515_row6_col1\" class=\"data row6 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row6_col2\" class=\"data row6 col2\" >0.747</td>\n",
              "      <td id=\"T_fa515_row6_col3\" class=\"data row6 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row7_col0\" class=\"data row7 col0\" >   - exp_1</td>\n",
              "      <td id=\"T_fa515_row7_col1\" class=\"data row7 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row7_col2\" class=\"data row7 col2\" >0.387</td>\n",
              "      <td id=\"T_fa515_row7_col3\" class=\"data row7 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row8_col0\" class=\"data row8 col0\" >   - exp_2</td>\n",
              "      <td id=\"T_fa515_row8_col1\" class=\"data row8 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row8_col2\" class=\"data row8 col2\" >0.315</td>\n",
              "      <td id=\"T_fa515_row8_col3\" class=\"data row8 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row9_col0\" class=\"data row9 col0\" >   - exp_3</td>\n",
              "      <td id=\"T_fa515_row9_col1\" class=\"data row9 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row9_col2\" class=\"data row9 col2\" >0.280</td>\n",
              "      <td id=\"T_fa515_row9_col3\" class=\"data row9 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row10_col0\" class=\"data row10 col0\" >   - exp_4</td>\n",
              "      <td id=\"T_fa515_row10_col1\" class=\"data row10 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row10_col2\" class=\"data row10 col2\" >0.322</td>\n",
              "      <td id=\"T_fa515_row10_col3\" class=\"data row10 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row11_col0\" class=\"data row11 col0\" >   - aut_1</td>\n",
              "      <td id=\"T_fa515_row11_col1\" class=\"data row11 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row11_col2\" class=\"data row11 col2\" >0.280</td>\n",
              "      <td id=\"T_fa515_row11_col3\" class=\"data row11 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row12_col0\" class=\"data row12 col0\" >   - aut_2</td>\n",
              "      <td id=\"T_fa515_row12_col1\" class=\"data row12 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row12_col2\" class=\"data row12 col2\" >0.300</td>\n",
              "      <td id=\"T_fa515_row12_col3\" class=\"data row12 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row13_col0\" class=\"data row13 col0\" >   - aut_3</td>\n",
              "      <td id=\"T_fa515_row13_col1\" class=\"data row13 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row13_col2\" class=\"data row13 col2\" >0.257</td>\n",
              "      <td id=\"T_fa515_row13_col3\" class=\"data row13 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row14_col0\" class=\"data row14 col0\" >**SEMEJANZA**</td>\n",
              "      <td id=\"T_fa515_row14_col1\" class=\"data row14 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row14_col2\" class=\"data row14 col2\" >0.757</td>\n",
              "      <td id=\"T_fa515_row14_col3\" class=\"data row14 col3\" >Aceptable (0.70-0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row15_col0\" class=\"data row15 col0\" ></td>\n",
              "      <td id=\"T_fa515_row15_col1\" class=\"data row15 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row15_col2\" class=\"data row15 col2\" >0.806</td>\n",
              "      <td id=\"T_fa515_row15_col3\" class=\"data row15 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row16_col0\" class=\"data row16 col0\" ></td>\n",
              "      <td id=\"T_fa515_row16_col1\" class=\"data row16 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row16_col2\" class=\"data row16 col2\" >0.387</td>\n",
              "      <td id=\"T_fa515_row16_col3\" class=\"data row16 col3\" >No Cumple (< 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row17_col0\" class=\"data row17 col0\" >   - att_1</td>\n",
              "      <td id=\"T_fa515_row17_col1\" class=\"data row17 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row17_col2\" class=\"data row17 col2\" >0.456</td>\n",
              "      <td id=\"T_fa515_row17_col3\" class=\"data row17 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row18_col0\" class=\"data row18 col0\" >   - att_2</td>\n",
              "      <td id=\"T_fa515_row18_col1\" class=\"data row18 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row18_col2\" class=\"data row18 col2\" >0.488</td>\n",
              "      <td id=\"T_fa515_row18_col3\" class=\"data row18 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row19_col0\" class=\"data row19 col0\" >   - att_3</td>\n",
              "      <td id=\"T_fa515_row19_col1\" class=\"data row19 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row19_col2\" class=\"data row19 col2\" >0.447</td>\n",
              "      <td id=\"T_fa515_row19_col3\" class=\"data row19 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row20_col0\" class=\"data row20 col0\" >   - att_4</td>\n",
              "      <td id=\"T_fa515_row20_col1\" class=\"data row20 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row20_col2\" class=\"data row20 col2\" >0.527</td>\n",
              "      <td id=\"T_fa515_row20_col3\" class=\"data row20 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row21_col0\" class=\"data row21 col0\" >   - sim_1</td>\n",
              "      <td id=\"T_fa515_row21_col1\" class=\"data row21 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row21_col2\" class=\"data row21 col2\" >0.719</td>\n",
              "      <td id=\"T_fa515_row21_col3\" class=\"data row21 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row22_col0\" class=\"data row22 col0\" >   - sim_2</td>\n",
              "      <td id=\"T_fa515_row22_col1\" class=\"data row22 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row22_col2\" class=\"data row22 col2\" >0.813</td>\n",
              "      <td id=\"T_fa515_row22_col3\" class=\"data row22 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row23_col0\" class=\"data row23 col0\" >   - sim_3</td>\n",
              "      <td id=\"T_fa515_row23_col1\" class=\"data row23 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row23_col2\" class=\"data row23 col2\" >0.777</td>\n",
              "      <td id=\"T_fa515_row23_col3\" class=\"data row23 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row24_col0\" class=\"data row24 col0\" >**FLUJO DE INFORMACIÓN**</td>\n",
              "      <td id=\"T_fa515_row24_col1\" class=\"data row24 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row24_col2\" class=\"data row24 col2\" >0.738</td>\n",
              "      <td id=\"T_fa515_row24_col3\" class=\"data row24 col3\" >Aceptable (0.70-0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row25_col0\" class=\"data row25 col0\" ></td>\n",
              "      <td id=\"T_fa515_row25_col1\" class=\"data row25 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row25_col2\" class=\"data row25 col2\" >0.768</td>\n",
              "      <td id=\"T_fa515_row25_col3\" class=\"data row25 col3\" >Aceptable (0.70-0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row26_col0\" class=\"data row26 col0\" ></td>\n",
              "      <td id=\"T_fa515_row26_col1\" class=\"data row26 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row26_col2\" class=\"data row26 col2\" >0.420</td>\n",
              "      <td id=\"T_fa515_row26_col3\" class=\"data row26 col3\" >No Cumple (< 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row27_col0\" class=\"data row27 col0\" >   - lid_1</td>\n",
              "      <td id=\"T_fa515_row27_col1\" class=\"data row27 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row27_col2\" class=\"data row27 col2\" >0.852</td>\n",
              "      <td id=\"T_fa515_row27_col3\" class=\"data row27 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row28_col0\" class=\"data row28 col0\" >   - lid_2</td>\n",
              "      <td id=\"T_fa515_row28_col1\" class=\"data row28 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row28_col2\" class=\"data row28 col2\" >0.808</td>\n",
              "      <td id=\"T_fa515_row28_col3\" class=\"data row28 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row29_col0\" class=\"data row29 col0\" >   - lid_3</td>\n",
              "      <td id=\"T_fa515_row29_col1\" class=\"data row29 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row29_col2\" class=\"data row29 col2\" >0.869</td>\n",
              "      <td id=\"T_fa515_row29_col3\" class=\"data row29 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row30_col0\" class=\"data row30 col0\" >   - lid_4</td>\n",
              "      <td id=\"T_fa515_row30_col1\" class=\"data row30 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row30_col2\" class=\"data row30 col2\" >0.884</td>\n",
              "      <td id=\"T_fa515_row30_col3\" class=\"data row30 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row31_col0\" class=\"data row31 col0\" >   - inf_1</td>\n",
              "      <td id=\"T_fa515_row31_col1\" class=\"data row31 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row31_col2\" class=\"data row31 col2\" >0.040</td>\n",
              "      <td id=\"T_fa515_row31_col3\" class=\"data row31 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row32_col0\" class=\"data row32 col0\" >   - inf_2</td>\n",
              "      <td id=\"T_fa515_row32_col1\" class=\"data row32 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row32_col2\" class=\"data row32 col2\" >0.115</td>\n",
              "      <td id=\"T_fa515_row32_col3\" class=\"data row32 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row33_col0\" class=\"data row33 col0\" >   - inf_3</td>\n",
              "      <td id=\"T_fa515_row33_col1\" class=\"data row33 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row33_col2\" class=\"data row33 col2\" >0.097</td>\n",
              "      <td id=\"T_fa515_row33_col3\" class=\"data row33 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row34_col0\" class=\"data row34 col0\" >**CONGRUENCIA**</td>\n",
              "      <td id=\"T_fa515_row34_col1\" class=\"data row34 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row34_col2\" class=\"data row34 col2\" >0.676</td>\n",
              "      <td id=\"T_fa515_row34_col3\" class=\"data row34 col3\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row35_col0\" class=\"data row35 col0\" ></td>\n",
              "      <td id=\"T_fa515_row35_col1\" class=\"data row35 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row35_col2\" class=\"data row35 col2\" >0.643</td>\n",
              "      <td id=\"T_fa515_row35_col3\" class=\"data row35 col3\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row36_col0\" class=\"data row36 col0\" ></td>\n",
              "      <td id=\"T_fa515_row36_col1\" class=\"data row36 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row36_col2\" class=\"data row36 col2\" >0.383</td>\n",
              "      <td id=\"T_fa515_row36_col3\" class=\"data row36 col3\" >No Cumple (< 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row37_col0\" class=\"data row37 col0\" >   - congf_1</td>\n",
              "      <td id=\"T_fa515_row37_col1\" class=\"data row37 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row37_col2\" class=\"data row37 col2\" >0.931</td>\n",
              "      <td id=\"T_fa515_row37_col3\" class=\"data row37 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row38_col0\" class=\"data row38 col0\" >   - congf_2</td>\n",
              "      <td id=\"T_fa515_row38_col1\" class=\"data row38 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row38_col2\" class=\"data row38 col2\" >0.851</td>\n",
              "      <td id=\"T_fa515_row38_col3\" class=\"data row38 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row39_col0\" class=\"data row39 col0\" >   - congf_3</td>\n",
              "      <td id=\"T_fa515_row39_col1\" class=\"data row39 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row39_col2\" class=\"data row39 col2\" >0.840</td>\n",
              "      <td id=\"T_fa515_row39_col3\" class=\"data row39 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row40_col0\" class=\"data row40 col0\" >   - congp_1</td>\n",
              "      <td id=\"T_fa515_row40_col1\" class=\"data row40 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row40_col2\" class=\"data row40 col2\" >-0.002</td>\n",
              "      <td id=\"T_fa515_row40_col3\" class=\"data row40 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row41_col0\" class=\"data row41 col0\" >   - congp_2</td>\n",
              "      <td id=\"T_fa515_row41_col1\" class=\"data row41 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row41_col2\" class=\"data row41 col2\" >-0.015</td>\n",
              "      <td id=\"T_fa515_row41_col3\" class=\"data row41 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row42_col0\" class=\"data row42 col0\" >   - congp_3</td>\n",
              "      <td id=\"T_fa515_row42_col1\" class=\"data row42 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row42_col2\" class=\"data row42 col2\" >-0.025</td>\n",
              "      <td id=\"T_fa515_row42_col3\" class=\"data row42 col3\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row43_col0\" class=\"data row43 col0\" >**CONCIENCIA PERSUASIÓN**</td>\n",
              "      <td id=\"T_fa515_row43_col1\" class=\"data row43 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row43_col2\" class=\"data row43 col2\" >0.853</td>\n",
              "      <td id=\"T_fa515_row43_col3\" class=\"data row43 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row44_col0\" class=\"data row44 col0\" ></td>\n",
              "      <td id=\"T_fa515_row44_col1\" class=\"data row44 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row44_col2\" class=\"data row44 col2\" >0.895</td>\n",
              "      <td id=\"T_fa515_row44_col3\" class=\"data row44 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row45_col0\" class=\"data row45 col0\" ></td>\n",
              "      <td id=\"T_fa515_row45_col1\" class=\"data row45 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row45_col2\" class=\"data row45 col2\" >0.630</td>\n",
              "      <td id=\"T_fa515_row45_col3\" class=\"data row45 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row46_col0\" class=\"data row46 col0\" >   - concp_1</td>\n",
              "      <td id=\"T_fa515_row46_col1\" class=\"data row46 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row46_col2\" class=\"data row46 col2\" >0.883</td>\n",
              "      <td id=\"T_fa515_row46_col3\" class=\"data row46 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row47_col0\" class=\"data row47 col0\" >   - concp_2</td>\n",
              "      <td id=\"T_fa515_row47_col1\" class=\"data row47 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row47_col2\" class=\"data row47 col2\" >0.844</td>\n",
              "      <td id=\"T_fa515_row47_col3\" class=\"data row47 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row48_col0\" class=\"data row48 col0\" >   - concp_3</td>\n",
              "      <td id=\"T_fa515_row48_col1\" class=\"data row48 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row48_col2\" class=\"data row48 col2\" >0.750</td>\n",
              "      <td id=\"T_fa515_row48_col3\" class=\"data row48 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row49_col0\" class=\"data row49 col0\" >   - concp_4</td>\n",
              "      <td id=\"T_fa515_row49_col1\" class=\"data row49 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row49_col2\" class=\"data row49 col2\" >0.735</td>\n",
              "      <td id=\"T_fa515_row49_col3\" class=\"data row49 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row50_col0\" class=\"data row50 col0\" >   - concp_5</td>\n",
              "      <td id=\"T_fa515_row50_col1\" class=\"data row50 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row50_col2\" class=\"data row50 col2\" >0.747</td>\n",
              "      <td id=\"T_fa515_row50_col3\" class=\"data row50 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row51_col0\" class=\"data row51 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_fa515_row51_col1\" class=\"data row51 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row51_col2\" class=\"data row51 col2\" >0.845</td>\n",
              "      <td id=\"T_fa515_row51_col3\" class=\"data row51 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row52_col0\" class=\"data row52 col0\" ></td>\n",
              "      <td id=\"T_fa515_row52_col1\" class=\"data row52 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row52_col2\" class=\"data row52 col2\" >0.906</td>\n",
              "      <td id=\"T_fa515_row52_col3\" class=\"data row52 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row53_col0\" class=\"data row53 col0\" ></td>\n",
              "      <td id=\"T_fa515_row53_col1\" class=\"data row53 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row53_col2\" class=\"data row53 col2\" >0.764</td>\n",
              "      <td id=\"T_fa515_row53_col3\" class=\"data row53 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row54_col0\" class=\"data row54 col0\" >   - act_1</td>\n",
              "      <td id=\"T_fa515_row54_col1\" class=\"data row54 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row54_col2\" class=\"data row54 col2\" >0.883</td>\n",
              "      <td id=\"T_fa515_row54_col3\" class=\"data row54 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row55_col0\" class=\"data row55 col0\" >   - act_2</td>\n",
              "      <td id=\"T_fa515_row55_col1\" class=\"data row55 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row55_col2\" class=\"data row55 col2\" >0.833</td>\n",
              "      <td id=\"T_fa515_row55_col3\" class=\"data row55 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row56_col0\" class=\"data row56 col0\" >   - act_3</td>\n",
              "      <td id=\"T_fa515_row56_col1\" class=\"data row56 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row56_col2\" class=\"data row56 col2\" >0.905</td>\n",
              "      <td id=\"T_fa515_row56_col3\" class=\"data row56 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row57_col0\" class=\"data row57 col0\" >**INTENCIÓN DE COMPRA**</td>\n",
              "      <td id=\"T_fa515_row57_col1\" class=\"data row57 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row57_col2\" class=\"data row57 col2\" >0.854</td>\n",
              "      <td id=\"T_fa515_row57_col3\" class=\"data row57 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row58_col0\" class=\"data row58 col0\" ></td>\n",
              "      <td id=\"T_fa515_row58_col1\" class=\"data row58 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row58_col2\" class=\"data row58 col2\" >0.911</td>\n",
              "      <td id=\"T_fa515_row58_col3\" class=\"data row58 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row59_col0\" class=\"data row59 col0\" ></td>\n",
              "      <td id=\"T_fa515_row59_col1\" class=\"data row59 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row59_col2\" class=\"data row59 col2\" >0.774</td>\n",
              "      <td id=\"T_fa515_row59_col3\" class=\"data row59 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row60_col0\" class=\"data row60 col0\" >   - pred_1</td>\n",
              "      <td id=\"T_fa515_row60_col1\" class=\"data row60 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row60_col2\" class=\"data row60 col2\" >0.917</td>\n",
              "      <td id=\"T_fa515_row60_col3\" class=\"data row60 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row61_col0\" class=\"data row61 col0\" >   - pred_2</td>\n",
              "      <td id=\"T_fa515_row61_col1\" class=\"data row61 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row61_col2\" class=\"data row61 col2\" >0.872</td>\n",
              "      <td id=\"T_fa515_row61_col3\" class=\"data row61 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row62_col0\" class=\"data row62 col0\" >   - pred_3</td>\n",
              "      <td id=\"T_fa515_row62_col1\" class=\"data row62 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row62_col2\" class=\"data row62 col2\" >0.850</td>\n",
              "      <td id=\"T_fa515_row62_col3\" class=\"data row62 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row63_col0\" class=\"data row63 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_fa515_row63_col1\" class=\"data row63 col1\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_fa515_row63_col2\" class=\"data row63 col2\" >0.831</td>\n",
              "      <td id=\"T_fa515_row63_col3\" class=\"data row63 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row64_col0\" class=\"data row64 col0\" ></td>\n",
              "      <td id=\"T_fa515_row64_col1\" class=\"data row64 col1\" >Fiabilidad Compuesta (CR)</td>\n",
              "      <td id=\"T_fa515_row64_col2\" class=\"data row64 col2\" >0.881</td>\n",
              "      <td id=\"T_fa515_row64_col3\" class=\"data row64 col3\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row65_col0\" class=\"data row65 col0\" ></td>\n",
              "      <td id=\"T_fa515_row65_col1\" class=\"data row65 col1\" >Varianza Media (AVE)</td>\n",
              "      <td id=\"T_fa515_row65_col2\" class=\"data row65 col2\" >0.598</td>\n",
              "      <td id=\"T_fa515_row65_col3\" class=\"data row65 col3\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row66_col0\" class=\"data row66 col0\" >   - eng_1</td>\n",
              "      <td id=\"T_fa515_row66_col1\" class=\"data row66 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row66_col2\" class=\"data row66 col2\" >0.723</td>\n",
              "      <td id=\"T_fa515_row66_col3\" class=\"data row66 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row67_col0\" class=\"data row67 col0\" >   - eng_2</td>\n",
              "      <td id=\"T_fa515_row67_col1\" class=\"data row67 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row67_col2\" class=\"data row67 col2\" >0.817</td>\n",
              "      <td id=\"T_fa515_row67_col3\" class=\"data row67 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row68_col0\" class=\"data row68 col0\" >   - eng_3</td>\n",
              "      <td id=\"T_fa515_row68_col1\" class=\"data row68 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row68_col2\" class=\"data row68 col2\" >0.711</td>\n",
              "      <td id=\"T_fa515_row68_col3\" class=\"data row68 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row69_col0\" class=\"data row69 col0\" >   - eng_4</td>\n",
              "      <td id=\"T_fa515_row69_col1\" class=\"data row69 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row69_col2\" class=\"data row69 col2\" >0.817</td>\n",
              "      <td id=\"T_fa515_row69_col3\" class=\"data row69 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_fa515_row70_col0\" class=\"data row70 col0\" >   - eng_5</td>\n",
              "      <td id=\"T_fa515_row70_col1\" class=\"data row70 col1\" >Carga Factorial (Loading)</td>\n",
              "      <td id=\"T_fa515_row70_col2\" class=\"data row70 col2\" >0.791</td>\n",
              "      <td id=\"T_fa515_row70_col3\" class=\"data row70 col3\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading, CR, AVE Chrombach por promedio\n",
        "\n",
        "** Enfoque 2 (Promedios / Two-Stage):**\n"
      ],
      "metadata": {
        "id": "UOr-mQ4hIOD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display\n",
        "\n",
        "# 1. CARGA DE DATOS\n",
        "try:\n",
        "    df = pd.read_excel('datos_codificados_ajustados (1).xlsx')\n",
        "except:\n",
        "    try:\n",
        "        df = pd.read_csv('datos_codificados_ajustados (1).xlsx - Sheet1.csv')\n",
        "    except:\n",
        "        print(\"Error: Carga tu archivo.\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. CÁLCULO DE PROMEDIOS (ETAPA 1)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Definimos los de primer orden para calcular sus promedios\n",
        "c_1er = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    # Estos se quedan igual, no necesitamos promedios para formar otros mayores\n",
        "    # (aunque podríamos calcular sus scores, aquí usaremos sus ítems originales)\n",
        "}\n",
        "\n",
        "# Creamos las nuevas columnas de promedios en el DataFrame\n",
        "print(\"Calculando promedios de constructos de primer orden...\")\n",
        "nuevas_cols = []\n",
        "for nombre, items in c_1er.items():\n",
        "    col_name = f\"AVG_{nombre}\" # Ejemplo: AVG_integridad\n",
        "    # Promedio fila por fila (axis=1) ignorando nulos\n",
        "    df[col_name] = df[items].mean(axis=1)\n",
        "    nuevas_cols.append(col_name)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. DEFINICIÓN DEL MODELO DE 2DO ORDEN (USANDO PROMEDIOS)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Aquí la magia: Los constructos grandes ahora usan los PROMEDIOS como ítems\n",
        "constructos_finales = {\n",
        "    # --- Constructos de 2do Orden (Usan los promedios creados arriba) ---\n",
        "    'CREDIBILIDAD': ['AVG_integridad', 'AVG_expertis', 'AVG_autenticidad'],\n",
        "    'SEMEJANZA': ['AVG_atractividad', 'AVG_similitud'],\n",
        "    'FLUJO DE INFORMACIÓN': ['AVG_lider_de_opinion', 'AVG_informatividad_del_contenido'],\n",
        "    'CONGRUENCIA': ['AVG_congruencia_influencer_follower', 'AVG_congruencia_influencer_producto'],\n",
        "\n",
        "    # --- Constructos Simples (Mantienen sus ítems originales) ---\n",
        "    'CONCIENCIA PERSUASIÓN': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'ACTITUD': ['act_1', 'act_2', 'act_3'],\n",
        "    'INTENCIÓN DE COMPRA': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'ENGAGEMENT': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. CÁLCULO Y EVALUACIÓN (IGUAL QUE ANTES)\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_cronbach_alpha(itemscores):\n",
        "    itemscores = np.asarray(itemscores)\n",
        "    itemvars = itemscores.var(axis=0, ddof=1)\n",
        "    tscores = itemscores.sum(axis=1)\n",
        "    nitems = itemscores.shape[1]\n",
        "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))\n",
        "\n",
        "def interpretar_loading(val):\n",
        "    if val >= 0.70: return \"Ideal (≥ 0.70)\"\n",
        "    elif val >= 0.60: return \"Aceptable (0.60-0.70)\"\n",
        "    else: return \"Bajo (< 0.60)\"\n",
        "\n",
        "def interpretar_alpha_cr(val, tipo=\"Alpha\"):\n",
        "    if tipo == \"CR\" and val > 0.95: return \"Posible Redundancia (> 0.95)\"\n",
        "    if val >= 0.80: return \"Bueno (≥ 0.80)\"\n",
        "    elif val >= 0.70: return \"Aceptable (0.70-0.80)\"\n",
        "    else: return \"Bajo (< 0.70)\"\n",
        "\n",
        "def interpretar_ave(val):\n",
        "    if val >= 0.50: return \"Cumple (≥ 0.50)\"\n",
        "    else: return \"No Cumple (< 0.50)\"\n",
        "\n",
        "rows = []\n",
        "\n",
        "for construct, items in constructos_finales.items():\n",
        "    # Verificar columnas (ahora buscamos AVG_... o items normales)\n",
        "    valid_items = [col for col in items if col in df.columns]\n",
        "    if not valid_items: continue\n",
        "\n",
        "    block = df[valid_items].dropna()\n",
        "    n_muestra = len(block)\n",
        "    if block.empty: continue\n",
        "\n",
        "    # Alpha\n",
        "    alpha = calculate_cronbach_alpha(block)\n",
        "\n",
        "    # PCA para Loadings\n",
        "    pca = PCA(n_components=1)\n",
        "    latent_score = pca.fit_transform(block)\n",
        "    corrs = [np.corrcoef(block[col], latent_score[:, 0])[0, 1] for col in valid_items]\n",
        "    if np.mean(corrs) < 0: latent_score = -latent_score\n",
        "\n",
        "    loadings = []\n",
        "    for col in valid_items:\n",
        "        l = np.corrcoef(block[col], latent_score[:, 0])[0, 1]\n",
        "        loadings.append(l)\n",
        "    loadings = np.array(loadings)\n",
        "\n",
        "    # CR y AVE\n",
        "    ave = np.mean(loadings**2)\n",
        "    sum_l = np.sum(loadings)\n",
        "    cr = (sum_l**2) / ((sum_l**2) + np.sum(1 - loadings**2))\n",
        "\n",
        "    # --- FILAS ---\n",
        "    rows.append({\n",
        "        'Constructo / Indicador': f\"**{construct}**\",\n",
        "        'N': n_muestra,\n",
        "        'Métrica': 'Alfa de Cronbach',\n",
        "        'Valor': alpha,\n",
        "        'Interpretación': interpretar_alpha_cr(alpha, \"Alpha\")\n",
        "    })\n",
        "    rows.append({\n",
        "        'Constructo / Indicador': \"\", 'N': \"\", 'Métrica': 'Fiabilidad (CR)', 'Valor': cr,\n",
        "        'Interpretación': interpretar_alpha_cr(cr, \"CR\")\n",
        "    })\n",
        "    rows.append({\n",
        "        'Constructo / Indicador': \"\", 'N': \"\", 'Métrica': 'Varianza (AVE)', 'Valor': ave,\n",
        "        'Interpretación': interpretar_ave(ave)\n",
        "    })\n",
        "\n",
        "    for item, load in zip(valid_items, loadings):\n",
        "        # Limpiamos el nombre para que se vea bonito en la tabla\n",
        "        nombre_item = item.replace(\"AVG_\", \"Promedio \")\n",
        "        rows.append({\n",
        "            'Constructo / Indicador': f\"   - {nombre_item}\",\n",
        "            'N': \"\",\n",
        "            'Métrica': 'Carga (Loading)',\n",
        "            'Valor': load,\n",
        "            'Interpretación': interpretar_loading(load)\n",
        "        })\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. VISUALIZACIÓN FINAL\n",
        "# -----------------------------------------------------------------------------\n",
        "df_res = pd.DataFrame(rows)\n",
        "\n",
        "def color_semaforo(val):\n",
        "    if isinstance(val, str):\n",
        "        if \"Ideal\" in val or \"Bueno\" in val or \"Cumple\" in val:\n",
        "            return 'background-color: #d4edda; color: #155724'\n",
        "        elif \"Aceptable\" in val or \"Redundancia\" in val:\n",
        "            return 'background-color: #fff3cd; color: #856404'\n",
        "        elif \"Bajo\" in val or \"No Cumple\" in val:\n",
        "            return 'background-color: #f8d7da; color: #721c24'\n",
        "    return ''\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EVALUACIÓN DEL MODELO DE MEDICIÓN (ENFOQUE 2 ETAPAS - PROMEDIOS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "display(df_res.style\n",
        "    .applymap(color_semaforo, subset=['Interpretación'])\n",
        "    .format({'Valor': '{:.3f}'})\n",
        "    .hide(axis='index')\n",
        "    .set_properties(**{'text-align': 'left'})\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eIoQnFtJHLH7",
        "outputId": "352c3e05-6aaf-47c6-bb4b-cdf9fdf55655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando promedios de constructos de primer orden...\n",
            "================================================================================\n",
            "EVALUACIÓN DEL MODELO DE MEDICIÓN (ENFOQUE 2 ETAPAS - PROMEDIOS)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1599216459.py:164: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
            "  .applymap(color_semaforo, subset=['Interpretación'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79727d132f30>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_efa74_row0_col0, #T_efa74_row0_col1, #T_efa74_row0_col2, #T_efa74_row0_col3, #T_efa74_row1_col0, #T_efa74_row1_col1, #T_efa74_row1_col2, #T_efa74_row1_col3, #T_efa74_row2_col0, #T_efa74_row2_col1, #T_efa74_row2_col2, #T_efa74_row2_col3, #T_efa74_row3_col0, #T_efa74_row3_col1, #T_efa74_row3_col2, #T_efa74_row3_col3, #T_efa74_row4_col0, #T_efa74_row4_col1, #T_efa74_row4_col2, #T_efa74_row4_col3, #T_efa74_row5_col0, #T_efa74_row5_col1, #T_efa74_row5_col2, #T_efa74_row5_col3, #T_efa74_row6_col0, #T_efa74_row6_col1, #T_efa74_row6_col2, #T_efa74_row6_col3, #T_efa74_row7_col0, #T_efa74_row7_col1, #T_efa74_row7_col2, #T_efa74_row7_col3, #T_efa74_row8_col0, #T_efa74_row8_col1, #T_efa74_row8_col2, #T_efa74_row8_col3, #T_efa74_row9_col0, #T_efa74_row9_col1, #T_efa74_row9_col2, #T_efa74_row9_col3, #T_efa74_row10_col0, #T_efa74_row10_col1, #T_efa74_row10_col2, #T_efa74_row10_col3, #T_efa74_row11_col0, #T_efa74_row11_col1, #T_efa74_row11_col2, #T_efa74_row11_col3, #T_efa74_row12_col0, #T_efa74_row12_col1, #T_efa74_row12_col2, #T_efa74_row12_col3, #T_efa74_row13_col0, #T_efa74_row13_col1, #T_efa74_row13_col2, #T_efa74_row13_col3, #T_efa74_row14_col0, #T_efa74_row14_col1, #T_efa74_row14_col2, #T_efa74_row14_col3, #T_efa74_row15_col0, #T_efa74_row15_col1, #T_efa74_row15_col2, #T_efa74_row15_col3, #T_efa74_row16_col0, #T_efa74_row16_col1, #T_efa74_row16_col2, #T_efa74_row16_col3, #T_efa74_row17_col0, #T_efa74_row17_col1, #T_efa74_row17_col2, #T_efa74_row17_col3, #T_efa74_row18_col0, #T_efa74_row18_col1, #T_efa74_row18_col2, #T_efa74_row18_col3, #T_efa74_row19_col0, #T_efa74_row19_col1, #T_efa74_row19_col2, #T_efa74_row19_col3, #T_efa74_row20_col0, #T_efa74_row20_col1, #T_efa74_row20_col2, #T_efa74_row20_col3, #T_efa74_row21_col0, #T_efa74_row21_col1, #T_efa74_row21_col2, #T_efa74_row21_col3, #T_efa74_row22_col0, #T_efa74_row22_col1, #T_efa74_row22_col2, #T_efa74_row22_col3, #T_efa74_row23_col0, #T_efa74_row23_col1, #T_efa74_row23_col2, #T_efa74_row23_col3, #T_efa74_row24_col0, #T_efa74_row24_col1, #T_efa74_row24_col2, #T_efa74_row24_col3, #T_efa74_row25_col0, #T_efa74_row25_col1, #T_efa74_row25_col2, #T_efa74_row25_col3, #T_efa74_row26_col0, #T_efa74_row26_col1, #T_efa74_row26_col2, #T_efa74_row26_col3, #T_efa74_row27_col0, #T_efa74_row27_col1, #T_efa74_row27_col2, #T_efa74_row27_col3, #T_efa74_row28_col0, #T_efa74_row28_col1, #T_efa74_row28_col2, #T_efa74_row28_col3, #T_efa74_row29_col0, #T_efa74_row29_col1, #T_efa74_row29_col2, #T_efa74_row29_col3, #T_efa74_row30_col0, #T_efa74_row30_col1, #T_efa74_row30_col2, #T_efa74_row30_col3, #T_efa74_row31_col0, #T_efa74_row31_col1, #T_efa74_row31_col2, #T_efa74_row31_col3, #T_efa74_row32_col0, #T_efa74_row32_col1, #T_efa74_row32_col2, #T_efa74_row32_col3, #T_efa74_row33_col0, #T_efa74_row33_col1, #T_efa74_row33_col2, #T_efa74_row33_col3, #T_efa74_row34_col0, #T_efa74_row34_col1, #T_efa74_row34_col2, #T_efa74_row34_col3, #T_efa74_row35_col0, #T_efa74_row35_col1, #T_efa74_row35_col2, #T_efa74_row35_col3, #T_efa74_row36_col0, #T_efa74_row36_col1, #T_efa74_row36_col2, #T_efa74_row36_col3, #T_efa74_row37_col0, #T_efa74_row37_col1, #T_efa74_row37_col2, #T_efa74_row37_col3, #T_efa74_row38_col0, #T_efa74_row38_col1, #T_efa74_row38_col2, #T_efa74_row38_col3, #T_efa74_row39_col0, #T_efa74_row39_col1, #T_efa74_row39_col2, #T_efa74_row39_col3, #T_efa74_row40_col0, #T_efa74_row40_col1, #T_efa74_row40_col2, #T_efa74_row40_col3, #T_efa74_row41_col0, #T_efa74_row41_col1, #T_efa74_row41_col2, #T_efa74_row41_col3, #T_efa74_row42_col0, #T_efa74_row42_col1, #T_efa74_row42_col2, #T_efa74_row42_col3, #T_efa74_row43_col0, #T_efa74_row43_col1, #T_efa74_row43_col2, #T_efa74_row43_col3, #T_efa74_row44_col0, #T_efa74_row44_col1, #T_efa74_row44_col2, #T_efa74_row44_col3, #T_efa74_row45_col0, #T_efa74_row45_col1, #T_efa74_row45_col2, #T_efa74_row45_col3, #T_efa74_row46_col0, #T_efa74_row46_col1, #T_efa74_row46_col2, #T_efa74_row46_col3, #T_efa74_row47_col0, #T_efa74_row47_col1, #T_efa74_row47_col2, #T_efa74_row47_col3, #T_efa74_row48_col0, #T_efa74_row48_col1, #T_efa74_row48_col2, #T_efa74_row48_col3 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_efa74_row0_col4, #T_efa74_row1_col4, #T_efa74_row4_col4, #T_efa74_row6_col4, #T_efa74_row7_col4, #T_efa74_row9_col4, #T_efa74_row11_col4, #T_efa74_row12_col4, #T_efa74_row16_col4, #T_efa74_row17_col4, #T_efa74_row20_col4 {\n",
              "  background-color: #f8d7da;\n",
              "  color: #721c24;\n",
              "  text-align: left;\n",
              "}\n",
              "#T_efa74_row2_col4, #T_efa74_row5_col4, #T_efa74_row8_col4, #T_efa74_row10_col4, #T_efa74_row13_col4, #T_efa74_row14_col4, #T_efa74_row18_col4, #T_efa74_row19_col4, #T_efa74_row21_col4, #T_efa74_row22_col4, #T_efa74_row23_col4, #T_efa74_row24_col4, #T_efa74_row25_col4, #T_efa74_row26_col4, #T_efa74_row27_col4, #T_efa74_row28_col4, #T_efa74_row29_col4, #T_efa74_row30_col4, #T_efa74_row31_col4, #T_efa74_row32_col4, #T_efa74_row33_col4, #T_efa74_row34_col4, #T_efa74_row35_col4, #T_efa74_row36_col4, #T_efa74_row37_col4, #T_efa74_row38_col4, #T_efa74_row39_col4, #T_efa74_row40_col4, #T_efa74_row41_col4, #T_efa74_row42_col4, #T_efa74_row43_col4, #T_efa74_row44_col4, #T_efa74_row45_col4, #T_efa74_row46_col4, #T_efa74_row47_col4, #T_efa74_row48_col4 {\n",
              "  background-color: #d4edda;\n",
              "  color: #155724;\n",
              "  text-align: left;\n",
              "}\n",
              "#T_efa74_row3_col4, #T_efa74_row15_col4 {\n",
              "  background-color: #fff3cd;\n",
              "  color: #856404;\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_efa74\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_efa74_level0_col0\" class=\"col_heading level0 col0\" >Constructo / Indicador</th>\n",
              "      <th id=\"T_efa74_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
              "      <th id=\"T_efa74_level0_col2\" class=\"col_heading level0 col2\" >Métrica</th>\n",
              "      <th id=\"T_efa74_level0_col3\" class=\"col_heading level0 col3\" >Valor</th>\n",
              "      <th id=\"T_efa74_level0_col4\" class=\"col_heading level0 col4\" >Interpretación</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row0_col0\" class=\"data row0 col0\" >**CREDIBILIDAD**</td>\n",
              "      <td id=\"T_efa74_row0_col1\" class=\"data row0 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row0_col2\" class=\"data row0 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row0_col3\" class=\"data row0 col3\" >0.168</td>\n",
              "      <td id=\"T_efa74_row0_col4\" class=\"data row0 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row1_col0\" class=\"data row1 col0\" ></td>\n",
              "      <td id=\"T_efa74_row1_col1\" class=\"data row1 col1\" ></td>\n",
              "      <td id=\"T_efa74_row1_col2\" class=\"data row1 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row1_col3\" class=\"data row1 col3\" >0.618</td>\n",
              "      <td id=\"T_efa74_row1_col4\" class=\"data row1 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row2_col0\" class=\"data row2 col0\" ></td>\n",
              "      <td id=\"T_efa74_row2_col1\" class=\"data row2 col1\" ></td>\n",
              "      <td id=\"T_efa74_row2_col2\" class=\"data row2 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row2_col3\" class=\"data row2 col3\" >0.372</td>\n",
              "      <td id=\"T_efa74_row2_col4\" class=\"data row2 col4\" >No Cumple (< 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row3_col0\" class=\"data row3 col0\" >   - Promedio integridad</td>\n",
              "      <td id=\"T_efa74_row3_col1\" class=\"data row3 col1\" ></td>\n",
              "      <td id=\"T_efa74_row3_col2\" class=\"data row3 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row3_col3\" class=\"data row3 col3\" >0.697</td>\n",
              "      <td id=\"T_efa74_row3_col4\" class=\"data row3 col4\" >Aceptable (0.60-0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row4_col0\" class=\"data row4 col0\" >   - Promedio expertis</td>\n",
              "      <td id=\"T_efa74_row4_col1\" class=\"data row4 col1\" ></td>\n",
              "      <td id=\"T_efa74_row4_col2\" class=\"data row4 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row4_col3\" class=\"data row4 col3\" >0.322</td>\n",
              "      <td id=\"T_efa74_row4_col4\" class=\"data row4 col4\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row5_col0\" class=\"data row5 col0\" >   - Promedio autenticidad</td>\n",
              "      <td id=\"T_efa74_row5_col1\" class=\"data row5 col1\" ></td>\n",
              "      <td id=\"T_efa74_row5_col2\" class=\"data row5 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row5_col3\" class=\"data row5 col3\" >0.726</td>\n",
              "      <td id=\"T_efa74_row5_col4\" class=\"data row5 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row6_col0\" class=\"data row6 col0\" >**SEMEJANZA**</td>\n",
              "      <td id=\"T_efa74_row6_col1\" class=\"data row6 col1\" >238</td>\n",
              "      <td id=\"T_efa74_row6_col2\" class=\"data row6 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row6_col3\" class=\"data row6 col3\" >0.115</td>\n",
              "      <td id=\"T_efa74_row6_col4\" class=\"data row6 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row7_col0\" class=\"data row7 col0\" ></td>\n",
              "      <td id=\"T_efa74_row7_col1\" class=\"data row7 col1\" ></td>\n",
              "      <td id=\"T_efa74_row7_col2\" class=\"data row7 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row7_col3\" class=\"data row7 col3\" >0.593</td>\n",
              "      <td id=\"T_efa74_row7_col4\" class=\"data row7 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row8_col0\" class=\"data row8 col0\" ></td>\n",
              "      <td id=\"T_efa74_row8_col1\" class=\"data row8 col1\" ></td>\n",
              "      <td id=\"T_efa74_row8_col2\" class=\"data row8 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row8_col3\" class=\"data row8 col3\" >0.511</td>\n",
              "      <td id=\"T_efa74_row8_col4\" class=\"data row8 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row9_col0\" class=\"data row9 col0\" >   - Promedio atractividad</td>\n",
              "      <td id=\"T_efa74_row9_col1\" class=\"data row9 col1\" ></td>\n",
              "      <td id=\"T_efa74_row9_col2\" class=\"data row9 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row9_col3\" class=\"data row9 col3\" >0.204</td>\n",
              "      <td id=\"T_efa74_row9_col4\" class=\"data row9 col4\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row10_col0\" class=\"data row10 col0\" >   - Promedio similitud</td>\n",
              "      <td id=\"T_efa74_row10_col1\" class=\"data row10 col1\" ></td>\n",
              "      <td id=\"T_efa74_row10_col2\" class=\"data row10 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row10_col3\" class=\"data row10 col3\" >0.990</td>\n",
              "      <td id=\"T_efa74_row10_col4\" class=\"data row10 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row11_col0\" class=\"data row11 col0\" >**FLUJO DE INFORMACIÓN**</td>\n",
              "      <td id=\"T_efa74_row11_col1\" class=\"data row11 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row11_col2\" class=\"data row11 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row11_col3\" class=\"data row11 col3\" >0.047</td>\n",
              "      <td id=\"T_efa74_row11_col4\" class=\"data row11 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row12_col0\" class=\"data row12 col0\" ></td>\n",
              "      <td id=\"T_efa74_row12_col1\" class=\"data row12 col1\" ></td>\n",
              "      <td id=\"T_efa74_row12_col2\" class=\"data row12 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row12_col3\" class=\"data row12 col3\" >0.672</td>\n",
              "      <td id=\"T_efa74_row12_col4\" class=\"data row12 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row13_col0\" class=\"data row13 col0\" ></td>\n",
              "      <td id=\"T_efa74_row13_col1\" class=\"data row13 col1\" ></td>\n",
              "      <td id=\"T_efa74_row13_col2\" class=\"data row13 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row13_col3\" class=\"data row13 col3\" >0.511</td>\n",
              "      <td id=\"T_efa74_row13_col4\" class=\"data row13 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row14_col0\" class=\"data row14 col0\" >   - Promedio lider_de_opinion</td>\n",
              "      <td id=\"T_efa74_row14_col1\" class=\"data row14 col1\" ></td>\n",
              "      <td id=\"T_efa74_row14_col2\" class=\"data row14 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row14_col3\" class=\"data row14 col3\" >0.811</td>\n",
              "      <td id=\"T_efa74_row14_col4\" class=\"data row14 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row15_col0\" class=\"data row15 col0\" >   - Promedio informatividad_del_contenido</td>\n",
              "      <td id=\"T_efa74_row15_col1\" class=\"data row15 col1\" ></td>\n",
              "      <td id=\"T_efa74_row15_col2\" class=\"data row15 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row15_col3\" class=\"data row15 col3\" >0.604</td>\n",
              "      <td id=\"T_efa74_row15_col4\" class=\"data row15 col4\" >Aceptable (0.60-0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row16_col0\" class=\"data row16 col0\" >**CONGRUENCIA**</td>\n",
              "      <td id=\"T_efa74_row16_col1\" class=\"data row16 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row16_col2\" class=\"data row16 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row16_col3\" class=\"data row16 col3\" >-0.012</td>\n",
              "      <td id=\"T_efa74_row16_col4\" class=\"data row16 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row17_col0\" class=\"data row17 col0\" ></td>\n",
              "      <td id=\"T_efa74_row17_col1\" class=\"data row17 col1\" ></td>\n",
              "      <td id=\"T_efa74_row17_col2\" class=\"data row17 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row17_col3\" class=\"data row17 col3\" >0.492</td>\n",
              "      <td id=\"T_efa74_row17_col4\" class=\"data row17 col4\" >Bajo (< 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row18_col0\" class=\"data row18 col0\" ></td>\n",
              "      <td id=\"T_efa74_row18_col1\" class=\"data row18 col1\" ></td>\n",
              "      <td id=\"T_efa74_row18_col2\" class=\"data row18 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row18_col3\" class=\"data row18 col3\" >0.500</td>\n",
              "      <td id=\"T_efa74_row18_col4\" class=\"data row18 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row19_col0\" class=\"data row19 col0\" >   - Promedio congruencia_influencer_follower</td>\n",
              "      <td id=\"T_efa74_row19_col1\" class=\"data row19 col1\" ></td>\n",
              "      <td id=\"T_efa74_row19_col2\" class=\"data row19 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row19_col3\" class=\"data row19 col3\" >1.000</td>\n",
              "      <td id=\"T_efa74_row19_col4\" class=\"data row19 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row20_col0\" class=\"data row20 col0\" >   - Promedio congruencia_influencer_producto</td>\n",
              "      <td id=\"T_efa74_row20_col1\" class=\"data row20 col1\" ></td>\n",
              "      <td id=\"T_efa74_row20_col2\" class=\"data row20 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row20_col3\" class=\"data row20 col3\" >-0.016</td>\n",
              "      <td id=\"T_efa74_row20_col4\" class=\"data row20 col4\" >Bajo (< 0.60)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row21_col0\" class=\"data row21 col0\" >**CONCIENCIA PERSUASIÓN**</td>\n",
              "      <td id=\"T_efa74_row21_col1\" class=\"data row21 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row21_col2\" class=\"data row21 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row21_col3\" class=\"data row21 col3\" >0.853</td>\n",
              "      <td id=\"T_efa74_row21_col4\" class=\"data row21 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row22_col0\" class=\"data row22 col0\" ></td>\n",
              "      <td id=\"T_efa74_row22_col1\" class=\"data row22 col1\" ></td>\n",
              "      <td id=\"T_efa74_row22_col2\" class=\"data row22 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row22_col3\" class=\"data row22 col3\" >0.895</td>\n",
              "      <td id=\"T_efa74_row22_col4\" class=\"data row22 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row23_col0\" class=\"data row23 col0\" ></td>\n",
              "      <td id=\"T_efa74_row23_col1\" class=\"data row23 col1\" ></td>\n",
              "      <td id=\"T_efa74_row23_col2\" class=\"data row23 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row23_col3\" class=\"data row23 col3\" >0.630</td>\n",
              "      <td id=\"T_efa74_row23_col4\" class=\"data row23 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row24_col0\" class=\"data row24 col0\" >   - concp_1</td>\n",
              "      <td id=\"T_efa74_row24_col1\" class=\"data row24 col1\" ></td>\n",
              "      <td id=\"T_efa74_row24_col2\" class=\"data row24 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row24_col3\" class=\"data row24 col3\" >0.883</td>\n",
              "      <td id=\"T_efa74_row24_col4\" class=\"data row24 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row25_col0\" class=\"data row25 col0\" >   - concp_2</td>\n",
              "      <td id=\"T_efa74_row25_col1\" class=\"data row25 col1\" ></td>\n",
              "      <td id=\"T_efa74_row25_col2\" class=\"data row25 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row25_col3\" class=\"data row25 col3\" >0.844</td>\n",
              "      <td id=\"T_efa74_row25_col4\" class=\"data row25 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row26_col0\" class=\"data row26 col0\" >   - concp_3</td>\n",
              "      <td id=\"T_efa74_row26_col1\" class=\"data row26 col1\" ></td>\n",
              "      <td id=\"T_efa74_row26_col2\" class=\"data row26 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row26_col3\" class=\"data row26 col3\" >0.750</td>\n",
              "      <td id=\"T_efa74_row26_col4\" class=\"data row26 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row27_col0\" class=\"data row27 col0\" >   - concp_4</td>\n",
              "      <td id=\"T_efa74_row27_col1\" class=\"data row27 col1\" ></td>\n",
              "      <td id=\"T_efa74_row27_col2\" class=\"data row27 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row27_col3\" class=\"data row27 col3\" >0.735</td>\n",
              "      <td id=\"T_efa74_row27_col4\" class=\"data row27 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row28_col0\" class=\"data row28 col0\" >   - concp_5</td>\n",
              "      <td id=\"T_efa74_row28_col1\" class=\"data row28 col1\" ></td>\n",
              "      <td id=\"T_efa74_row28_col2\" class=\"data row28 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row28_col3\" class=\"data row28 col3\" >0.747</td>\n",
              "      <td id=\"T_efa74_row28_col4\" class=\"data row28 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row29_col0\" class=\"data row29 col0\" >**ACTITUD**</td>\n",
              "      <td id=\"T_efa74_row29_col1\" class=\"data row29 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row29_col2\" class=\"data row29 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row29_col3\" class=\"data row29 col3\" >0.845</td>\n",
              "      <td id=\"T_efa74_row29_col4\" class=\"data row29 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row30_col0\" class=\"data row30 col0\" ></td>\n",
              "      <td id=\"T_efa74_row30_col1\" class=\"data row30 col1\" ></td>\n",
              "      <td id=\"T_efa74_row30_col2\" class=\"data row30 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row30_col3\" class=\"data row30 col3\" >0.906</td>\n",
              "      <td id=\"T_efa74_row30_col4\" class=\"data row30 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row31_col0\" class=\"data row31 col0\" ></td>\n",
              "      <td id=\"T_efa74_row31_col1\" class=\"data row31 col1\" ></td>\n",
              "      <td id=\"T_efa74_row31_col2\" class=\"data row31 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row31_col3\" class=\"data row31 col3\" >0.764</td>\n",
              "      <td id=\"T_efa74_row31_col4\" class=\"data row31 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row32_col0\" class=\"data row32 col0\" >   - act_1</td>\n",
              "      <td id=\"T_efa74_row32_col1\" class=\"data row32 col1\" ></td>\n",
              "      <td id=\"T_efa74_row32_col2\" class=\"data row32 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row32_col3\" class=\"data row32 col3\" >0.883</td>\n",
              "      <td id=\"T_efa74_row32_col4\" class=\"data row32 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row33_col0\" class=\"data row33 col0\" >   - act_2</td>\n",
              "      <td id=\"T_efa74_row33_col1\" class=\"data row33 col1\" ></td>\n",
              "      <td id=\"T_efa74_row33_col2\" class=\"data row33 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row33_col3\" class=\"data row33 col3\" >0.833</td>\n",
              "      <td id=\"T_efa74_row33_col4\" class=\"data row33 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row34_col0\" class=\"data row34 col0\" >   - act_3</td>\n",
              "      <td id=\"T_efa74_row34_col1\" class=\"data row34 col1\" ></td>\n",
              "      <td id=\"T_efa74_row34_col2\" class=\"data row34 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row34_col3\" class=\"data row34 col3\" >0.905</td>\n",
              "      <td id=\"T_efa74_row34_col4\" class=\"data row34 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row35_col0\" class=\"data row35 col0\" >**INTENCIÓN DE COMPRA**</td>\n",
              "      <td id=\"T_efa74_row35_col1\" class=\"data row35 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row35_col2\" class=\"data row35 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row35_col3\" class=\"data row35 col3\" >0.854</td>\n",
              "      <td id=\"T_efa74_row35_col4\" class=\"data row35 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row36_col0\" class=\"data row36 col0\" ></td>\n",
              "      <td id=\"T_efa74_row36_col1\" class=\"data row36 col1\" ></td>\n",
              "      <td id=\"T_efa74_row36_col2\" class=\"data row36 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row36_col3\" class=\"data row36 col3\" >0.911</td>\n",
              "      <td id=\"T_efa74_row36_col4\" class=\"data row36 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row37_col0\" class=\"data row37 col0\" ></td>\n",
              "      <td id=\"T_efa74_row37_col1\" class=\"data row37 col1\" ></td>\n",
              "      <td id=\"T_efa74_row37_col2\" class=\"data row37 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row37_col3\" class=\"data row37 col3\" >0.774</td>\n",
              "      <td id=\"T_efa74_row37_col4\" class=\"data row37 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row38_col0\" class=\"data row38 col0\" >   - pred_1</td>\n",
              "      <td id=\"T_efa74_row38_col1\" class=\"data row38 col1\" ></td>\n",
              "      <td id=\"T_efa74_row38_col2\" class=\"data row38 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row38_col3\" class=\"data row38 col3\" >0.917</td>\n",
              "      <td id=\"T_efa74_row38_col4\" class=\"data row38 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row39_col0\" class=\"data row39 col0\" >   - pred_2</td>\n",
              "      <td id=\"T_efa74_row39_col1\" class=\"data row39 col1\" ></td>\n",
              "      <td id=\"T_efa74_row39_col2\" class=\"data row39 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row39_col3\" class=\"data row39 col3\" >0.872</td>\n",
              "      <td id=\"T_efa74_row39_col4\" class=\"data row39 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row40_col0\" class=\"data row40 col0\" >   - pred_3</td>\n",
              "      <td id=\"T_efa74_row40_col1\" class=\"data row40 col1\" ></td>\n",
              "      <td id=\"T_efa74_row40_col2\" class=\"data row40 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row40_col3\" class=\"data row40 col3\" >0.850</td>\n",
              "      <td id=\"T_efa74_row40_col4\" class=\"data row40 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row41_col0\" class=\"data row41 col0\" >**ENGAGEMENT**</td>\n",
              "      <td id=\"T_efa74_row41_col1\" class=\"data row41 col1\" >240</td>\n",
              "      <td id=\"T_efa74_row41_col2\" class=\"data row41 col2\" >Alfa de Cronbach</td>\n",
              "      <td id=\"T_efa74_row41_col3\" class=\"data row41 col3\" >0.831</td>\n",
              "      <td id=\"T_efa74_row41_col4\" class=\"data row41 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row42_col0\" class=\"data row42 col0\" ></td>\n",
              "      <td id=\"T_efa74_row42_col1\" class=\"data row42 col1\" ></td>\n",
              "      <td id=\"T_efa74_row42_col2\" class=\"data row42 col2\" >Fiabilidad (CR)</td>\n",
              "      <td id=\"T_efa74_row42_col3\" class=\"data row42 col3\" >0.881</td>\n",
              "      <td id=\"T_efa74_row42_col4\" class=\"data row42 col4\" >Bueno (≥ 0.80)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row43_col0\" class=\"data row43 col0\" ></td>\n",
              "      <td id=\"T_efa74_row43_col1\" class=\"data row43 col1\" ></td>\n",
              "      <td id=\"T_efa74_row43_col2\" class=\"data row43 col2\" >Varianza (AVE)</td>\n",
              "      <td id=\"T_efa74_row43_col3\" class=\"data row43 col3\" >0.598</td>\n",
              "      <td id=\"T_efa74_row43_col4\" class=\"data row43 col4\" >Cumple (≥ 0.50)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row44_col0\" class=\"data row44 col0\" >   - eng_1</td>\n",
              "      <td id=\"T_efa74_row44_col1\" class=\"data row44 col1\" ></td>\n",
              "      <td id=\"T_efa74_row44_col2\" class=\"data row44 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row44_col3\" class=\"data row44 col3\" >0.723</td>\n",
              "      <td id=\"T_efa74_row44_col4\" class=\"data row44 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row45_col0\" class=\"data row45 col0\" >   - eng_2</td>\n",
              "      <td id=\"T_efa74_row45_col1\" class=\"data row45 col1\" ></td>\n",
              "      <td id=\"T_efa74_row45_col2\" class=\"data row45 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row45_col3\" class=\"data row45 col3\" >0.817</td>\n",
              "      <td id=\"T_efa74_row45_col4\" class=\"data row45 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row46_col0\" class=\"data row46 col0\" >   - eng_3</td>\n",
              "      <td id=\"T_efa74_row46_col1\" class=\"data row46 col1\" ></td>\n",
              "      <td id=\"T_efa74_row46_col2\" class=\"data row46 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row46_col3\" class=\"data row46 col3\" >0.711</td>\n",
              "      <td id=\"T_efa74_row46_col4\" class=\"data row46 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row47_col0\" class=\"data row47 col0\" >   - eng_4</td>\n",
              "      <td id=\"T_efa74_row47_col1\" class=\"data row47 col1\" ></td>\n",
              "      <td id=\"T_efa74_row47_col2\" class=\"data row47 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row47_col3\" class=\"data row47 col3\" >0.817</td>\n",
              "      <td id=\"T_efa74_row47_col4\" class=\"data row47 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_efa74_row48_col0\" class=\"data row48 col0\" >   - eng_5</td>\n",
              "      <td id=\"T_efa74_row48_col1\" class=\"data row48 col1\" ></td>\n",
              "      <td id=\"T_efa74_row48_col2\" class=\"data row48 col2\" >Carga (Loading)</td>\n",
              "      <td id=\"T_efa74_row48_col3\" class=\"data row48 col3\" >0.791</td>\n",
              "      <td id=\"T_efa74_row48_col4\" class=\"data row48 col4\" >Ideal (≥ 0.70)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminant validity – Fornell–Larcker Criterion\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sk6LPJf3J28o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Esto tiene formato de código\n",
        "```\n",
        "\n",
        "#  Fornell–Larcker Criterion\n",
        "\n",
        "Solo constructos de primer orden"
      ],
      "metadata": {
        "id": "qsHCDNS8738G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ==========================================\n",
        "# 1. DICCIONARIO (PRIMER ORDEN)\n",
        "# ==========================================\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FUNCIONES DE CÁLCULO (AVE y Scores)\n",
        "# ==========================================\n",
        "\n",
        "def calcular_raiz_ave(df_data, items):\n",
        "    \"\"\"Estima la Raíz Cuadrada del AVE usando PCA.\"\"\"\n",
        "    # Extraemos solo los datos de este constructo y limpiamos nulos\n",
        "    data = df_data[items].dropna()\n",
        "\n",
        "    if data.shape[1] < 1: return np.nan\n",
        "\n",
        "    # PCA para estimar la varianza compartida (1er componente)\n",
        "    pca = PCA(n_components=1)\n",
        "    pca.fit(data)\n",
        "\n",
        "    # Obtenemos los scores del factor\n",
        "    scores = pca.transform(data).flatten()\n",
        "\n",
        "    # Calculamos cargas factoriales (correlación ítem-score)\n",
        "    cargas = [np.corrcoef(data[col], scores)[0,1] for col in items]\n",
        "    cargas = np.array(cargas)\n",
        "\n",
        "    # AVE = Suma de cargas al cuadrado / número de ítems\n",
        "    ave = np.sum(cargas**2) / len(items)\n",
        "    return np.sqrt(ave)\n",
        "\n",
        "# ==========================================\n",
        "# 3. EJECUCIÓN PRINCIPAL\n",
        "# ==========================================\n",
        "\n",
        "if 'df' not in locals():\n",
        "    print(\"❌ ERROR: Carga tus datos en la variable 'df' primero.\")\n",
        "else:\n",
        "    print(\"1. Procesando Fornell-Larcker...\")\n",
        "\n",
        "    # A) LIMPIEZA Y VALIDACIÓN\n",
        "    columnas_necesarias = [item for sublist in constructos_1er_orden.values() for item in sublist]\n",
        "    df_analisis = df[columnas_necesarias].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    print(f\"✅ Total de encuestados utilizados: {len(df_analisis)}\")\n",
        "\n",
        "    # B) CÁLCULO DE SCORES Y AVE\n",
        "    df_scores = pd.DataFrame()\n",
        "    diccionario_raiz_ave = {}\n",
        "\n",
        "    for nombre, items in constructos_1er_orden.items():\n",
        "        # 1. Score del constructo (Promedio simple)\n",
        "        df_scores[nombre] = df_analisis[items].mean(axis=1)\n",
        "\n",
        "        # 2. Raíz cuadrada del AVE\n",
        "        diccionario_raiz_ave[nombre] = calcular_raiz_ave(df_analisis, items)\n",
        "\n",
        "    # C) MATRIZ DE CORRELACIÓN\n",
        "    matriz_fl = df_scores.corr()\n",
        "\n",
        "    # D) SUSTITUCIÓN DE LA DIAGONAL\n",
        "    nombres = list(constructos_1er_orden.keys())\n",
        "    for nombre in nombres:\n",
        "        # Reemplazamos el 1.000 de la diagonal por la Raíz del AVE\n",
        "        matriz_fl.at[nombre, nombre] = diccionario_raiz_ave[nombre]\n",
        "\n",
        "    # E) FORMATO TRIANGULAR INFERIOR (Estilo Paper)\n",
        "    # Creamos máscara para borrar la parte de arriba\n",
        "    mask = np.triu(np.ones(matriz_fl.shape), k=1).astype(bool)\n",
        "    matriz_final = matriz_fl.mask(mask)\n",
        "\n",
        "    # Formateo visual\n",
        "    pd.options.display.float_format = '{:.3f}'.format\n",
        "    matriz_pretty = matriz_final.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CRITERIO FORNELL-LARCKER (Validez Discriminante)\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"DIAGONAL (Raíz AVE) > Fuera de Diagonal (Correlaciones)\")\n",
        "    print(\"-\" * 80)\n",
        "    print(matriz_pretty)\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. EXPORTAR A EXCEL\n",
        "    # ==========================================\n",
        "    nombre_archivo = 'Fornell_Larcker_Resultados.xlsx'\n",
        "    matriz_pretty.to_excel(nombre_archivo, index=True)\n",
        "    print(f\"\\n✅ Archivo '{nombre_archivo}' generado exitosamente.\")\n",
        "\n",
        "    # Descarga automática (si estás en Colab)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(nombre_archivo)\n",
        "    except ImportError:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "HS--5vwdLs68",
        "outputId": "0acd98eb-2cbd-4b33-f731-82241c3e5974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Procesando Fornell-Larcker...\n",
            "✅ Total de encuestados utilizados: 240\n",
            "\n",
            "================================================================================\n",
            "CRITERIO FORNELL-LARCKER (Validez Discriminante)\n",
            "================================================================================\n",
            "DIAGONAL (Raíz AVE) > Fuera de Diagonal (Correlaciones)\n",
            "--------------------------------------------------------------------------------\n",
            "                                     integridad expertis autenticidad atractividad similitud lider_de_opinion informatividad_del_contenido congruencia_influencer_follower congruencia_influencer_producto conciencia_de_la_persuasion actitud predisposicion_a_comprar_un_producto engagement\n",
            "integridad                                0.854                                                                                                                                                                                                                                               \n",
            "expertis                                  0.063    0.801                                                                                                                                                                                                                                      \n",
            "autenticidad                              0.084    0.041        0.874                                                                                                                                                                                                                         \n",
            "atractividad                              0.057    0.097        0.062        0.861                                                                                                                                                                                                            \n",
            "similitud                                -0.071   -0.057       -0.047        0.062     0.895                                                                                                                                                                                                  \n",
            "lider_de_opinion                          0.012    0.012        0.019       -0.035    -0.036            0.856                                                                                                                                                                                 \n",
            "informatividad_del_contenido             -0.023   -0.040       -0.075        0.021     0.097            0.024                        0.872                                                                                                                                                    \n",
            "congruencia_influencer_follower          -0.023    0.012        0.090       -0.043    -0.141            0.112                        0.036                           0.875                                                                                                                    \n",
            "congruencia_influencer_producto          -0.053    0.094       -0.028        0.004    -0.000            0.048                       -0.024                          -0.006                           0.878                                                                                    \n",
            "conciencia_de_la_persuasion               0.068   -0.005       -0.112        0.032     0.059           -0.098                       -0.084                           0.087                          -0.079                       0.794                                                        \n",
            "actitud                                  -0.024    0.084        0.055        0.029     0.106            0.001                        0.058                          -0.042                           0.068                       0.058   0.874                                                \n",
            "predisposicion_a_comprar_un_producto     -0.035   -0.052       -0.140       -0.096     0.017            0.026                        0.020                          -0.044                           0.047                       0.217   0.043                                0.880           \n",
            "engagement                                0.020    0.042       -0.121       -0.025     0.001            0.222                        0.104                          -0.043                           0.189                       0.084   0.049                                0.006      0.773\n",
            "\n",
            "✅ Archivo 'Fornell_Larcker_Resultados.xlsx' generado exitosamente.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1351667706.py:92: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  matriz_pretty = matriz_final.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f853a25-83eb-4ca5-a3df-1b6ac0498806\", \"Fornell_Larcker_Resultados.xlsx\", 5986)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fornell–Larcker Criterion\n",
        "solo utilizando Constructos de segundo Orden"
      ],
      "metadata": {
        "id": "YOEdByH3_hb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ==========================================\n",
        "# 1. DEFINICIÓN DE CONSTRUCTOS (1er y 2do Orden)\n",
        "# ==========================================\n",
        "\n",
        "# Tu diccionario base (Primer Orden)\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# Diccionario de Segundo Orden (Agrupación)\n",
        "constructos_2do_orden = {\n",
        "    'Credibilidad': (constructos_1er_orden['integridad'] +\n",
        "                     constructos_1er_orden['expertis'] +\n",
        "                     constructos_1er_orden['autenticidad']),\n",
        "\n",
        "    'Semejanza': (constructos_1er_orden['atractividad'] +\n",
        "                  constructos_1er_orden['similitud']),\n",
        "\n",
        "    'Flujo_de_informacion': (constructos_1er_orden['lider_de_opinion'] +\n",
        "                             constructos_1er_orden['informatividad_del_contenido']),\n",
        "\n",
        "    'Congruencia': (constructos_1er_orden['congruencia_influencer_follower'] +\n",
        "                    constructos_1er_orden['congruencia_influencer_producto']),\n",
        "\n",
        "    'Conciencia_Persuasion': constructos_1er_orden['conciencia_de_la_persuasion'],\n",
        "    'Actitud': constructos_1er_orden['actitud'],\n",
        "    'Intencion_Compra': constructos_1er_orden['predisposicion_a_comprar_un_producto'],\n",
        "    'Engagement': constructos_1er_orden['engagement']\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FUNCIÓN DE CÁLCULO (AVE con PCA)\n",
        "# ==========================================\n",
        "\n",
        "def calcular_raiz_ave(df_data, items):\n",
        "    \"\"\"\n",
        "    Calcula la Raíz Cuadrada del AVE para un grupo de ítems.\n",
        "    Usa PCA (1ra componente) para estimar la varianza compartida.\n",
        "    \"\"\"\n",
        "    # Extraer datos limpios para estos ítems\n",
        "    data = df_data[items].dropna()\n",
        "\n",
        "    if data.shape[1] < 1: return np.nan\n",
        "\n",
        "    # PCA para extraer el factor común\n",
        "    pca = PCA(n_components=1)\n",
        "    pca.fit(data)\n",
        "    scores = pca.transform(data).flatten()\n",
        "\n",
        "    # Cargas factoriales aproximadas (correlación ítem-score)\n",
        "    cargas = [np.corrcoef(data[col], scores)[0,1] for col in items]\n",
        "    cargas = np.array(cargas)\n",
        "\n",
        "    # Cálculo AVE\n",
        "    ave = np.sum(cargas**2) / len(items)\n",
        "    return np.sqrt(ave)\n",
        "\n",
        "# ==========================================\n",
        "# 3. EJECUCIÓN PRINCIPAL\n",
        "# ==========================================\n",
        "\n",
        "if 'df' not in locals():\n",
        "    print(\"❌ ERROR: Carga tus datos en la variable 'df' primero.\")\n",
        "else:\n",
        "    print(\"1. Iniciando análisis de Fornell-Larcker (2do Orden)...\")\n",
        "\n",
        "    # --- A) LIMPIEZA DE DATOS ---\n",
        "    # Recopilamos todos los ítems únicos necesarios desde el diccionario de 2do orden\n",
        "    todos_items = []\n",
        "    for items in constructos_2do_orden.values():\n",
        "        todos_items.extend(items)\n",
        "    todos_items = list(set(todos_items)) # Eliminar duplicados por seguridad\n",
        "\n",
        "    # Validar columnas\n",
        "    faltantes = [c for c in todos_items if c not in df.columns]\n",
        "    if faltantes:\n",
        "        print(f\"❌ ERROR: Faltan estas columnas en el Excel: {faltantes}\")\n",
        "    else:\n",
        "        # Crear sub-dataframe limpio y numérico\n",
        "        df_analisis = df[todos_items].apply(pd.to_numeric, errors='coerce')\n",
        "        print(f\"✅ Datos procesados: {len(df_analisis)} encuestados.\")\n",
        "\n",
        "        # --- B) CÁLCULOS POR CONSTRUCTO ---\n",
        "        df_scores = pd.DataFrame()\n",
        "        diccionario_raiz_ave = {}\n",
        "\n",
        "        print(\"2. Calculando AVEs y Scores agrupados...\")\n",
        "        for nombre, items in constructos_2do_orden.items():\n",
        "            # Score = Promedio de todos los ítems del constructo (o sub-constructos)\n",
        "            df_scores[nombre] = df_analisis[items].mean(axis=1)\n",
        "\n",
        "            # Raíz AVE = Calculada sobre el conjunto total de ítems\n",
        "            diccionario_raiz_ave[nombre] = calcular_raiz_ave(df_analisis, items)\n",
        "\n",
        "        # --- C) MATRIZ DE CORRELACIÓN Y FORNELL-LARCKER ---\n",
        "        # 1. Matriz base de correlaciones\n",
        "        matriz_fl = df_scores.corr()\n",
        "\n",
        "        # 2. Insertar Raíz AVE en la diagonal\n",
        "        nombres = list(constructos_2do_orden.keys())\n",
        "        for nombre in nombres:\n",
        "            matriz_fl.at[nombre, nombre] = diccionario_raiz_ave[nombre]\n",
        "\n",
        "        # 3. Máscara para dejar solo el triángulo inferior (estilo paper)\n",
        "        mask = np.triu(np.ones(matriz_fl.shape), k=1).astype(bool)\n",
        "        matriz_final = matriz_fl.mask(mask)\n",
        "\n",
        "        # 4. Formato bonito (3 decimales y espacios vacíos)\n",
        "        pd.options.display.float_format = '{:.3f}'.format\n",
        "        matriz_pretty = matriz_final.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CRITERIO FORNELL-LARCKER (CONSTRUCTOS DE 2DO ORDEN)\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Nota: La diagonal (negrita) es la Raíz Cuadrada del AVE.\")\n",
        "        print(\"Debe ser mayor que las correlaciones debajo de ella.\")\n",
        "        print(\"-\" * 80)\n",
        "        print(matriz_pretty)\n",
        "\n",
        "        # ==========================================\n",
        "        # 4. EXPORTAR A EXCEL\n",
        "        # ==========================================\n",
        "        nombre_archivo = 'Fornell_Larcker_2do_Orden.xlsx'\n",
        "        matriz_pretty.to_excel(nombre_archivo, index=True)\n",
        "        print(f\"\\n✅ Archivo generado: {nombre_archivo}\")\n",
        "\n",
        "        # Descarga automática en Colab\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            files.download(nombre_archivo)\n",
        "        except ImportError:\n",
        "            pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "x4ptP-jCNgXl",
        "outputId": "c6edd462-98e5-44da-e0bc-3d681efff218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Iniciando análisis de Fornell-Larcker (2do Orden)...\n",
            "✅ Datos procesados: 240 encuestados.\n",
            "2. Calculando AVEs y Scores agrupados...\n",
            "\n",
            "================================================================================\n",
            "CRITERIO FORNELL-LARCKER (CONSTRUCTOS DE 2DO ORDEN)\n",
            "================================================================================\n",
            "Nota: La diagonal (negrita) es la Raíz Cuadrada del AVE.\n",
            "Debe ser mayor que las correlaciones debajo de ella.\n",
            "--------------------------------------------------------------------------------\n",
            "                      Credibilidad Semejanza Flujo_de_informacion Congruencia Conciencia_Persuasion Actitud Intencion_Compra Engagement\n",
            "Credibilidad                 0.528                                                                                                     \n",
            "Semejanza                    0.022     0.622                                                                                           \n",
            "Flujo_de_informacion        -0.023     0.008                0.648                                                                      \n",
            "Congruencia                  0.032    -0.095                0.101       0.619                                                          \n",
            "Conciencia_Persuasion       -0.013     0.061               -0.127       0.020                 0.794                                    \n",
            "Actitud                      0.058     0.089                0.035       0.009                 0.058   0.874                            \n",
            "Intencion_Compra            -0.114    -0.058                0.033      -0.005                 0.217   0.043            0.880           \n",
            "Engagement                  -0.019    -0.017                0.238       0.084                 0.084   0.049            0.006      0.773\n",
            "\n",
            "✅ Archivo generado: Fornell_Larcker_2do_Orden.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-182786015.py:126: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  matriz_pretty = matriz_final.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3611137a-f0dd-4b0f-888a-496eb2248359\", \"Fornell_Larcker_2do_Orden.xlsx\", 5421)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTMT (Heterotrait-Monotrait Ratio)\n",
        "\n",
        "Solo constructos de primer orden"
      ],
      "metadata": {
        "id": "19yQf7dGBztb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. DICCIONARIO DE CONSTRUCTOS DE PRIMER ORDEN\n",
        "# ==========================================\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FUNCIÓN AUXILIAR DE CÁLCULO\n",
        "# ==========================================\n",
        "def get_avg_corr(corr_matrix, items_i, items_j=None):\n",
        "    \"\"\"Calcula la correlación promedio monotrait (ignorando diagonal) o heterotrait.\"\"\"\n",
        "    if items_j is None:\n",
        "        # Monotrait: Correlación interna del mismo constructo\n",
        "        sub_matrix = corr_matrix.loc[items_i, items_i].values\n",
        "        np.fill_diagonal(sub_matrix, np.nan)\n",
        "        return np.nanmean(sub_matrix)\n",
        "    else:\n",
        "        # Heterotrait: Correlación cruzada entre dos constructos\n",
        "        sub_matrix = corr_matrix.loc[items_i, items_j].values\n",
        "        return np.mean(sub_matrix)\n",
        "\n",
        "# ==========================================\n",
        "# 3. EJECUCIÓN PRINCIPAL\n",
        "# ==========================================\n",
        "\n",
        "if 'df' not in locals():\n",
        "    print(\"❌ ERROR: Por favor, carga tus datos en la variable 'df' primero (ej: df = pd.read_excel('tus_datos.xlsx'))\")\n",
        "else:\n",
        "    print(\"1. Procesando datos y calculando matriz HTMT...\")\n",
        "\n",
        "    # --- A) LIMPIEZA DE DATOS ---\n",
        "    # Obtenemos la lista de todas las columnas numéricas que necesitamos\n",
        "    columnas_necesarias = [item for sublist in constructos_1er_orden.values() for item in sublist]\n",
        "\n",
        "    # Verificamos que existan en el DataFrame\n",
        "    faltantes = [c for c in columnas_necesarias if c not in df.columns]\n",
        "    if faltantes:\n",
        "        print(f\"❌ ERROR: Las siguientes columnas del diccionario no están en tu Excel: {faltantes}\")\n",
        "    else:\n",
        "        # Creamos un nuevo DF solo con las columnas numéricas y forzamos la conversión\n",
        "        df_analisis = df[columnas_necesarias].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "        # --- B) CÁLCULO DE MATRIZ DE CORRELACIÓN ---\n",
        "        matriz_corr = df_analisis.corr()\n",
        "\n",
        "        nombres_constructos = list(constructos_1er_orden.keys())\n",
        "        n = len(nombres_constructos)\n",
        "\n",
        "        # Creamos el DataFrame para la matriz HTMT\n",
        "        matriz_htmt = pd.DataFrame(index=nombres_constructos, columns=nombres_constructos, dtype=float)\n",
        "\n",
        "        # Pre-calculamos los promedios monotrait para eficiencia\n",
        "        avg_mono_corr = {}\n",
        "        for nombre, items in constructos_1er_orden.items():\n",
        "            avg_mono_corr[nombre] = get_avg_corr(matriz_corr, items)\n",
        "\n",
        "        # Llenamos la matriz HTMT\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n): # Solo calculamos el triángulo superior\n",
        "                name_i = nombres_constructos[i]\n",
        "                name_j = nombres_constructos[j]\n",
        "\n",
        "                # Numerador: Correlación promedio Heterotrait\n",
        "                hetero_corr = get_avg_corr(matriz_corr, constructos_1er_orden[name_i], constructos_1er_orden[name_j])\n",
        "\n",
        "                # Denominador: Media geométrica de las correlaciones promedio Monotrait\n",
        "                denom = np.sqrt(avg_mono_corr[name_i] * avg_mono_corr[name_j])\n",
        "\n",
        "                if denom == 0:\n",
        "                    htmt_val = np.nan\n",
        "                else:\n",
        "                    htmt_val = hetero_corr / denom\n",
        "\n",
        "                # Guardamos el valor simétricamente\n",
        "                matriz_htmt.at[name_i, name_j] = htmt_val\n",
        "                matriz_htmt.at[name_j, name_i] = htmt_val\n",
        "\n",
        "        # --- C) FORMATEO COMO TABLA TRIANGULAR INFERIOR ---\n",
        "\n",
        "        # 1. Crear una máscara para el triángulo superior y la diagonal principal\n",
        "        mask = np.triu(np.ones(matriz_htmt.shape), k=0).astype(bool)\n",
        "\n",
        "        # 2. Aplicar la máscara: Reemplazar los valores enmascarados por NaN\n",
        "        matriz_triangular = matriz_htmt.mask(mask)\n",
        "\n",
        "        # 3. Configurar el formato de visualización a 3 decimales\n",
        "        pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "        # 4. Opcional: Reemplazar NaN por cadenas vacías \"\" para una salida más limpia, similar a la imagen\n",
        "        # Esto convierte los números a cadenas, así que el formato float anterior no aplicará.\n",
        "        # Lo formateamos manualmente.\n",
        "        matriz_final_str = matriz_triangular.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"TABLA 4. VALIDEZ DISCRIMINANTE – HETEROTRAIT–MONOTRAIT RATIO (HTMT)\")\n",
        "        print(\"=\"*80)\n",
        "        print(matriz_final_str)\n",
        "        print(\"\\nCriterio de Validez Discriminante: Los valores HTMT deben ser inferiores a 0.85 (o 0.90 para criterios más flexibles) para indicar que los constructos son distintos.\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 4. EXPORTAR A EXCEL\n",
        "# ==========================================\n",
        "\n",
        "nombre_archivo = 'Matriz_HTMT_Resultados.xlsx'\n",
        "\n",
        "# 1. Guardar el DataFrame en un archivo Excel\n",
        "# 'index=True' es importante para que se guarden los nombres de las filas\n",
        "matriz_final_str.to_excel(nombre_archivo, index=True)\n",
        "\n",
        "print(f\"✅ Archivo '{nombre_archivo}' generado exitosamente.\")\n",
        "\n",
        "# 2. Intentar descargar automáticamente (Solo funciona en Google Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(nombre_archivo)\n",
        "    print(\"⬇️ Iniciando descarga...\")\n",
        "except ImportError:\n",
        "    # Si no estás en Colab (ej. Jupyter local), el archivo ya se guardó en tu carpeta\n",
        "    print(f\"📂 El archivo se ha guardado en tu carpeta local como: {nombre_archivo}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "zoOMSZ9EK0hg",
        "outputId": "927f3dd8-42f6-4b9d-d19e-edb76f466613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Procesando datos y calculando matriz HTMT...\n",
            "\n",
            "================================================================================\n",
            "TABLA 4. VALIDEZ DISCRIMINANTE – HETEROTRAIT–MONOTRAIT RATIO (HTMT)\n",
            "================================================================================\n",
            "                                     integridad expertis autenticidad atractividad similitud lider_de_opinion informatividad_del_contenido congruencia_influencer_follower congruencia_influencer_producto conciencia_de_la_persuasion actitud predisposicion_a_comprar_un_producto engagement\n",
            "integridad                                                                                                                                                                                                                                                                                    \n",
            "expertis                                  0.077                                                                                                                                                                                                                                               \n",
            "autenticidad                              0.097    0.051                                                                                                                                                                                                                                      \n",
            "atractividad                              0.064    0.117        0.073                                                                                                                                                                                                                         \n",
            "similitud                                -0.083   -0.069       -0.055        0.065                                                                                                                                                                                                            \n",
            "lider_de_opinion                          0.010    0.014        0.022       -0.042    -0.038                                                                                                                                                                                                  \n",
            "informatividad_del_contenido             -0.027   -0.046       -0.090        0.021     0.118            0.029                                                                                                                                                                                 \n",
            "congruencia_influencer_follower          -0.028    0.009        0.108       -0.051    -0.165            0.132                        0.051                                                                                                                                                    \n",
            "congruencia_influencer_producto          -0.059    0.113       -0.033        0.005    -0.002            0.054                       -0.030                          -0.008                                                                                                                    \n",
            "conciencia_de_la_persuasion               0.075    0.003       -0.120        0.040     0.066           -0.115                       -0.103                           0.098                          -0.096                                                                                    \n",
            "actitud                                  -0.027    0.104        0.060        0.028     0.117            0.001                        0.068                          -0.044                           0.079                       0.065                                                        \n",
            "predisposicion_a_comprar_un_producto     -0.041   -0.058       -0.170       -0.109     0.021            0.033                        0.018                          -0.054                           0.054                       0.248   0.049                                                \n",
            "engagement                                0.026    0.056       -0.142       -0.028     0.006            0.259                        0.120                          -0.049                           0.222                       0.100   0.061                                0.009           \n",
            "\n",
            "Criterio de Validez Discriminante: Los valores HTMT deben ser inferiores a 0.85 (o 0.90 para criterios más flexibles) para indicar que los constructos son distintos.\n",
            "✅ Archivo 'Matriz_HTMT_Resultados.xlsx' generado exitosamente.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1409335012.py:108: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  matriz_final_str = matriz_triangular.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd936f40-91dc-4989-8684-81d44e21695a\", \"Matriz_HTMT_Resultados.xlsx\", 5956)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Iniciando descarga...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HTMT (Heterotrait-Monotrait Ratio)\n",
        "\n",
        "Solo constructos de segundo orden"
      ],
      "metadata": {
        "id": "NHke5wqlOEb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. DEFINICIÓN DE CONSTRUCTOS\n",
        "# ==========================================\n",
        "\n",
        "# Tu diccionario base (Primer Orden)\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# Diccionario de Segundo Orden (Agrupación)\n",
        "constructos_2do_orden = {\n",
        "    # Agrupados\n",
        "    'Credibilidad': (constructos_1er_orden['integridad'] +\n",
        "                     constructos_1er_orden['expertis'] +\n",
        "                     constructos_1er_orden['autenticidad']),\n",
        "\n",
        "    'Semejanza': (constructos_1er_orden['atractividad'] +\n",
        "                  constructos_1er_orden['similitud']),\n",
        "\n",
        "    'Flujo_de_informacion': (constructos_1er_orden['lider_de_opinion'] +\n",
        "                             constructos_1er_orden['informatividad_del_contenido']),\n",
        "\n",
        "    'Congruencia': (constructos_1er_orden['congruencia_influencer_follower'] +\n",
        "                    constructos_1er_orden['congruencia_influencer_producto']),\n",
        "\n",
        "    # Individuales mantenidos\n",
        "    'Conciencia_Persuasion': constructos_1er_orden['conciencia_de_la_persuasion'],\n",
        "    'Actitud': constructos_1er_orden['actitud'],\n",
        "    'Intencion_Compra': constructos_1er_orden['predisposicion_a_comprar_un_producto'],\n",
        "    'Engagement': constructos_1er_orden['engagement']\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. FUNCIÓN DE CÁLCULO HTMT\n",
        "# ==========================================\n",
        "def get_avg_corr(corr_matrix, items_i, items_j=None):\n",
        "    \"\"\"Calcula la correlación promedio (HTMT logic).\"\"\"\n",
        "    if items_j is None:\n",
        "        # Monotrait: Correlación interna (ignorando la diagonal 1.0)\n",
        "        sub_matrix = corr_matrix.loc[items_i, items_i].values\n",
        "        np.fill_diagonal(sub_matrix, np.nan)\n",
        "        return np.nanmean(sub_matrix)\n",
        "    else:\n",
        "        # Heterotrait: Correlación cruzada\n",
        "        sub_matrix = corr_matrix.loc[items_i, items_j].values\n",
        "        return np.mean(sub_matrix)\n",
        "\n",
        "# ==========================================\n",
        "# 3. EJECUCIÓN PRINCIPAL\n",
        "# ==========================================\n",
        "\n",
        "if 'df' not in locals():\n",
        "    print(\"❌ ERROR: Carga tus datos en la variable 'df' primero.\")\n",
        "else:\n",
        "    print(\"1. Procesando HTMT para 2do Orden...\")\n",
        "\n",
        "    # --- A) LIMPIEZA DE DATOS (Lista Blanca) ---\n",
        "    # Recopilamos TODOS los ítems involucrados en los constructos de 2do orden\n",
        "    todos_items = []\n",
        "    for items in constructos_2do_orden.values():\n",
        "        todos_items.extend(items)\n",
        "    todos_items = list(set(todos_items)) # Eliminamos duplicados\n",
        "\n",
        "    # Validamos existencia en el Excel\n",
        "    faltantes = [c for c in todos_items if c not in df.columns]\n",
        "\n",
        "    if faltantes:\n",
        "        print(f\"❌ ERROR: Faltan columnas en tu Excel: {faltantes}\")\n",
        "    else:\n",
        "        # Creamos subset numérico limpio\n",
        "        df_analisis = df[todos_items].apply(pd.to_numeric, errors='coerce')\n",
        "        print(f\"✅ Total encuestados analizados: {len(df_analisis)}\")\n",
        "\n",
        "        # --- B) CÁLCULO DE MATRIZ DE CORRELACIÓN ---\n",
        "        # Calculamos correlación de ítems sobre todos los datos\n",
        "        matriz_corr_items = df_analisis.corr()\n",
        "\n",
        "        nombres_constructos = list(constructos_2do_orden.keys())\n",
        "        n = len(nombres_constructos)\n",
        "\n",
        "        # DataFrame vacío para resultados\n",
        "        matriz_htmt = pd.DataFrame(index=nombres_constructos, columns=nombres_constructos, dtype=float)\n",
        "\n",
        "        # Pre-calculamos Monotraits (promedio correlación interna de cada constructo de 2do orden)\n",
        "        avg_mono_corr = {}\n",
        "        for nombre, items in constructos_2do_orden.items():\n",
        "            avg_mono_corr[nombre] = get_avg_corr(matriz_corr_items, items)\n",
        "\n",
        "        # --- C) CÁLCULO HTMT ---\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                name_i = nombres_constructos[i]\n",
        "                name_j = nombres_constructos[j]\n",
        "\n",
        "                # 1. Heterotrait (Correlación cruzada entre los dos grupos de ítems)\n",
        "                hetero_corr = get_avg_corr(matriz_corr_items,\n",
        "                                         constructos_2do_orden[name_i],\n",
        "                                         constructos_2do_orden[name_j])\n",
        "\n",
        "                # 2. Denominador (Media geométrica de los Monotraits)\n",
        "                denom = np.sqrt(avg_mono_corr[name_i] * avg_mono_corr[name_j])\n",
        "\n",
        "                if denom == 0:\n",
        "                    htmt_val = np.nan\n",
        "                else:\n",
        "                    htmt_val = hetero_corr / denom\n",
        "\n",
        "                # Guardamos simétricamente\n",
        "                matriz_htmt.at[name_i, name_j] = htmt_val\n",
        "                matriz_htmt.at[name_j, name_i] = htmt_val\n",
        "\n",
        "        # --- D) FORMATO VISUAL (Triangular Inferior) ---\n",
        "        mask = np.triu(np.ones(matriz_htmt.shape), k=0).astype(bool)\n",
        "        matriz_triangular = matriz_htmt.mask(mask)\n",
        "\n",
        "        pd.options.display.float_format = '{:.3f}'.format\n",
        "        matriz_pretty = matriz_triangular.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"HTMT RATIO - CONSTRUCTOS DE 2DO ORDEN\")\n",
        "        print(\"=\"*80)\n",
        "        print(matriz_pretty)\n",
        "        print(\"\\nNota: Valores < 0.85 (o 0.90) indican validez discriminante establecida.\")\n",
        "\n",
        "        # ==========================================\n",
        "        # 4. EXPORTAR A EXCEL\n",
        "        # ==========================================\n",
        "        nombre_archivo = 'HTMT_2do_Orden.xlsx'\n",
        "        matriz_pretty.to_excel(nombre_archivo, index=True)\n",
        "        print(f\"\\n✅ Archivo generado: {nombre_archivo}\")\n",
        "\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            files.download(nombre_archivo)\n",
        "        except ImportError:\n",
        "            pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "xjv0YWroOBa1",
        "outputId": "a6dd0f85-4a5b-4101-d872-2b9b6dbe8d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Procesando HTMT para 2do Orden...\n",
            "✅ Total encuestados analizados: 240\n",
            "\n",
            "================================================================================\n",
            "HTMT RATIO - CONSTRUCTOS DE 2DO ORDEN\n",
            "================================================================================\n",
            "                      Credibilidad Semejanza Flujo_de_informacion Congruencia Conciencia_Persuasion Actitud Intencion_Compra Engagement\n",
            "Credibilidad                                                                                                                           \n",
            "Semejanza                    0.043                                                                                                     \n",
            "Flujo_de_informacion        -0.036     0.009                                                                                           \n",
            "Congruencia                  0.042    -0.115                0.137                                                                      \n",
            "Conciencia_Persuasion       -0.008     0.076               -0.164       0.001                                                          \n",
            "Actitud                      0.074     0.098                0.045       0.028                 0.065                                    \n",
            "Intencion_Compra            -0.146    -0.076                0.040       0.001                 0.248   0.049                            \n",
            "Engagement                  -0.020    -0.020                0.299       0.138                 0.100   0.061            0.009           \n",
            "\n",
            "Nota: Valores < 0.85 (o 0.90) indican validez discriminante establecida.\n",
            "\n",
            "✅ Archivo generado: HTMT_2do_Orden.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-390569194.py:132: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  matriz_pretty = matriz_triangular.applymap(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else '')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_37d1ffc8-0f52-47a9-88b0-730721d6d8c9\", \"HTMT_2do_Orden.xlsx\", 5393)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# MODELADO SEM PLS\n",
        "\n",
        "Consytructos de primer orden\n",
        "```\n",
        "\n",
        "# Modelado SEM PLS  \n",
        "\n",
        "Solo constructos de primer orden"
      ],
      "metadata": {
        "id": "1ZxU2hPkXwZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Constrcutso de Primer orden\n",
        "\n",
        "Path Analysis (Análisis de Senderos) utilizando el enfoque Two-Stage (Dos Etapas).\n"
      ],
      "metadata": {
        "id": "jRhUUTaqsE5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# ==========================================\n",
        "# 1. DICCIONARIO (PRIMER ORDEN)\n",
        "# ==========================================\n",
        "constructos_1er_orden = {\n",
        "    'integridad': ['int_1', 'int_2', 'int_3', 'int_4'],\n",
        "    'expertis': ['exp_1', 'exp_2', 'exp_3', 'exp_4'],\n",
        "    'autenticidad': ['aut_1', 'aut_2', 'aut_3'],\n",
        "    'atractividad': ['att_1', 'att_2', 'att_3', 'att_4'],\n",
        "    'similitud': ['sim_1', 'sim_2', 'sim_3'],\n",
        "    'lider_de_opinion': ['lid_1', 'lid_2', 'lid_3', 'lid_4'],\n",
        "    'informatividad_del_contenido': ['inf_1', 'inf_2', 'inf_3'],\n",
        "    'congruencia_influencer_follower': ['congf_1', 'congf_2', 'congf_3'],\n",
        "    'congruencia_influencer_producto': ['congp_1', 'congp_2', 'congp_3'],\n",
        "    'conciencia_de_la_persuasion': ['concp_1', 'concp_2', 'concp_3', 'concp_4', 'concp_5'],\n",
        "    'actitud': ['act_1', 'act_2', 'act_3'],\n",
        "    'predisposicion_a_comprar_un_producto': ['pred_1', 'pred_2', 'pred_3'],\n",
        "    'engagement': ['eng_1', 'eng_2', 'eng_3', 'eng_4', 'eng_5']\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. PROCESAMIENTO ROBUSTO (ETAPA 1)\n",
        "# ==========================================\n",
        "\n",
        "if 'df' not in locals():\n",
        "    print(\"❌ ERROR: Carga tus datos en 'df' primero.\")\n",
        "else:\n",
        "    print(\"1. Calculando Scores Latentes (Etapa 1)...\")\n",
        "\n",
        "    # A) Limpieza Inicial de Columnas\n",
        "    todos_items = [item for sublist in constructos_1er_orden.values() for item in sublist]\n",
        "    # Forzamos conversión a numérico y los errores se vuelven NaN\n",
        "    df_clean = df[todos_items].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # B) Cálculo de Scores Promedio\n",
        "    df_scores = pd.DataFrame()\n",
        "    for nombre, items in constructos_1er_orden.items():\n",
        "        # Calculamos promedio ignorando nulos parciales\n",
        "        df_scores[nombre] = df_clean[items].mean(axis=1)\n",
        "\n",
        "    # C) LIMPIEZA CRÍTICA (Aquí estaba el error)\n",
        "    # Eliminamos filas que tengan CUALQUIER constructo vacío (NaN)\n",
        "    n_antes = len(df_scores)\n",
        "    df_scores = df_scores.dropna()\n",
        "    n_despues = len(df_scores)\n",
        "\n",
        "    if n_antes != n_despues:\n",
        "        print(f\"⚠️ Se eliminaron {n_antes - n_despues} encuestados por tener datos incompletos en los constructos.\")\n",
        "\n",
        "    print(f\"✅ Muestra final válida para el modelo: {n_despues} respuestas.\")\n",
        "\n",
        "    if n_despues < 10:\n",
        "        print(\"❌ ERROR CRÍTICO: Te has quedado sin datos suficientes. Revisa si tus columnas del Excel están vacías.\")\n",
        "    else:\n",
        "        # D) Estandarización (Z-Scores)\n",
        "        # Usamos un manejo seguro para evitar divisiones por cero\n",
        "        desviaciones = df_scores.std()\n",
        "        cols_sin_varianza = desviaciones[desviaciones == 0].index\n",
        "\n",
        "        if len(cols_sin_varianza) > 0:\n",
        "            print(f\"⚠️ Las siguientes variables son constantes (varianza 0) y se eliminarán: {list(cols_sin_varianza)}\")\n",
        "            df_scores = df_scores.drop(columns=cols_sin_varianza)\n",
        "\n",
        "        df_z = (df_scores - df_scores.mean()) / df_scores.std()\n",
        "\n",
        "        # Limpieza final de seguridad (infinitos)\n",
        "        df_z = df_z.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "        print(\"✅ Scores estandarizados correctamente.\")\n",
        "\n",
        "        # ==========================================\n",
        "        # 3. MODELADO ESTRUCTURAL (ETAPA 2)\n",
        "        # ==========================================\n",
        "\n",
        "        # Variables predictoras (Drivers)\n",
        "        drivers = [\n",
        "            'integridad', 'expertis', 'autenticidad', 'atractividad', 'similitud',\n",
        "            'lider_de_opinion', 'informatividad_del_contenido',\n",
        "            'congruencia_influencer_follower', 'congruencia_influencer_producto'\n",
        "        ]\n",
        "\n",
        "        villano = 'conciencia_de_la_persuasion'\n",
        "\n",
        "        # Función auxiliar para correr modelos de forma segura\n",
        "        def correr_modelo(y_name, x_names, data):\n",
        "            # Verificar que todas las columnas existan (por si se borró alguna por varianza 0)\n",
        "            cols_disponibles = [c for c in x_names if c in data.columns]\n",
        "\n",
        "            if y_name not in data.columns:\n",
        "                print(f\"❌ No se puede calcular modelo para '{y_name}' (Variable eliminada o inexistente).\")\n",
        "                return None\n",
        "\n",
        "            X = data[cols_disponibles]\n",
        "            y = data[y_name]\n",
        "            X = sm.add_constant(X) # Agregar intercepto\n",
        "\n",
        "            # missing='drop' es una red de seguridad extra de statsmodels\n",
        "            try:\n",
        "                model = sm.OLS(y, X, missing='drop').fit()\n",
        "                return model\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error al ajustar modelo {y_name}: {e}\")\n",
        "                return None\n",
        "\n",
        "        # --- MODELO A: Impacto en ACTITUD ---\n",
        "        model_actitud = correr_modelo('actitud', drivers + [villano], df_z)\n",
        "\n",
        "        # --- MODELO B: Impacto en ENGAGEMENT ---\n",
        "        model_eng = correr_modelo('engagement', drivers + [villano], df_z)\n",
        "\n",
        "        # --- MODELO C: Impacto en INTENCIÓN DE COMPRA ---\n",
        "        # Drivers aquí son los mediadores + villano\n",
        "        mediadores = ['actitud', 'engagement']\n",
        "        model_compra = correr_modelo('predisposicion_a_comprar_un_producto', mediadores + [villano], df_z)\n",
        "\n",
        "        # ==========================================\n",
        "        # 4. REPORTE DE RESULTADOS\n",
        "        # ==========================================\n",
        "\n",
        "        def imprimir_resumen_bonito(modelo, titulo):\n",
        "            if modelo is None: return\n",
        "\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"RESULTADOS: {titulo}\")\n",
        "            print(f\"R-Cuadrado (Poder Explicativo): {modelo.rsquared:.3f}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"{'Variable':<35} | {'Beta':<8} | {'P-Value':<8} | {'Sig?'}\")\n",
        "            print(\"-\" * 75)\n",
        "\n",
        "            params = modelo.params\n",
        "            pvalues = modelo.pvalues\n",
        "\n",
        "            # Ordenar por magnitud de impacto (absoluto) para ver lo más importante primero\n",
        "            vars_sorted = params.abs().sort_values(ascending=False).index\n",
        "\n",
        "            for variable in vars_sorted:\n",
        "                if variable == 'const': continue\n",
        "\n",
        "                beta = params[variable]\n",
        "                p = pvalues[variable]\n",
        "\n",
        "                sig = \"\"\n",
        "                if p < 0.001: sig = \"***\"\n",
        "                elif p < 0.01: sig = \"**\"\n",
        "                elif p < 0.05: sig = \"*\"\n",
        "                else: sig = \"\"\n",
        "\n",
        "                print(f\"{variable:<35} | {beta:>8.3f} | {p:>8.3f} | {sig}\")\n",
        "\n",
        "        # Imprimir reportes\n",
        "        imprimir_resumen_bonito(model_actitud, \"IMPACTO -> ACTITUD\")\n",
        "        imprimir_resumen_bonito(model_eng, \"IMPACTO -> ENGAGEMENT\")\n",
        "        imprimir_resumen_bonito(model_compra, \"IMPACTO -> INTENCIÓN COMPRA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh610Pmj1MRj",
        "outputId": "28e5a5a0-5c1c-4ed3-f8c4-6e40d560d78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Calculando Scores Latentes (Etapa 1)...\n",
            "⚠️ Se eliminaron 2 encuestados por tener datos incompletos en los constructos.\n",
            "✅ Muestra final válida para el modelo: 238 respuestas.\n",
            "✅ Scores estandarizados correctamente.\n",
            "\n",
            "============================================================\n",
            "RESULTADOS: IMPACTO -> ACTITUD\n",
            "R-Cuadrado (Poder Explicativo): 0.037\n",
            "============================================================\n",
            "Variable                            | Beta     | P-Value  | Sig?\n",
            "---------------------------------------------------------------------------\n",
            "similitud                           |    0.095 |    0.155 | \n",
            "expertis                            |    0.089 |    0.181 | \n",
            "conciencia_de_la_persuasion         |    0.086 |    0.202 | \n",
            "autenticidad                        |    0.076 |    0.256 | \n",
            "informatividad_del_contenido        |    0.064 |    0.334 | \n",
            "congruencia_influencer_producto     |    0.058 |    0.380 | \n",
            "congruencia_influencer_follower     |   -0.046 |    0.492 | \n",
            "integridad                          |   -0.033 |    0.618 | \n",
            "lider_de_opinion                    |    0.017 |    0.795 | \n",
            "atractividad                        |    0.005 |    0.934 | \n",
            "\n",
            "============================================================\n",
            "RESULTADOS: IMPACTO -> ENGAGEMENT\n",
            "R-Cuadrado (Poder Explicativo): 0.092\n",
            "============================================================\n",
            "Variable                            | Beta     | P-Value  | Sig?\n",
            "---------------------------------------------------------------------------\n",
            "lider_de_opinion                    |    0.203 |    0.002 | **\n",
            "congruencia_influencer_producto     |    0.148 |    0.021 | *\n",
            "informatividad_del_contenido        |    0.121 |    0.061 | \n",
            "conciencia_de_la_persuasion         |    0.110 |    0.095 | \n",
            "congruencia_influencer_follower     |   -0.085 |    0.193 | \n",
            "autenticidad                        |   -0.076 |    0.239 | \n",
            "integridad                          |    0.034 |    0.599 | \n",
            "atractividad                        |   -0.024 |    0.704 | \n",
            "similitud                           |   -0.020 |    0.753 | \n",
            "expertis                            |   -0.002 |    0.970 | \n",
            "\n",
            "============================================================\n",
            "RESULTADOS: IMPACTO -> INTENCIÓN COMPRA\n",
            "R-Cuadrado (Poder Explicativo): 0.046\n",
            "============================================================\n",
            "Variable                            | Beta     | P-Value  | Sig?\n",
            "---------------------------------------------------------------------------\n",
            "conciencia_de_la_persuasion         |    0.209 |    0.001 | **\n",
            "actitud                             |    0.034 |    0.597 | \n",
            "engagement                          |   -0.034 |    0.598 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# PLS-SEM (Mode A) 1er ORDEN + MODERACIÓN TOTAL por \"conciencia de la persuasión\"\n",
        "# + Bootstrap (CI + p empírico aproximado)\n",
        "# Copia y pega TODO este bloque en una sola celda.\n",
        "#\n",
        "# Requisitos:\n",
        "#   - df  (tu dataframe original)\n",
        "#   - constructos_1er_orden (tu diccionario de bloques/ítems)\n",
        "# ============================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# 0) CONFIGURACIÓN\n",
        "# ============================================================\n",
        "BOOTSTRAP = True\n",
        "N_BOOT = 5000          # <- solicitado: 5000\n",
        "SEED = 7\n",
        "\n",
        "MOD = \"conciencia_de_la_persuasion\"  # nombre del moderador (constructo latente)\n",
        "\n",
        "# ============================================================\n",
        "# 1) MODELO ESTRUCTURAL (tu hipótesis, todo 1er orden)\n",
        "#    - Exógenos 1er orden -> actitud/engagement\n",
        "#    - actitud/engagement -> intención\n",
        "#    - conciencia de la persuasión con:\n",
        "#         a) efecto directo sobre actitud, engagement e intención\n",
        "#         b) moderación TOTAL (interacciones) sobre TODAS las relaciones del modelo\n",
        "# ============================================================\n",
        "predictores_1er_orden = [\n",
        "    \"integridad\", \"expertis\", \"autenticidad\",\n",
        "    \"atractividad\", \"similitud\",\n",
        "    \"lider_de_opinion\", \"informatividad_del_contenido\",\n",
        "    \"congruencia_influencer_follower\", \"congruencia_influencer_producto\"\n",
        "]\n",
        "\n",
        "def inter_name(x, mod=MOD):\n",
        "    return f\"{x}_x_{mod}\"\n",
        "\n",
        "paths = {\n",
        "    \"actitud\": (\n",
        "        predictores_1er_orden\n",
        "        + [MOD]  # efecto directo del moderador sobre actitud (negativo esperado)\n",
        "        + [inter_name(p) for p in predictores_1er_orden]  # moderación de TODOS los predictores -> actitud\n",
        "    ),\n",
        "    \"engagement\": (\n",
        "        predictores_1er_orden\n",
        "        + [MOD]  # efecto directo del moderador sobre engagement (negativo esperado)\n",
        "        + [inter_name(p) for p in predictores_1er_orden]  # moderación de TODOS los predictores -> engagement\n",
        "    ),\n",
        "    \"predisposicion_a_comprar_un_producto\": [\n",
        "        \"actitud\", \"engagement\",\n",
        "        MOD,  # efecto directo del moderador sobre intención (negativo esperado)\n",
        "        inter_name(\"actitud\"),     # moderación actitud -> intención\n",
        "        inter_name(\"engagement\")   # moderación engagement -> intención\n",
        "    ]\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2) PREPARA df_analisis (solo columnas necesarias + limpieza robusta)\n",
        "# ============================================================\n",
        "def preparar_df_para_pls(df, constructos):\n",
        "    cols = [it for items in constructos.values() for it in items]\n",
        "    faltan = [c for c in cols if c not in df.columns]\n",
        "    if faltan:\n",
        "        raise ValueError(f\"Faltan columnas en tu df: {faltan}\")\n",
        "\n",
        "    df2 = df[cols].copy()\n",
        "    df2 = df2.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    df2 = df2.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # elimina columnas constantes\n",
        "    nun = df2.nunique(dropna=True)\n",
        "    const_cols = nun[nun <= 1].index.tolist()\n",
        "    if const_cols:\n",
        "        print(\"⚠️ Columnas constantes/sin variación (se eliminan):\", const_cols)\n",
        "        df2 = df2.drop(columns=const_cols)\n",
        "\n",
        "    # imputación simple por media\n",
        "    nan_before = int(df2.isna().sum().sum())\n",
        "    if nan_before > 0:\n",
        "        df2 = df2.apply(lambda s: s.fillna(s.mean()))\n",
        "        nan_after = int(df2.isna().sum().sum())\n",
        "        print(f\"✅ Imputación NaN: antes={nan_before}, después={nan_after}\")\n",
        "\n",
        "    # chequeo final\n",
        "    if not np.isfinite(df2.to_numpy()).all():\n",
        "        df2 = df2.replace([np.inf, -np.inf], np.nan).apply(lambda s: s.fillna(s.mean()))\n",
        "        if not np.isfinite(df2.to_numpy()).all():\n",
        "            raise ValueError(\"Aún hay valores no finitos (NaN/Inf) en df_analisis.\")\n",
        "\n",
        "    print(\"✅ df_analisis listo. Shape:\", df2.shape)\n",
        "    return df2\n",
        "\n",
        "df_analisis = preparar_df_para_pls(df, constructos_1er_orden)\n",
        "\n",
        "# ============================================================\n",
        "# 3) FUNCIONES PLS Mode A + Interacciones (robustas)\n",
        "# ============================================================\n",
        "def zscore_df(df):\n",
        "    mu = df.mean()\n",
        "    sd = df.std(ddof=0).replace(0, 1)\n",
        "    out = (df - mu) / sd\n",
        "    out = out.replace([np.inf, -np.inf], np.nan)\n",
        "    return out.fillna(0)\n",
        "\n",
        "def ols_beta(X, y):\n",
        "    \"\"\"\n",
        "    OLS con intercepto.\n",
        "    Si hay problema numérico (SVD), aplica ridge mínimo.\n",
        "    \"\"\"\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    y = np.asarray(y, dtype=float).reshape(-1, 1)\n",
        "\n",
        "    mask = np.isfinite(X).all(axis=1) & np.isfinite(y).ravel()\n",
        "    X = X[mask]; y = y[mask]\n",
        "\n",
        "    if X.shape[0] < X.shape[1] + 2:\n",
        "        return np.full(X.shape[1], np.nan), np.nan\n",
        "\n",
        "    X1 = np.column_stack([np.ones(len(X)), X])\n",
        "\n",
        "    try:\n",
        "        b = np.linalg.lstsq(X1, y, rcond=None)[0]\n",
        "    except np.linalg.LinAlgError:\n",
        "        lam = 1e-6\n",
        "        XtX = X1.T @ X1 + lam * np.eye(X1.shape[1])\n",
        "        b = np.linalg.solve(XtX, X1.T @ y)\n",
        "\n",
        "    yhat = X1 @ b\n",
        "    ssr = ((y - yhat) ** 2).sum()\n",
        "    sst = ((y - y.mean()) ** 2).sum()\n",
        "    r2 = 1 - (ssr / sst) if sst > 0 else np.nan\n",
        "\n",
        "    return b[1:].flatten(), float(r2)\n",
        "\n",
        "def init_outer_weights(cols):\n",
        "    return np.ones(len(cols)) / max(len(cols), 1)\n",
        "\n",
        "def latent_scores(dfZ, blocks, outer_w):\n",
        "    scores = {}\n",
        "    for c, cols in blocks.items():\n",
        "        cols_ok = [x for x in cols if x in dfZ.columns]\n",
        "        if len(cols_ok) == 0:\n",
        "            raise ValueError(f\"El constructo '{c}' se quedó sin ítems (revisa columnas eliminadas).\")\n",
        "        X = dfZ[cols_ok].to_numpy()\n",
        "\n",
        "        w = outer_w[c]\n",
        "        if len(w) != len(cols_ok):\n",
        "            w = np.ones(len(cols_ok)) / len(cols_ok)\n",
        "        w = w.reshape(-1, 1)\n",
        "\n",
        "        lv = (X @ w).flatten()\n",
        "        lv = (lv - lv.mean()) / (lv.std(ddof=0) + 1e-12)\n",
        "        scores[c] = lv\n",
        "\n",
        "        outer_w[c] = (w.flatten() / (np.linalg.norm(w) + 1e-12))\n",
        "    return pd.DataFrame(scores), outer_w\n",
        "\n",
        "def update_outer_weights_modeA(dfZ, blocks, LV_base, inner_pred):\n",
        "    new_w = {}\n",
        "    for c, cols in blocks.items():\n",
        "        cols_ok = [x for x in cols if x in dfZ.columns]\n",
        "        X = dfZ[cols_ok].to_numpy()\n",
        "\n",
        "        ref = inner_pred.get(c, LV_base[c].to_numpy()).reshape(-1, 1)\n",
        "\n",
        "        w = []\n",
        "        for j in range(X.shape[1]):\n",
        "            xj = X[:, [j]]\n",
        "            num = float((xj * ref).mean())\n",
        "            den = float(xj.std(ddof=0) * ref.std(ddof=0) + 1e-12)\n",
        "            w.append(num / den)\n",
        "\n",
        "        w = np.array(w, dtype=float)\n",
        "        w = w / (np.linalg.norm(w) + 1e-12)\n",
        "        new_w[c] = w\n",
        "    return new_w\n",
        "\n",
        "def add_interactions_from_paths(LV, paths, mod=MOD):\n",
        "    \"\"\"\n",
        "    Crea todas las variables de interacción que aparezcan en paths:\n",
        "      <X>_x_<mod> = zscore( LV[X] * LV[mod] )\n",
        "    \"\"\"\n",
        "    need = set()\n",
        "    suf = f\"_x_{mod}\"\n",
        "    for endog, exogs in paths.items():\n",
        "        for ex in exogs:\n",
        "            if isinstance(ex, str) and ex.endswith(suf):\n",
        "                need.add(ex)\n",
        "\n",
        "    for inter in need:\n",
        "        base = inter.replace(suf, \"\")\n",
        "        if base not in LV.columns:\n",
        "            raise ValueError(f\"No puedo crear interacción '{inter}': falta base '{base}' en LV.\")\n",
        "        if mod not in LV.columns:\n",
        "            raise ValueError(f\"No puedo crear interacción '{inter}': falta moderador '{mod}' en LV.\")\n",
        "\n",
        "        prod = LV[base].to_numpy() * LV[mod].to_numpy()\n",
        "        prod = (prod - prod.mean()) / (prod.std(ddof=0) + 1e-12)\n",
        "        LV[inter] = prod\n",
        "\n",
        "    return LV\n",
        "\n",
        "def inner_estimates(LV_base, paths, mod=MOD):\n",
        "    \"\"\"\n",
        "    Estima el inner model con interacciones (moderación total).\n",
        "    Devuelve:\n",
        "      - preds: predicciones estandarizadas por endógeno (para actualizar outer weights)\n",
        "      - betas: dict[endog][exog] = beta\n",
        "      - r2s:   dict[endog] = R²\n",
        "      - LV:    dataframe con interacciones ya creadas\n",
        "    \"\"\"\n",
        "    LV = LV_base.copy()\n",
        "    LV = add_interactions_from_paths(LV, paths, mod=mod)\n",
        "\n",
        "    preds, betas, r2s = {}, {}, {}\n",
        "    for endog, exogs in paths.items():\n",
        "        X = LV[exogs].to_numpy()\n",
        "        y = LV[endog].to_numpy()\n",
        "\n",
        "        b, r2 = ols_beta(X, y)\n",
        "        betas[endog] = dict(zip(exogs, b))\n",
        "        r2s[endog] = r2\n",
        "\n",
        "        yhat = X @ b\n",
        "        yhat = (yhat - yhat.mean()) / (yhat.std(ddof=0) + 1e-12)\n",
        "        preds[endog] = yhat\n",
        "\n",
        "    return preds, betas, r2s, LV\n",
        "\n",
        "def pls_scores_modeA(df, blocks, paths, max_iter=200, tol=1e-7, verbose=False):\n",
        "    dfZ = zscore_df(df)\n",
        "    outer_w = {c: init_outer_weights([x for x in cols if x in dfZ.columns]) for c, cols in blocks.items()}\n",
        "\n",
        "    for it in range(max_iter):\n",
        "        LV_base, outer_w = latent_scores(dfZ, blocks, outer_w)\n",
        "        inner_pred, _, _, _ = inner_estimates(LV_base, paths, mod=MOD)\n",
        "        new_w = update_outer_weights_modeA(dfZ, blocks, LV_base, inner_pred)\n",
        "\n",
        "        deltas = []\n",
        "        for c in blocks.keys():\n",
        "            w_old = outer_w[c]; w_new = new_w[c]\n",
        "            m = min(len(w_old), len(w_new))\n",
        "            deltas.append(np.max(np.abs(w_new[:m] - w_old[:m])))\n",
        "        change = float(np.max(deltas)) if deltas else np.nan\n",
        "\n",
        "        outer_w = new_w\n",
        "        if verbose and (it % 20 == 0 or change < tol):\n",
        "            print(f\"Iter {it:03d} | max Δw = {change:.2e}\")\n",
        "        if change < tol:\n",
        "            break\n",
        "\n",
        "    LV_base, _ = latent_scores(zscore_df(df), blocks, outer_w)\n",
        "    _, betas, r2s, LV_full = inner_estimates(LV_base, paths, mod=MOD)\n",
        "    return LV_full, outer_w, betas, r2s\n",
        "\n",
        "# ============================================================\n",
        "# 4) EJECUTA MODELO ORIGINAL\n",
        "# ============================================================\n",
        "LV, outer_w, betas, r2s = pls_scores_modeA(df_analisis, constructos_1er_orden, paths, verbose=False)\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"R² (endógenas)\")\n",
        "print(\"====================\")\n",
        "for k, v in r2s.items():\n",
        "    print(f\"{k}: {v:.3f}\")\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"PATH COEFFICIENTS β (modelo con moderación total)\")\n",
        "print(\"====================\")\n",
        "for endog, exogs in paths.items():\n",
        "    print(f\"\\n{endog} (R²={r2s[endog]:.3f})\")\n",
        "    for ex in exogs:\n",
        "        print(f\"  {ex:50s} -> {endog:35s}  β={betas[endog][ex]:+.3f}\")\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"FOCO: conciencia de la persuasión (efectos directos y moderación)\")\n",
        "print(\"====================\")\n",
        "for target in [\"actitud\", \"engagement\", \"predisposicion_a_comprar_un_producto\"]:\n",
        "    b_dir = betas[target].get(MOD, np.nan)\n",
        "    print(f\"Directo: {MOD:28s} -> {target:35s}  β={b_dir:+.3f}  (esperas NEGATIVO)\")\n",
        "\n",
        "print(\"\\nInteracciones (moderación) sobre Actitud/Engagement:\")\n",
        "for p in predictores_1er_orden:\n",
        "    bA = betas[\"actitud\"].get(inter_name(p), np.nan)\n",
        "    bE = betas[\"engagement\"].get(inter_name(p), np.nan)\n",
        "    print(f\"  {p:35s}×conciencia -> actitud    β={bA:+.3f} (esperas NEGATIVO)\")\n",
        "    print(f\"  {p:35s}×conciencia -> engagement β={bE:+.3f} (esperas NEGATIVO)\")\n",
        "\n",
        "print(\"\\nInteracciones (moderación) sobre Intención de compra:\")\n",
        "b4 = betas[\"predisposicion_a_comprar_un_producto\"].get(inter_name(\"actitud\"), np.nan)\n",
        "b5 = betas[\"predisposicion_a_comprar_un_producto\"].get(inter_name(\"engagement\"), np.nan)\n",
        "print(f\"  Actitud×conciencia -> intención   β={b4:+.3f}  (esperas NEGATIVO)\")\n",
        "print(f\"  Engagement×conciencia -> intención β={b5:+.3f}  (esperas NEGATIVO)\")\n",
        "\n",
        "# ============================================================\n",
        "# 5) BOOTSTRAP (CI + p empírico aprox)\n",
        "# ============================================================\n",
        "def bootstrap_paths(df_analisis, blocks, paths, B=5000, seed=7):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # original\n",
        "    LV0, _, betas0, r2_0 = pls_scores_modeA(df_analisis, blocks, paths, verbose=False)\n",
        "\n",
        "    edges = [(endog, exog) for endog, exogs in paths.items() for exog in exogs]\n",
        "    boot = {e: [] for e in edges}\n",
        "\n",
        "    n = len(df_analisis)\n",
        "\n",
        "    # barra de progreso opcional\n",
        "    try:\n",
        "        from tqdm import tqdm\n",
        "        iterator = tqdm(range(B), desc=f\"Bootstrap (B={B})\")\n",
        "    except Exception:\n",
        "        iterator = range(B)\n",
        "\n",
        "    for _ in iterator:\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        sample = df_analisis.iloc[idx].reset_index(drop=True)\n",
        "\n",
        "        LVb, _, betas_b, _ = pls_scores_modeA(sample, blocks, paths, verbose=False)\n",
        "\n",
        "        for (endog, exog) in edges:\n",
        "            boot[(endog, exog)].append(float(betas_b[endog][exog]))\n",
        "\n",
        "    rows = []\n",
        "    for (endog, exog) in edges:\n",
        "        dist = np.array(boot[(endog, exog)], dtype=float)\n",
        "\n",
        "        b0 = float(betas0[endog][exog])\n",
        "        se = float(np.nanstd(dist, ddof=1))\n",
        "        t = (b0 / se) if se > 0 else np.nan\n",
        "\n",
        "        # p empírico 2-colas: proporción de signos respecto a 0\n",
        "        p_emp = 2 * min(np.mean(dist <= 0), np.mean(dist >= 0))\n",
        "\n",
        "        ci_low = float(np.nanpercentile(dist, 2.5))\n",
        "        ci_high = float(np.nanpercentile(dist, 97.5))\n",
        "\n",
        "        rows.append({\n",
        "            \"Endog\": endog,\n",
        "            \"Exog\": exog,\n",
        "            \"Beta_orig\": b0,\n",
        "            \"CI_2.5%\": ci_low,\n",
        "            \"CI_97.5%\": ci_high,\n",
        "            \"SE_boot\": se,\n",
        "            \"t_boot\": float(t),\n",
        "            \"p_emp(2-colas)\": float(p_emp),\n",
        "            \"Significativo_0.05\": (p_emp < 0.05)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows).sort_values(by=\"p_emp(2-colas)\")\n",
        "\n",
        "if BOOTSTRAP:\n",
        "    print(\"\\n====================\")\n",
        "    print(f\"BOOTSTRAP (B={N_BOOT}) - CI y p empírico\")\n",
        "    print(\"====================\")\n",
        "    tabla_boot = bootstrap_paths(\n",
        "        df_analisis, constructos_1er_orden,\n",
        "        paths,\n",
        "        B=N_BOOT, seed=SEED\n",
        "    )\n",
        "    pd.options.display.float_format = \"{:.4f}\".format\n",
        "    print(tabla_boot)\n",
        "\n",
        "print(\"\\n✅ Listo: Modelo 1er orden + conciencia de la persuasión (directo + moderación total) + bootstrap.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzuIOAjVLjLX",
        "outputId": "ac1706d2-31ea-42f1-a106-47051fc6eb5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Imputación NaN: antes=8, después=0\n",
            "✅ df_analisis listo. Shape: (240, 47)\n",
            "\n",
            "====================\n",
            "R² (endógenas)\n",
            "====================\n",
            "actitud: 0.131\n",
            "engagement: 0.174\n",
            "predisposicion_a_comprar_un_producto: 0.051\n",
            "\n",
            "====================\n",
            "PATH COEFFICIENTS β (modelo con moderación total)\n",
            "====================\n",
            "\n",
            "actitud (R²=0.131)\n",
            "  integridad                                         -> actitud                              β=-0.005\n",
            "  expertis                                           -> actitud                              β=+0.096\n",
            "  autenticidad                                       -> actitud                              β=+0.082\n",
            "  atractividad                                       -> actitud                              β=-0.003\n",
            "  similitud                                          -> actitud                              β=+0.125\n",
            "  lider_de_opinion                                   -> actitud                              β=+0.021\n",
            "  informatividad_del_contenido                       -> actitud                              β=+0.061\n",
            "  congruencia_influencer_follower                    -> actitud                              β=-0.037\n",
            "  congruencia_influencer_producto                    -> actitud                              β=+0.079\n",
            "  conciencia_de_la_persuasion                        -> actitud                              β=+0.101\n",
            "  integridad_x_conciencia_de_la_persuasion           -> actitud                              β=+0.083\n",
            "  expertis_x_conciencia_de_la_persuasion             -> actitud                              β=-0.103\n",
            "  autenticidad_x_conciencia_de_la_persuasion         -> actitud                              β=-0.147\n",
            "  atractividad_x_conciencia_de_la_persuasion         -> actitud                              β=+0.197\n",
            "  similitud_x_conciencia_de_la_persuasion            -> actitud                              β=-0.205\n",
            "  lider_de_opinion_x_conciencia_de_la_persuasion     -> actitud                              β=+0.016\n",
            "  informatividad_del_contenido_x_conciencia_de_la_persuasion -> actitud                              β=+0.053\n",
            "  congruencia_influencer_follower_x_conciencia_de_la_persuasion -> actitud                              β=+0.113\n",
            "  congruencia_influencer_producto_x_conciencia_de_la_persuasion -> actitud                              β=+0.060\n",
            "\n",
            "engagement (R²=0.174)\n",
            "  integridad                                         -> engagement                           β=+0.056\n",
            "  expertis                                           -> engagement                           β=+0.003\n",
            "  autenticidad                                       -> engagement                           β=-0.098\n",
            "  atractividad                                       -> engagement                           β=-0.020\n",
            "  similitud                                          -> engagement                           β=-0.030\n",
            "  lider_de_opinion                                   -> engagement                           β=+0.256\n",
            "  informatividad_del_contenido                       -> engagement                           β=+0.092\n",
            "  congruencia_influencer_follower                    -> engagement                           β=-0.076\n",
            "  congruencia_influencer_producto                    -> engagement                           β=+0.180\n",
            "  conciencia_de_la_persuasion                        -> engagement                           β=+0.141\n",
            "  integridad_x_conciencia_de_la_persuasion           -> engagement                           β=+0.161\n",
            "  expertis_x_conciencia_de_la_persuasion             -> engagement                           β=-0.053\n",
            "  autenticidad_x_conciencia_de_la_persuasion         -> engagement                           β=+0.050\n",
            "  atractividad_x_conciencia_de_la_persuasion         -> engagement                           β=-0.023\n",
            "  similitud_x_conciencia_de_la_persuasion            -> engagement                           β=+0.121\n",
            "  lider_de_opinion_x_conciencia_de_la_persuasion     -> engagement                           β=+0.053\n",
            "  informatividad_del_contenido_x_conciencia_de_la_persuasion -> engagement                           β=-0.038\n",
            "  congruencia_influencer_follower_x_conciencia_de_la_persuasion -> engagement                           β=+0.008\n",
            "  congruencia_influencer_producto_x_conciencia_de_la_persuasion -> engagement                           β=-0.075\n",
            "\n",
            "predisposicion_a_comprar_un_producto (R²=0.051)\n",
            "  actitud                                            -> predisposicion_a_comprar_un_producto  β=+0.032\n",
            "  engagement                                         -> predisposicion_a_comprar_un_producto  β=-0.011\n",
            "  conciencia_de_la_persuasion                        -> predisposicion_a_comprar_un_producto  β=+0.217\n",
            "  actitud_x_conciencia_de_la_persuasion              -> predisposicion_a_comprar_un_producto  β=-0.027\n",
            "  engagement_x_conciencia_de_la_persuasion           -> predisposicion_a_comprar_un_producto  β=-0.011\n",
            "\n",
            "====================\n",
            "FOCO: conciencia de la persuasión (efectos directos y moderación)\n",
            "====================\n",
            "Directo: conciencia_de_la_persuasion  -> actitud                              β=+0.101  (esperas NEGATIVO)\n",
            "Directo: conciencia_de_la_persuasion  -> engagement                           β=+0.141  (esperas NEGATIVO)\n",
            "Directo: conciencia_de_la_persuasion  -> predisposicion_a_comprar_un_producto  β=+0.217  (esperas NEGATIVO)\n",
            "\n",
            "Interacciones (moderación) sobre Actitud/Engagement:\n",
            "  integridad                         ×conciencia -> actitud    β=+0.083 (esperas NEGATIVO)\n",
            "  integridad                         ×conciencia -> engagement β=+0.161 (esperas NEGATIVO)\n",
            "  expertis                           ×conciencia -> actitud    β=-0.103 (esperas NEGATIVO)\n",
            "  expertis                           ×conciencia -> engagement β=-0.053 (esperas NEGATIVO)\n",
            "  autenticidad                       ×conciencia -> actitud    β=-0.147 (esperas NEGATIVO)\n",
            "  autenticidad                       ×conciencia -> engagement β=+0.050 (esperas NEGATIVO)\n",
            "  atractividad                       ×conciencia -> actitud    β=+0.197 (esperas NEGATIVO)\n",
            "  atractividad                       ×conciencia -> engagement β=-0.023 (esperas NEGATIVO)\n",
            "  similitud                          ×conciencia -> actitud    β=-0.205 (esperas NEGATIVO)\n",
            "  similitud                          ×conciencia -> engagement β=+0.121 (esperas NEGATIVO)\n",
            "  lider_de_opinion                   ×conciencia -> actitud    β=+0.016 (esperas NEGATIVO)\n",
            "  lider_de_opinion                   ×conciencia -> engagement β=+0.053 (esperas NEGATIVO)\n",
            "  informatividad_del_contenido       ×conciencia -> actitud    β=+0.053 (esperas NEGATIVO)\n",
            "  informatividad_del_contenido       ×conciencia -> engagement β=-0.038 (esperas NEGATIVO)\n",
            "  congruencia_influencer_follower    ×conciencia -> actitud    β=+0.113 (esperas NEGATIVO)\n",
            "  congruencia_influencer_follower    ×conciencia -> engagement β=+0.008 (esperas NEGATIVO)\n",
            "  congruencia_influencer_producto    ×conciencia -> actitud    β=+0.060 (esperas NEGATIVO)\n",
            "  congruencia_influencer_producto    ×conciencia -> engagement β=-0.075 (esperas NEGATIVO)\n",
            "\n",
            "Interacciones (moderación) sobre Intención de compra:\n",
            "  Actitud×conciencia -> intención   β=-0.027  (esperas NEGATIVO)\n",
            "  Engagement×conciencia -> intención β=-0.011  (esperas NEGATIVO)\n",
            "\n",
            "====================\n",
            "BOOTSTRAP (B=5000) - CI y p empírico\n",
            "====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bootstrap (B=5000): 100%|██████████| 5000/5000 [25:34<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Endog                                               Exog  Beta_orig  CI_2.5%  CI_97.5%  SE_boot  t_boot  p_emp(2-colas)  Significativo_0.05\n",
            "40  predisposicion_a_comprar_un_producto                        conciencia_de_la_persuasion     0.2172   0.1014    0.3339   0.0604  3.5955          0.0008                True\n",
            "24                            engagement                                   lider_de_opinion     0.2556   0.1087    0.3857   0.0710  3.6018          0.0012                True\n",
            "27                            engagement                    congruencia_influencer_producto     0.1802   0.0350    0.2900   0.0653  2.7594          0.0100                True\n",
            "29                            engagement           integridad_x_conciencia_de_la_persuasion     0.1612   0.0335    0.2894   0.0635  2.5386          0.0116                True\n",
            "13                               actitud         atractividad_x_conciencia_de_la_persuasion     0.1975   0.0476    0.3394   0.0752  2.6243          0.0152                True\n",
            "14                               actitud            similitud_x_conciencia_de_la_persuasion    -0.2049  -0.3675   -0.0317   0.0848 -2.4151          0.0212                True\n",
            "33                            engagement            similitud_x_conciencia_de_la_persuasion     0.1207   0.0105    0.2332   0.0571  2.1131          0.0332                True\n",
            "28                            engagement                        conciencia_de_la_persuasion     0.1414  -0.0170    0.2715   0.0742  1.9062          0.0792               False\n",
            "12                               actitud         autenticidad_x_conciencia_de_la_persuasion    -0.1473  -0.2934    0.0171   0.0785 -1.8750          0.0800               False\n",
            "25                            engagement                       informatividad_del_contenido     0.0918  -0.0227    0.2151   0.0606  1.5163          0.1112               False\n",
            "21                            engagement                                       autenticidad    -0.0983  -0.2147    0.0289   0.0621 -1.5843          0.1304               False\n",
            "17                               actitud  congruencia_influencer_follower_x_conciencia_d...     0.1133  -0.0346    0.2511   0.0728  1.5559          0.1320               False\n",
            "4                                actitud                                          similitud     0.1247  -0.0338    0.2807   0.0815  1.5292          0.1388               False\n",
            "1                                actitud                                           expertis     0.0962  -0.0439    0.2305   0.0690  1.3952          0.1688               False\n",
            "9                                actitud                        conciencia_de_la_persuasion     0.1007  -0.0445    0.2570   0.0765  1.3159          0.1732               False\n",
            "8                                actitud                    congruencia_influencer_producto     0.0790  -0.0366    0.2028   0.0614  1.2879          0.1764               False\n",
            "2                                actitud                                       autenticidad     0.0816  -0.0425    0.1963   0.0607  1.3433          0.2004               False\n",
            "10                               actitud           integridad_x_conciencia_de_la_persuasion     0.0835  -0.0498    0.2285   0.0723  1.1542          0.2212               False\n",
            "11                               actitud             expertis_x_conciencia_de_la_persuasion    -0.1031  -0.2707    0.0536   0.0827 -1.2459          0.2244               False\n",
            "26                            engagement                    congruencia_influencer_follower    -0.0763  -0.1895    0.0514   0.0612 -1.2466          0.2300               False\n",
            "6                                actitud                       informatividad_del_contenido     0.0613  -0.0561    0.1860   0.0606  1.0116          0.2816               False\n",
            "18                               actitud  congruencia_influencer_producto_x_conciencia_d...     0.0596  -0.0797    0.1963   0.0699  0.8535          0.4200               False\n",
            "31                            engagement         autenticidad_x_conciencia_de_la_persuasion     0.0502  -0.0870    0.1796   0.0676  0.7428          0.4364               False\n",
            "19                            engagement                                         integridad     0.0563  -0.0748    0.1769   0.0641  0.8778          0.4432               False\n",
            "16                               actitud  informatividad_del_contenido_x_conciencia_de_l...     0.0529  -0.0846    0.1786   0.0668  0.7918          0.4820               False\n",
            "37                            engagement  congruencia_influencer_producto_x_conciencia_d...    -0.0747  -0.2245    0.1230   0.0895 -0.8353          0.4924               False\n",
            "35                            engagement  informatividad_del_contenido_x_conciencia_de_l...    -0.0382  -0.1819    0.0928   0.0706 -0.5407          0.5016               False\n",
            "34                            engagement     lider_de_opinion_x_conciencia_de_la_persuasion     0.0530  -0.1006    0.2264   0.0833  0.6359          0.5276               False\n",
            "7                                actitud                    congruencia_influencer_follower    -0.0365  -0.1596    0.0938   0.0652 -0.5603          0.5780               False\n",
            "38  predisposicion_a_comprar_un_producto                                            actitud     0.0319  -0.0926    0.1699   0.0662  0.4816          0.5944               False\n",
            "23                            engagement                                          similitud    -0.0295  -0.1425    0.0884   0.0590 -0.5003          0.6160               False\n",
            "30                            engagement             expertis_x_conciencia_de_la_persuasion    -0.0526  -0.1949    0.1280   0.0819 -0.6423          0.6488               False\n",
            "32                            engagement         atractividad_x_conciencia_de_la_persuasion    -0.0225  -0.1693    0.1064   0.0690 -0.3269          0.6692               False\n",
            "41  predisposicion_a_comprar_un_producto              actitud_x_conciencia_de_la_persuasion    -0.0269  -0.1556    0.0927   0.0633 -0.4252          0.6740               False\n",
            "42  predisposicion_a_comprar_un_producto           engagement_x_conciencia_de_la_persuasion    -0.0107  -0.1477    0.1200   0.0686 -0.1563          0.8404               False\n",
            "22                            engagement                                       atractividad    -0.0195  -0.1322    0.1083   0.0607 -0.3211          0.8412               False\n",
            "39  predisposicion_a_comprar_un_producto                                         engagement    -0.0105  -0.1275    0.1078   0.0610 -0.1727          0.8420               False\n",
            "5                                actitud                                   lider_de_opinion     0.0212  -0.1359    0.1630   0.0760  0.2785          0.8644               False\n",
            "15                               actitud     lider_de_opinion_x_conciencia_de_la_persuasion     0.0162  -0.1509    0.1606   0.0804  0.2017          0.8972               False\n",
            "36                            engagement  congruencia_influencer_follower_x_conciencia_d...     0.0079  -0.1158    0.1259   0.0606  0.1310          0.8980               False\n",
            "20                            engagement                                           expertis     0.0034  -0.1328    0.1340   0.0676  0.0507          0.9660               False\n",
            "0                                actitud                                         integridad    -0.0055  -0.1425    0.1408   0.0724 -0.0754          0.9836               False\n",
            "3                                actitud                                       atractividad    -0.0028  -0.1257    0.1220   0.0640 -0.0435          1.0000               False\n",
            "\n",
            "✅ Listo: Modelo 1er orden + conciencia de la persuasión (directo + moderación total) + bootstrap.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# PLS-SEM (Mode A) 1er ORDEN + MODERACIÓN TOTAL por \"conciencia de la persuasión\"\n",
        "# + Bootstrap (CI + p empírico aproximado)\n",
        "# TODO EN UNA SOLA CELDA (Google Colab)\n",
        "#\n",
        "# Requisitos:\n",
        "#   - df  (tu dataframe original)\n",
        "#   - constructos_1er_orden (dict: {constructo:[items...]})\n",
        "# ============================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ============================================================\n",
        "# 0) CONFIGURACIÓN\n",
        "# ============================================================\n",
        "BOOTSTRAP = True\n",
        "N_BOOT = 5000\n",
        "SEED = 7\n",
        "MOD = \"conciencia_de_la_persuasion\"  # moderador (latente)\n",
        "\n",
        "# ============================================================\n",
        "# 1) MODELO ESTRUCTURAL (tu hipótesis, todo 1er orden)\n",
        "#    - Exógenos 1er orden -> actitud/engagement\n",
        "#    - actitud/engagement -> intención\n",
        "#    - conciencia de la persuasión:\n",
        "#         a) efectos directos sobre actitud, engagement e intención\n",
        "#         b) moderación TOTAL (interacciones) sobre TODAS las relaciones exógenas -> actitud/engagement\n",
        "#            + moderación de actitud/engagement -> intención\n",
        "# ============================================================\n",
        "predictores_1er_orden = [\n",
        "    \"integridad\", \"expertis\", \"autenticidad\",\n",
        "    \"atractividad\", \"similitud\",\n",
        "    \"lider_de_opinion\", \"informatividad_del_contenido\",\n",
        "    \"congruencia_influencer_follower\", \"congruencia_influencer_producto\"\n",
        "]\n",
        "\n",
        "def inter_name(x, mod=MOD):\n",
        "    return f\"{x}_x_{mod}\"\n",
        "\n",
        "paths = {\n",
        "    \"actitud\": (\n",
        "        predictores_1er_orden\n",
        "        + [MOD]\n",
        "        + [inter_name(p) for p in predictores_1er_orden]\n",
        "    ),\n",
        "    \"engagement\": (\n",
        "        predictores_1er_orden\n",
        "        + [MOD]\n",
        "        + [inter_name(p) for p in predictores_1er_orden]\n",
        "    ),\n",
        "    \"predisposicion_a_comprar_un_producto\": [\n",
        "        \"actitud\", \"engagement\",\n",
        "        MOD,\n",
        "        inter_name(\"actitud\"),\n",
        "        inter_name(\"engagement\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2) PREPARA df_analisis (solo columnas necesarias + limpieza robusta)\n",
        "# ============================================================\n",
        "def preparar_df_para_pls(df, constructos):\n",
        "    cols = [it for items in constructos.values() for it in items]\n",
        "    faltan = [c for c in cols if c not in df.columns]\n",
        "    if faltan:\n",
        "        raise ValueError(f\"Faltan columnas en tu df: {faltan}\")\n",
        "\n",
        "    df2 = df[cols].copy()\n",
        "    df2 = df2.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    df2 = df2.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    nun = df2.nunique(dropna=True)\n",
        "    const_cols = nun[nun <= 1].index.tolist()\n",
        "    if const_cols:\n",
        "        print(\"⚠️ Columnas constantes/sin variación (se eliminan):\", const_cols)\n",
        "        df2 = df2.drop(columns=const_cols)\n",
        "\n",
        "    nan_before = int(df2.isna().sum().sum())\n",
        "    if nan_before > 0:\n",
        "        df2 = df2.apply(lambda s: s.fillna(s.mean()))\n",
        "        nan_after = int(df2.isna().sum().sum())\n",
        "        print(f\"✅ Imputación NaN: antes={nan_before}, después={nan_after}\")\n",
        "\n",
        "    if not np.isfinite(df2.to_numpy()).all():\n",
        "        df2 = df2.replace([np.inf, -np.inf], np.nan).apply(lambda s: s.fillna(s.mean()))\n",
        "        if not np.isfinite(df2.to_numpy()).all():\n",
        "            raise ValueError(\"Aún hay valores no finitos (NaN/Inf) en df_analisis.\")\n",
        "\n",
        "    print(\"✅ df_analisis listo. Shape:\", df2.shape)\n",
        "    return df2\n",
        "\n",
        "df_analisis = preparar_df_para_pls(df, constructos_1er_orden)\n",
        "\n",
        "# ============================================================\n",
        "# 3) FUNCIONES PLS Mode A + Interacciones (robustas)\n",
        "# ============================================================\n",
        "def zscore_df(df):\n",
        "    mu = df.mean()\n",
        "    sd = df.std(ddof=0).replace(0, 1)\n",
        "    out = (df - mu) / sd\n",
        "    out = out.replace([np.inf, -np.inf], np.nan)\n",
        "    return out.fillna(0)\n",
        "\n",
        "def ols_beta(X, y):\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    y = np.asarray(y, dtype=float).reshape(-1, 1)\n",
        "\n",
        "    mask = np.isfinite(X).all(axis=1) & np.isfinite(y).ravel()\n",
        "    X = X[mask]; y = y[mask]\n",
        "\n",
        "    if X.shape[0] < X.shape[1] + 2:\n",
        "        return np.full(X.shape[1], np.nan), np.nan\n",
        "\n",
        "    X1 = np.column_stack([np.ones(len(X)), X])\n",
        "\n",
        "    try:\n",
        "        b = np.linalg.lstsq(X1, y, rcond=None)[0]\n",
        "    except np.linalg.LinAlgError:\n",
        "        lam = 1e-6\n",
        "        XtX = X1.T @ X1 + lam * np.eye(X1.shape[1])\n",
        "        b = np.linalg.solve(XtX, X1.T @ y)\n",
        "\n",
        "    yhat = X1 @ b\n",
        "    ssr = ((y - yhat) ** 2).sum()\n",
        "    sst = ((y - y.mean()) ** 2).sum()\n",
        "    r2 = 1 - (ssr / sst) if sst > 0 else np.nan\n",
        "\n",
        "    return b[1:].flatten(), float(r2)\n",
        "\n",
        "def init_outer_weights(cols):\n",
        "    return np.ones(len(cols)) / max(len(cols), 1)\n",
        "\n",
        "def latent_scores(dfZ, blocks, outer_w):\n",
        "    scores = {}\n",
        "    for c, cols in blocks.items():\n",
        "        cols_ok = [x for x in cols if x in dfZ.columns]\n",
        "        if len(cols_ok) == 0:\n",
        "            raise ValueError(f\"El constructo '{c}' se quedó sin ítems (revisa columnas eliminadas).\")\n",
        "        X = dfZ[cols_ok].to_numpy()\n",
        "\n",
        "        w = outer_w[c]\n",
        "        if len(w) != len(cols_ok):\n",
        "            w = np.ones(len(cols_ok)) / len(cols_ok)\n",
        "        w = w.reshape(-1, 1)\n",
        "\n",
        "        lv = (X @ w).flatten()\n",
        "        lv = (lv - lv.mean()) / (lv.std(ddof=0) + 1e-12)\n",
        "        scores[c] = lv\n",
        "\n",
        "        outer_w[c] = (w.flatten() / (np.linalg.norm(w) + 1e-12))\n",
        "    return pd.DataFrame(scores), outer_w\n",
        "\n",
        "def update_outer_weights_modeA(dfZ, blocks, LV_base, inner_pred):\n",
        "    new_w = {}\n",
        "    for c, cols in blocks.items():\n",
        "        cols_ok = [x for x in cols if x in dfZ.columns]\n",
        "        X = dfZ[cols_ok].to_numpy()\n",
        "\n",
        "        ref = inner_pred.get(c, LV_base[c].to_numpy()).reshape(-1, 1)\n",
        "\n",
        "        w = []\n",
        "        for j in range(X.shape[1]):\n",
        "            xj = X[:, [j]]\n",
        "            num = float((xj * ref).mean())\n",
        "            den = float(xj.std(ddof=0) * ref.std(ddof=0) + 1e-12)\n",
        "            w.append(num / den)\n",
        "\n",
        "        w = np.array(w, dtype=float)\n",
        "        w = w / (np.linalg.norm(w) + 1e-12)\n",
        "        new_w[c] = w\n",
        "    return new_w\n",
        "\n",
        "def add_interactions_from_paths(LV, paths, mod=MOD):\n",
        "    need = set()\n",
        "    suf = f\"_x_{mod}\"\n",
        "    for endog, exogs in paths.items():\n",
        "        for ex in exogs:\n",
        "            if isinstance(ex, str) and ex.endswith(suf):\n",
        "                need.add(ex)\n",
        "\n",
        "    for inter in need:\n",
        "        base = inter.replace(suf, \"\")\n",
        "        if base not in LV.columns:\n",
        "            raise ValueError(f\"No puedo crear interacción '{inter}': falta base '{base}' en LV.\")\n",
        "        if mod not in LV.columns:\n",
        "            raise ValueError(f\"No puedo crear interacción '{inter}': falta moderador '{mod}' en LV.\")\n",
        "\n",
        "        prod = LV[base].to_numpy() * LV[mod].to_numpy()\n",
        "        prod = (prod - prod.mean()) / (prod.std(ddof=0) + 1e-12)\n",
        "        LV[inter] = prod\n",
        "\n",
        "    return LV\n",
        "\n",
        "def inner_estimates(LV_base, paths, mod=MOD):\n",
        "    LV = LV_base.copy()\n",
        "    LV = add_interactions_from_paths(LV, paths, mod=mod)\n",
        "\n",
        "    preds, betas, r2s = {}, {}, {}\n",
        "    for endog, exogs in paths.items():\n",
        "        X = LV[exogs].to_numpy()\n",
        "        y = LV[endog].to_numpy()\n",
        "\n",
        "        b, r2 = ols_beta(X, y)\n",
        "        betas[endog] = dict(zip(exogs, b))\n",
        "        r2s[endog] = r2\n",
        "\n",
        "        yhat = X @ b\n",
        "        yhat = (yhat - yhat.mean()) / (yhat.std(ddof=0) + 1e-12)\n",
        "        preds[endog] = yhat\n",
        "\n",
        "    return preds, betas, r2s, LV\n",
        "\n",
        "def pls_scores_modeA(df, blocks, paths, max_iter=200, tol=1e-7, verbose=False):\n",
        "    dfZ = zscore_df(df)\n",
        "    outer_w = {c: init_outer_weights([x for x in cols if x in dfZ.columns]) for c, cols in blocks.items()}\n",
        "\n",
        "    for it in range(max_iter):\n",
        "        LV_base, outer_w = latent_scores(dfZ, blocks, outer_w)\n",
        "        inner_pred, _, _, _ = inner_estimates(LV_base, paths, mod=MOD)\n",
        "        new_w = update_outer_weights_modeA(dfZ, blocks, LV_base, inner_pred)\n",
        "\n",
        "        deltas = []\n",
        "        for c in blocks.keys():\n",
        "            w_old = outer_w[c]; w_new = new_w[c]\n",
        "            m = min(len(w_old), len(w_new))\n",
        "            deltas.append(np.max(np.abs(w_new[:m] - w_old[:m])))\n",
        "        change = float(np.max(deltas)) if deltas else np.nan\n",
        "\n",
        "        outer_w = new_w\n",
        "        if verbose and (it % 20 == 0 or change < tol):\n",
        "            print(f\"Iter {it:03d} | max Δw = {change:.2e}\")\n",
        "        if change < tol:\n",
        "            break\n",
        "\n",
        "    LV_base, _ = latent_scores(zscore_df(df), blocks, outer_w)\n",
        "    _, betas, r2s, LV_full = inner_estimates(LV_base, paths, mod=MOD)\n",
        "    return LV_full, outer_w, betas, r2s\n",
        "\n",
        "# ============================================================\n",
        "# 4) EJECUTA MODELO\n",
        "# ============================================================\n",
        "LV, outer_w, betas, r2s = pls_scores_modeA(df_analisis, constructos_1er_orden, paths, verbose=False)\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"R² (endógenas)\")\n",
        "print(\"====================\")\n",
        "for k, v in r2s.items():\n",
        "    print(f\"{k}: {v:.3f}\")\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"FOCO: conciencia de la persuasión (directos)\")\n",
        "print(\"====================\")\n",
        "for target in [\"actitud\", \"engagement\", \"predisposicion_a_comprar_un_producto\"]:\n",
        "    b_dir = betas[target].get(MOD, np.nan)\n",
        "    print(f\"{MOD} -> {target:35s}  β={b_dir:+.3f}  (esperas NEGATIVO)\")\n",
        "\n",
        "# ============================================================\n",
        "# 5) BOOTSTRAP (CI + p empírico aprox)\n",
        "# ============================================================\n",
        "def bootstrap_paths(df_analisis, blocks, paths, B=5000, seed=7):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    LV0, _, betas0, r2_0 = pls_scores_modeA(df_analisis, blocks, paths, verbose=False)\n",
        "\n",
        "    edges = [(endog, exog) for endog, exogs in paths.items() for exog in exogs]\n",
        "    boot = {e: [] for e in edges}\n",
        "\n",
        "    n = len(df_analisis)\n",
        "\n",
        "    try:\n",
        "        from tqdm import tqdm\n",
        "        iterator = tqdm(range(B), desc=f\"Bootstrap (B={B})\")\n",
        "    except Exception:\n",
        "        iterator = range(B)\n",
        "\n",
        "    for _ in iterator:\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        sample = df_analisis.iloc[idx].reset_index(drop=True)\n",
        "\n",
        "        LVb, _, betas_b, _ = pls_scores_modeA(sample, blocks, paths, verbose=False)\n",
        "\n",
        "        for (endog, exog) in edges:\n",
        "            boot[(endog, exog)].append(float(betas_b[endog][exog]))\n",
        "\n",
        "    rows = []\n",
        "    for (endog, exog) in edges:\n",
        "        dist = np.array(boot[(endog, exog)], dtype=float)\n",
        "        b0 = float(betas0[endog][exog])\n",
        "        se = float(np.nanstd(dist, ddof=1))\n",
        "        t = (b0 / se) if se > 0 else np.nan\n",
        "        p_emp = 2 * min(np.mean(dist <= 0), np.mean(dist >= 0))\n",
        "        ci_low = float(np.nanpercentile(dist, 2.5))\n",
        "        ci_high = float(np.nanpercentile(dist, 97.5))\n",
        "\n",
        "        rows.append({\n",
        "            \"Endog\": endog,\n",
        "            \"Exog\": exog,\n",
        "            \"Beta\": b0,\n",
        "            \"CI_2.5%\": ci_low,\n",
        "            \"CI_97.5%\": ci_high,\n",
        "            \"SE\": se,\n",
        "            \"t\": float(t),\n",
        "            \"p\": float(p_emp),\n",
        "            \"Sig_0.05\": (p_emp < 0.05)\n",
        "        })\n",
        "\n",
        "    out = pd.DataFrame(rows).sort_values(by=\"p\")\n",
        "    return out\n",
        "\n",
        "tabla_boot = None\n",
        "if BOOTSTRAP:\n",
        "    print(\"\\n====================\")\n",
        "    print(f\"BOOTSTRAP (B={N_BOOT}) - CI y p empírico\")\n",
        "    print(\"====================\")\n",
        "    tabla_boot = bootstrap_paths(\n",
        "        df_analisis, constructos_1er_orden, paths,\n",
        "        B=N_BOOT, seed=SEED\n",
        "    )\n",
        "\n",
        "# ============================================================\n",
        "# 6) MOSTRAR TABLA (SIN “DESFASE”): centrada + scroll horizontal\n",
        "# ============================================================\n",
        "def mostrar_tabla_bootstrap(tabla, max_rows=200):\n",
        "    if tabla is None or len(tabla) == 0:\n",
        "        print(\"No hay tabla_boot para mostrar.\")\n",
        "        return\n",
        "\n",
        "    tb = tabla.copy()\n",
        "\n",
        "    # (opcional) limitar filas visibles en pantalla\n",
        "    tb_show = tb.head(max_rows).copy()\n",
        "\n",
        "    # ordena columnas\n",
        "    cols = [\"Endog\",\"Exog\",\"Beta\",\"CI_2.5%\",\"CI_97.5%\",\"SE\",\"t\",\"p\",\"Sig_0.05\"]\n",
        "    tb_show = tb_show[[c for c in cols if c in tb_show.columns]]\n",
        "\n",
        "    sty = (\n",
        "        tb_show.style\n",
        "        .format({\n",
        "            \"Beta\": \"{:+.4f}\",\n",
        "            \"CI_2.5%\": \"{:+.4f}\",\n",
        "            \"CI_97.5%\": \"{:+.4f}\",\n",
        "            \"SE\": \"{:.4f}\",\n",
        "            \"t\": \"{:.3f}\",\n",
        "            \"p\": \"{:.4f}\",\n",
        "        }, na_rep=\"NA\")\n",
        "        .set_properties(**{\"text-align\":\"center\", \"white-space\":\"nowrap\"})\n",
        "        .set_table_styles([\n",
        "            {\"selector\":\"th\", \"props\":[(\"text-align\",\"center\"), (\"white-space\",\"nowrap\")]},\n",
        "            {\"selector\":\"td\", \"props\":[(\"text-align\",\"center\"), (\"white-space\",\"nowrap\")]},\n",
        "            {\"selector\":\"table\", \"props\":[(\"border-collapse\",\"collapse\"), (\"width\",\"max-content\")]}\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    display(HTML(\"<div style='max-width:100%; overflow-x:auto; border:1px solid #eee; padding:8px;'>\" +\n",
        "                 sty.to_html() +\n",
        "                 \"</div>\"))\n",
        "\n",
        "# Muestra tabla completa (o top N si es enorme)\n",
        "mostrar_tabla_bootstrap(tabla_boot, max_rows=300)\n",
        "\n",
        "# (Opcional) exportar\n",
        "# tabla_boot.to_csv(\"bootstrap_paths.csv\", index=False)\n",
        "# tabla_boot.to_excel(\"bootstrap_paths.xlsx\", index=False)\n",
        "\n",
        "print(\"\\n✅ Listo. Ya tienes CI + p para todos en una tabla bien renderizada (no consola).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yZuXH5v7UDr1",
        "outputId": "cc2a9276-8e17-4895-aee8-cccc90670ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imputación NaN: antes=8, después=0\n",
            "✅ df_analisis listo. Shape: (240, 47)\n",
            "\n",
            "====================\n",
            "R² (endógenas)\n",
            "====================\n",
            "actitud: 0.131\n",
            "engagement: 0.174\n",
            "predisposicion_a_comprar_un_producto: 0.051\n",
            "\n",
            "====================\n",
            "FOCO: conciencia de la persuasión (directos)\n",
            "====================\n",
            "conciencia_de_la_persuasion -> actitud                              β=+0.101  (esperas NEGATIVO)\n",
            "conciencia_de_la_persuasion -> engagement                           β=+0.141  (esperas NEGATIVO)\n",
            "conciencia_de_la_persuasion -> predisposicion_a_comprar_un_producto  β=+0.217  (esperas NEGATIVO)\n",
            "\n",
            "====================\n",
            "BOOTSTRAP (B=5000) - CI y p empírico\n",
            "====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bootstrap (B=5000): 100%|██████████| 5000/5000 [26:26<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='max-width:100%; overflow-x:auto; border:1px solid #eee; padding:8px;'><style type=\"text/css\">\n",
              "#T_d9ae7 th {\n",
              "  text-align: center;\n",
              "  white-space: nowrap;\n",
              "}\n",
              "#T_d9ae7 td {\n",
              "  text-align: center;\n",
              "  white-space: nowrap;\n",
              "}\n",
              "#T_d9ae7 table {\n",
              "  border-collapse: collapse;\n",
              "  width: max-content;\n",
              "}\n",
              "#T_d9ae7_row0_col0, #T_d9ae7_row0_col1, #T_d9ae7_row0_col2, #T_d9ae7_row0_col3, #T_d9ae7_row0_col4, #T_d9ae7_row0_col5, #T_d9ae7_row0_col6, #T_d9ae7_row0_col7, #T_d9ae7_row0_col8, #T_d9ae7_row1_col0, #T_d9ae7_row1_col1, #T_d9ae7_row1_col2, #T_d9ae7_row1_col3, #T_d9ae7_row1_col4, #T_d9ae7_row1_col5, #T_d9ae7_row1_col6, #T_d9ae7_row1_col7, #T_d9ae7_row1_col8, #T_d9ae7_row2_col0, #T_d9ae7_row2_col1, #T_d9ae7_row2_col2, #T_d9ae7_row2_col3, #T_d9ae7_row2_col4, #T_d9ae7_row2_col5, #T_d9ae7_row2_col6, #T_d9ae7_row2_col7, #T_d9ae7_row2_col8, #T_d9ae7_row3_col0, #T_d9ae7_row3_col1, #T_d9ae7_row3_col2, #T_d9ae7_row3_col3, #T_d9ae7_row3_col4, #T_d9ae7_row3_col5, #T_d9ae7_row3_col6, #T_d9ae7_row3_col7, #T_d9ae7_row3_col8, #T_d9ae7_row4_col0, #T_d9ae7_row4_col1, #T_d9ae7_row4_col2, #T_d9ae7_row4_col3, #T_d9ae7_row4_col4, #T_d9ae7_row4_col5, #T_d9ae7_row4_col6, #T_d9ae7_row4_col7, #T_d9ae7_row4_col8, #T_d9ae7_row5_col0, #T_d9ae7_row5_col1, #T_d9ae7_row5_col2, #T_d9ae7_row5_col3, #T_d9ae7_row5_col4, #T_d9ae7_row5_col5, #T_d9ae7_row5_col6, #T_d9ae7_row5_col7, #T_d9ae7_row5_col8, #T_d9ae7_row6_col0, #T_d9ae7_row6_col1, #T_d9ae7_row6_col2, #T_d9ae7_row6_col3, #T_d9ae7_row6_col4, #T_d9ae7_row6_col5, #T_d9ae7_row6_col6, #T_d9ae7_row6_col7, #T_d9ae7_row6_col8, #T_d9ae7_row7_col0, #T_d9ae7_row7_col1, #T_d9ae7_row7_col2, #T_d9ae7_row7_col3, #T_d9ae7_row7_col4, #T_d9ae7_row7_col5, #T_d9ae7_row7_col6, #T_d9ae7_row7_col7, #T_d9ae7_row7_col8, #T_d9ae7_row8_col0, #T_d9ae7_row8_col1, #T_d9ae7_row8_col2, #T_d9ae7_row8_col3, #T_d9ae7_row8_col4, #T_d9ae7_row8_col5, #T_d9ae7_row8_col6, #T_d9ae7_row8_col7, #T_d9ae7_row8_col8, #T_d9ae7_row9_col0, #T_d9ae7_row9_col1, #T_d9ae7_row9_col2, #T_d9ae7_row9_col3, #T_d9ae7_row9_col4, #T_d9ae7_row9_col5, #T_d9ae7_row9_col6, #T_d9ae7_row9_col7, #T_d9ae7_row9_col8, #T_d9ae7_row10_col0, #T_d9ae7_row10_col1, #T_d9ae7_row10_col2, #T_d9ae7_row10_col3, #T_d9ae7_row10_col4, #T_d9ae7_row10_col5, #T_d9ae7_row10_col6, #T_d9ae7_row10_col7, #T_d9ae7_row10_col8, #T_d9ae7_row11_col0, #T_d9ae7_row11_col1, #T_d9ae7_row11_col2, #T_d9ae7_row11_col3, #T_d9ae7_row11_col4, #T_d9ae7_row11_col5, #T_d9ae7_row11_col6, #T_d9ae7_row11_col7, #T_d9ae7_row11_col8, #T_d9ae7_row12_col0, #T_d9ae7_row12_col1, #T_d9ae7_row12_col2, #T_d9ae7_row12_col3, #T_d9ae7_row12_col4, #T_d9ae7_row12_col5, #T_d9ae7_row12_col6, #T_d9ae7_row12_col7, #T_d9ae7_row12_col8, #T_d9ae7_row13_col0, #T_d9ae7_row13_col1, #T_d9ae7_row13_col2, #T_d9ae7_row13_col3, #T_d9ae7_row13_col4, #T_d9ae7_row13_col5, #T_d9ae7_row13_col6, #T_d9ae7_row13_col7, #T_d9ae7_row13_col8, #T_d9ae7_row14_col0, #T_d9ae7_row14_col1, #T_d9ae7_row14_col2, #T_d9ae7_row14_col3, #T_d9ae7_row14_col4, #T_d9ae7_row14_col5, #T_d9ae7_row14_col6, #T_d9ae7_row14_col7, #T_d9ae7_row14_col8, #T_d9ae7_row15_col0, #T_d9ae7_row15_col1, #T_d9ae7_row15_col2, #T_d9ae7_row15_col3, #T_d9ae7_row15_col4, #T_d9ae7_row15_col5, #T_d9ae7_row15_col6, #T_d9ae7_row15_col7, #T_d9ae7_row15_col8, #T_d9ae7_row16_col0, #T_d9ae7_row16_col1, #T_d9ae7_row16_col2, #T_d9ae7_row16_col3, #T_d9ae7_row16_col4, #T_d9ae7_row16_col5, #T_d9ae7_row16_col6, #T_d9ae7_row16_col7, #T_d9ae7_row16_col8, #T_d9ae7_row17_col0, #T_d9ae7_row17_col1, #T_d9ae7_row17_col2, #T_d9ae7_row17_col3, #T_d9ae7_row17_col4, #T_d9ae7_row17_col5, #T_d9ae7_row17_col6, #T_d9ae7_row17_col7, #T_d9ae7_row17_col8, #T_d9ae7_row18_col0, #T_d9ae7_row18_col1, #T_d9ae7_row18_col2, #T_d9ae7_row18_col3, #T_d9ae7_row18_col4, #T_d9ae7_row18_col5, #T_d9ae7_row18_col6, #T_d9ae7_row18_col7, #T_d9ae7_row18_col8, #T_d9ae7_row19_col0, #T_d9ae7_row19_col1, #T_d9ae7_row19_col2, #T_d9ae7_row19_col3, #T_d9ae7_row19_col4, #T_d9ae7_row19_col5, #T_d9ae7_row19_col6, #T_d9ae7_row19_col7, #T_d9ae7_row19_col8, #T_d9ae7_row20_col0, #T_d9ae7_row20_col1, #T_d9ae7_row20_col2, #T_d9ae7_row20_col3, #T_d9ae7_row20_col4, #T_d9ae7_row20_col5, #T_d9ae7_row20_col6, #T_d9ae7_row20_col7, #T_d9ae7_row20_col8, #T_d9ae7_row21_col0, #T_d9ae7_row21_col1, #T_d9ae7_row21_col2, #T_d9ae7_row21_col3, #T_d9ae7_row21_col4, #T_d9ae7_row21_col5, #T_d9ae7_row21_col6, #T_d9ae7_row21_col7, #T_d9ae7_row21_col8, #T_d9ae7_row22_col0, #T_d9ae7_row22_col1, #T_d9ae7_row22_col2, #T_d9ae7_row22_col3, #T_d9ae7_row22_col4, #T_d9ae7_row22_col5, #T_d9ae7_row22_col6, #T_d9ae7_row22_col7, #T_d9ae7_row22_col8, #T_d9ae7_row23_col0, #T_d9ae7_row23_col1, #T_d9ae7_row23_col2, #T_d9ae7_row23_col3, #T_d9ae7_row23_col4, #T_d9ae7_row23_col5, #T_d9ae7_row23_col6, #T_d9ae7_row23_col7, #T_d9ae7_row23_col8, #T_d9ae7_row24_col0, #T_d9ae7_row24_col1, #T_d9ae7_row24_col2, #T_d9ae7_row24_col3, #T_d9ae7_row24_col4, #T_d9ae7_row24_col5, #T_d9ae7_row24_col6, #T_d9ae7_row24_col7, #T_d9ae7_row24_col8, #T_d9ae7_row25_col0, #T_d9ae7_row25_col1, #T_d9ae7_row25_col2, #T_d9ae7_row25_col3, #T_d9ae7_row25_col4, #T_d9ae7_row25_col5, #T_d9ae7_row25_col6, #T_d9ae7_row25_col7, #T_d9ae7_row25_col8, #T_d9ae7_row26_col0, #T_d9ae7_row26_col1, #T_d9ae7_row26_col2, #T_d9ae7_row26_col3, #T_d9ae7_row26_col4, #T_d9ae7_row26_col5, #T_d9ae7_row26_col6, #T_d9ae7_row26_col7, #T_d9ae7_row26_col8, #T_d9ae7_row27_col0, #T_d9ae7_row27_col1, #T_d9ae7_row27_col2, #T_d9ae7_row27_col3, #T_d9ae7_row27_col4, #T_d9ae7_row27_col5, #T_d9ae7_row27_col6, #T_d9ae7_row27_col7, #T_d9ae7_row27_col8, #T_d9ae7_row28_col0, #T_d9ae7_row28_col1, #T_d9ae7_row28_col2, #T_d9ae7_row28_col3, #T_d9ae7_row28_col4, #T_d9ae7_row28_col5, #T_d9ae7_row28_col6, #T_d9ae7_row28_col7, #T_d9ae7_row28_col8, #T_d9ae7_row29_col0, #T_d9ae7_row29_col1, #T_d9ae7_row29_col2, #T_d9ae7_row29_col3, #T_d9ae7_row29_col4, #T_d9ae7_row29_col5, #T_d9ae7_row29_col6, #T_d9ae7_row29_col7, #T_d9ae7_row29_col8, #T_d9ae7_row30_col0, #T_d9ae7_row30_col1, #T_d9ae7_row30_col2, #T_d9ae7_row30_col3, #T_d9ae7_row30_col4, #T_d9ae7_row30_col5, #T_d9ae7_row30_col6, #T_d9ae7_row30_col7, #T_d9ae7_row30_col8, #T_d9ae7_row31_col0, #T_d9ae7_row31_col1, #T_d9ae7_row31_col2, #T_d9ae7_row31_col3, #T_d9ae7_row31_col4, #T_d9ae7_row31_col5, #T_d9ae7_row31_col6, #T_d9ae7_row31_col7, #T_d9ae7_row31_col8, #T_d9ae7_row32_col0, #T_d9ae7_row32_col1, #T_d9ae7_row32_col2, #T_d9ae7_row32_col3, #T_d9ae7_row32_col4, #T_d9ae7_row32_col5, #T_d9ae7_row32_col6, #T_d9ae7_row32_col7, #T_d9ae7_row32_col8, #T_d9ae7_row33_col0, #T_d9ae7_row33_col1, #T_d9ae7_row33_col2, #T_d9ae7_row33_col3, #T_d9ae7_row33_col4, #T_d9ae7_row33_col5, #T_d9ae7_row33_col6, #T_d9ae7_row33_col7, #T_d9ae7_row33_col8, #T_d9ae7_row34_col0, #T_d9ae7_row34_col1, #T_d9ae7_row34_col2, #T_d9ae7_row34_col3, #T_d9ae7_row34_col4, #T_d9ae7_row34_col5, #T_d9ae7_row34_col6, #T_d9ae7_row34_col7, #T_d9ae7_row34_col8, #T_d9ae7_row35_col0, #T_d9ae7_row35_col1, #T_d9ae7_row35_col2, #T_d9ae7_row35_col3, #T_d9ae7_row35_col4, #T_d9ae7_row35_col5, #T_d9ae7_row35_col6, #T_d9ae7_row35_col7, #T_d9ae7_row35_col8, #T_d9ae7_row36_col0, #T_d9ae7_row36_col1, #T_d9ae7_row36_col2, #T_d9ae7_row36_col3, #T_d9ae7_row36_col4, #T_d9ae7_row36_col5, #T_d9ae7_row36_col6, #T_d9ae7_row36_col7, #T_d9ae7_row36_col8, #T_d9ae7_row37_col0, #T_d9ae7_row37_col1, #T_d9ae7_row37_col2, #T_d9ae7_row37_col3, #T_d9ae7_row37_col4, #T_d9ae7_row37_col5, #T_d9ae7_row37_col6, #T_d9ae7_row37_col7, #T_d9ae7_row37_col8, #T_d9ae7_row38_col0, #T_d9ae7_row38_col1, #T_d9ae7_row38_col2, #T_d9ae7_row38_col3, #T_d9ae7_row38_col4, #T_d9ae7_row38_col5, #T_d9ae7_row38_col6, #T_d9ae7_row38_col7, #T_d9ae7_row38_col8, #T_d9ae7_row39_col0, #T_d9ae7_row39_col1, #T_d9ae7_row39_col2, #T_d9ae7_row39_col3, #T_d9ae7_row39_col4, #T_d9ae7_row39_col5, #T_d9ae7_row39_col6, #T_d9ae7_row39_col7, #T_d9ae7_row39_col8, #T_d9ae7_row40_col0, #T_d9ae7_row40_col1, #T_d9ae7_row40_col2, #T_d9ae7_row40_col3, #T_d9ae7_row40_col4, #T_d9ae7_row40_col5, #T_d9ae7_row40_col6, #T_d9ae7_row40_col7, #T_d9ae7_row40_col8, #T_d9ae7_row41_col0, #T_d9ae7_row41_col1, #T_d9ae7_row41_col2, #T_d9ae7_row41_col3, #T_d9ae7_row41_col4, #T_d9ae7_row41_col5, #T_d9ae7_row41_col6, #T_d9ae7_row41_col7, #T_d9ae7_row41_col8, #T_d9ae7_row42_col0, #T_d9ae7_row42_col1, #T_d9ae7_row42_col2, #T_d9ae7_row42_col3, #T_d9ae7_row42_col4, #T_d9ae7_row42_col5, #T_d9ae7_row42_col6, #T_d9ae7_row42_col7, #T_d9ae7_row42_col8 {\n",
              "  text-align: center;\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_d9ae7\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d9ae7_level0_col0\" class=\"col_heading level0 col0\" >Endog</th>\n",
              "      <th id=\"T_d9ae7_level0_col1\" class=\"col_heading level0 col1\" >Exog</th>\n",
              "      <th id=\"T_d9ae7_level0_col2\" class=\"col_heading level0 col2\" >Beta</th>\n",
              "      <th id=\"T_d9ae7_level0_col3\" class=\"col_heading level0 col3\" >CI_2.5%</th>\n",
              "      <th id=\"T_d9ae7_level0_col4\" class=\"col_heading level0 col4\" >CI_97.5%</th>\n",
              "      <th id=\"T_d9ae7_level0_col5\" class=\"col_heading level0 col5\" >SE</th>\n",
              "      <th id=\"T_d9ae7_level0_col6\" class=\"col_heading level0 col6\" >t</th>\n",
              "      <th id=\"T_d9ae7_level0_col7\" class=\"col_heading level0 col7\" >p</th>\n",
              "      <th id=\"T_d9ae7_level0_col8\" class=\"col_heading level0 col8\" >Sig_0.05</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row0\" class=\"row_heading level0 row0\" >40</th>\n",
              "      <td id=\"T_d9ae7_row0_col0\" class=\"data row0 col0\" >predisposicion_a_comprar_un_producto</td>\n",
              "      <td id=\"T_d9ae7_row0_col1\" class=\"data row0 col1\" >conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row0_col2\" class=\"data row0 col2\" >+0.2172</td>\n",
              "      <td id=\"T_d9ae7_row0_col3\" class=\"data row0 col3\" >+0.1014</td>\n",
              "      <td id=\"T_d9ae7_row0_col4\" class=\"data row0 col4\" >+0.3339</td>\n",
              "      <td id=\"T_d9ae7_row0_col5\" class=\"data row0 col5\" >0.0604</td>\n",
              "      <td id=\"T_d9ae7_row0_col6\" class=\"data row0 col6\" >3.596</td>\n",
              "      <td id=\"T_d9ae7_row0_col7\" class=\"data row0 col7\" >0.0008</td>\n",
              "      <td id=\"T_d9ae7_row0_col8\" class=\"data row0 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row1\" class=\"row_heading level0 row1\" >24</th>\n",
              "      <td id=\"T_d9ae7_row1_col0\" class=\"data row1 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row1_col1\" class=\"data row1 col1\" >lider_de_opinion</td>\n",
              "      <td id=\"T_d9ae7_row1_col2\" class=\"data row1 col2\" >+0.2556</td>\n",
              "      <td id=\"T_d9ae7_row1_col3\" class=\"data row1 col3\" >+0.1087</td>\n",
              "      <td id=\"T_d9ae7_row1_col4\" class=\"data row1 col4\" >+0.3857</td>\n",
              "      <td id=\"T_d9ae7_row1_col5\" class=\"data row1 col5\" >0.0710</td>\n",
              "      <td id=\"T_d9ae7_row1_col6\" class=\"data row1 col6\" >3.602</td>\n",
              "      <td id=\"T_d9ae7_row1_col7\" class=\"data row1 col7\" >0.0012</td>\n",
              "      <td id=\"T_d9ae7_row1_col8\" class=\"data row1 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row2\" class=\"row_heading level0 row2\" >27</th>\n",
              "      <td id=\"T_d9ae7_row2_col0\" class=\"data row2 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row2_col1\" class=\"data row2 col1\" >congruencia_influencer_producto</td>\n",
              "      <td id=\"T_d9ae7_row2_col2\" class=\"data row2 col2\" >+0.1802</td>\n",
              "      <td id=\"T_d9ae7_row2_col3\" class=\"data row2 col3\" >+0.0350</td>\n",
              "      <td id=\"T_d9ae7_row2_col4\" class=\"data row2 col4\" >+0.2900</td>\n",
              "      <td id=\"T_d9ae7_row2_col5\" class=\"data row2 col5\" >0.0653</td>\n",
              "      <td id=\"T_d9ae7_row2_col6\" class=\"data row2 col6\" >2.759</td>\n",
              "      <td id=\"T_d9ae7_row2_col7\" class=\"data row2 col7\" >0.0100</td>\n",
              "      <td id=\"T_d9ae7_row2_col8\" class=\"data row2 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row3\" class=\"row_heading level0 row3\" >29</th>\n",
              "      <td id=\"T_d9ae7_row3_col0\" class=\"data row3 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row3_col1\" class=\"data row3 col1\" >integridad_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row3_col2\" class=\"data row3 col2\" >+0.1612</td>\n",
              "      <td id=\"T_d9ae7_row3_col3\" class=\"data row3 col3\" >+0.0335</td>\n",
              "      <td id=\"T_d9ae7_row3_col4\" class=\"data row3 col4\" >+0.2894</td>\n",
              "      <td id=\"T_d9ae7_row3_col5\" class=\"data row3 col5\" >0.0635</td>\n",
              "      <td id=\"T_d9ae7_row3_col6\" class=\"data row3 col6\" >2.539</td>\n",
              "      <td id=\"T_d9ae7_row3_col7\" class=\"data row3 col7\" >0.0116</td>\n",
              "      <td id=\"T_d9ae7_row3_col8\" class=\"data row3 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row4\" class=\"row_heading level0 row4\" >13</th>\n",
              "      <td id=\"T_d9ae7_row4_col0\" class=\"data row4 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row4_col1\" class=\"data row4 col1\" >atractividad_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row4_col2\" class=\"data row4 col2\" >+0.1975</td>\n",
              "      <td id=\"T_d9ae7_row4_col3\" class=\"data row4 col3\" >+0.0476</td>\n",
              "      <td id=\"T_d9ae7_row4_col4\" class=\"data row4 col4\" >+0.3394</td>\n",
              "      <td id=\"T_d9ae7_row4_col5\" class=\"data row4 col5\" >0.0752</td>\n",
              "      <td id=\"T_d9ae7_row4_col6\" class=\"data row4 col6\" >2.624</td>\n",
              "      <td id=\"T_d9ae7_row4_col7\" class=\"data row4 col7\" >0.0152</td>\n",
              "      <td id=\"T_d9ae7_row4_col8\" class=\"data row4 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row5\" class=\"row_heading level0 row5\" >14</th>\n",
              "      <td id=\"T_d9ae7_row5_col0\" class=\"data row5 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row5_col1\" class=\"data row5 col1\" >similitud_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row5_col2\" class=\"data row5 col2\" >-0.2049</td>\n",
              "      <td id=\"T_d9ae7_row5_col3\" class=\"data row5 col3\" >-0.3675</td>\n",
              "      <td id=\"T_d9ae7_row5_col4\" class=\"data row5 col4\" >-0.0317</td>\n",
              "      <td id=\"T_d9ae7_row5_col5\" class=\"data row5 col5\" >0.0848</td>\n",
              "      <td id=\"T_d9ae7_row5_col6\" class=\"data row5 col6\" >-2.415</td>\n",
              "      <td id=\"T_d9ae7_row5_col7\" class=\"data row5 col7\" >0.0212</td>\n",
              "      <td id=\"T_d9ae7_row5_col8\" class=\"data row5 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row6\" class=\"row_heading level0 row6\" >33</th>\n",
              "      <td id=\"T_d9ae7_row6_col0\" class=\"data row6 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row6_col1\" class=\"data row6 col1\" >similitud_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row6_col2\" class=\"data row6 col2\" >+0.1207</td>\n",
              "      <td id=\"T_d9ae7_row6_col3\" class=\"data row6 col3\" >+0.0105</td>\n",
              "      <td id=\"T_d9ae7_row6_col4\" class=\"data row6 col4\" >+0.2332</td>\n",
              "      <td id=\"T_d9ae7_row6_col5\" class=\"data row6 col5\" >0.0571</td>\n",
              "      <td id=\"T_d9ae7_row6_col6\" class=\"data row6 col6\" >2.113</td>\n",
              "      <td id=\"T_d9ae7_row6_col7\" class=\"data row6 col7\" >0.0332</td>\n",
              "      <td id=\"T_d9ae7_row6_col8\" class=\"data row6 col8\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row7\" class=\"row_heading level0 row7\" >28</th>\n",
              "      <td id=\"T_d9ae7_row7_col0\" class=\"data row7 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row7_col1\" class=\"data row7 col1\" >conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row7_col2\" class=\"data row7 col2\" >+0.1414</td>\n",
              "      <td id=\"T_d9ae7_row7_col3\" class=\"data row7 col3\" >-0.0170</td>\n",
              "      <td id=\"T_d9ae7_row7_col4\" class=\"data row7 col4\" >+0.2715</td>\n",
              "      <td id=\"T_d9ae7_row7_col5\" class=\"data row7 col5\" >0.0742</td>\n",
              "      <td id=\"T_d9ae7_row7_col6\" class=\"data row7 col6\" >1.906</td>\n",
              "      <td id=\"T_d9ae7_row7_col7\" class=\"data row7 col7\" >0.0792</td>\n",
              "      <td id=\"T_d9ae7_row7_col8\" class=\"data row7 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row8\" class=\"row_heading level0 row8\" >12</th>\n",
              "      <td id=\"T_d9ae7_row8_col0\" class=\"data row8 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row8_col1\" class=\"data row8 col1\" >autenticidad_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row8_col2\" class=\"data row8 col2\" >-0.1473</td>\n",
              "      <td id=\"T_d9ae7_row8_col3\" class=\"data row8 col3\" >-0.2934</td>\n",
              "      <td id=\"T_d9ae7_row8_col4\" class=\"data row8 col4\" >+0.0171</td>\n",
              "      <td id=\"T_d9ae7_row8_col5\" class=\"data row8 col5\" >0.0785</td>\n",
              "      <td id=\"T_d9ae7_row8_col6\" class=\"data row8 col6\" >-1.875</td>\n",
              "      <td id=\"T_d9ae7_row8_col7\" class=\"data row8 col7\" >0.0800</td>\n",
              "      <td id=\"T_d9ae7_row8_col8\" class=\"data row8 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row9\" class=\"row_heading level0 row9\" >25</th>\n",
              "      <td id=\"T_d9ae7_row9_col0\" class=\"data row9 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row9_col1\" class=\"data row9 col1\" >informatividad_del_contenido</td>\n",
              "      <td id=\"T_d9ae7_row9_col2\" class=\"data row9 col2\" >+0.0918</td>\n",
              "      <td id=\"T_d9ae7_row9_col3\" class=\"data row9 col3\" >-0.0227</td>\n",
              "      <td id=\"T_d9ae7_row9_col4\" class=\"data row9 col4\" >+0.2151</td>\n",
              "      <td id=\"T_d9ae7_row9_col5\" class=\"data row9 col5\" >0.0606</td>\n",
              "      <td id=\"T_d9ae7_row9_col6\" class=\"data row9 col6\" >1.516</td>\n",
              "      <td id=\"T_d9ae7_row9_col7\" class=\"data row9 col7\" >0.1112</td>\n",
              "      <td id=\"T_d9ae7_row9_col8\" class=\"data row9 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row10\" class=\"row_heading level0 row10\" >21</th>\n",
              "      <td id=\"T_d9ae7_row10_col0\" class=\"data row10 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row10_col1\" class=\"data row10 col1\" >autenticidad</td>\n",
              "      <td id=\"T_d9ae7_row10_col2\" class=\"data row10 col2\" >-0.0983</td>\n",
              "      <td id=\"T_d9ae7_row10_col3\" class=\"data row10 col3\" >-0.2147</td>\n",
              "      <td id=\"T_d9ae7_row10_col4\" class=\"data row10 col4\" >+0.0289</td>\n",
              "      <td id=\"T_d9ae7_row10_col5\" class=\"data row10 col5\" >0.0621</td>\n",
              "      <td id=\"T_d9ae7_row10_col6\" class=\"data row10 col6\" >-1.584</td>\n",
              "      <td id=\"T_d9ae7_row10_col7\" class=\"data row10 col7\" >0.1304</td>\n",
              "      <td id=\"T_d9ae7_row10_col8\" class=\"data row10 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row11\" class=\"row_heading level0 row11\" >17</th>\n",
              "      <td id=\"T_d9ae7_row11_col0\" class=\"data row11 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row11_col1\" class=\"data row11 col1\" >congruencia_influencer_follower_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row11_col2\" class=\"data row11 col2\" >+0.1133</td>\n",
              "      <td id=\"T_d9ae7_row11_col3\" class=\"data row11 col3\" >-0.0346</td>\n",
              "      <td id=\"T_d9ae7_row11_col4\" class=\"data row11 col4\" >+0.2511</td>\n",
              "      <td id=\"T_d9ae7_row11_col5\" class=\"data row11 col5\" >0.0728</td>\n",
              "      <td id=\"T_d9ae7_row11_col6\" class=\"data row11 col6\" >1.556</td>\n",
              "      <td id=\"T_d9ae7_row11_col7\" class=\"data row11 col7\" >0.1320</td>\n",
              "      <td id=\"T_d9ae7_row11_col8\" class=\"data row11 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row12\" class=\"row_heading level0 row12\" >4</th>\n",
              "      <td id=\"T_d9ae7_row12_col0\" class=\"data row12 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row12_col1\" class=\"data row12 col1\" >similitud</td>\n",
              "      <td id=\"T_d9ae7_row12_col2\" class=\"data row12 col2\" >+0.1247</td>\n",
              "      <td id=\"T_d9ae7_row12_col3\" class=\"data row12 col3\" >-0.0338</td>\n",
              "      <td id=\"T_d9ae7_row12_col4\" class=\"data row12 col4\" >+0.2807</td>\n",
              "      <td id=\"T_d9ae7_row12_col5\" class=\"data row12 col5\" >0.0815</td>\n",
              "      <td id=\"T_d9ae7_row12_col6\" class=\"data row12 col6\" >1.529</td>\n",
              "      <td id=\"T_d9ae7_row12_col7\" class=\"data row12 col7\" >0.1388</td>\n",
              "      <td id=\"T_d9ae7_row12_col8\" class=\"data row12 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row13\" class=\"row_heading level0 row13\" >1</th>\n",
              "      <td id=\"T_d9ae7_row13_col0\" class=\"data row13 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row13_col1\" class=\"data row13 col1\" >expertis</td>\n",
              "      <td id=\"T_d9ae7_row13_col2\" class=\"data row13 col2\" >+0.0962</td>\n",
              "      <td id=\"T_d9ae7_row13_col3\" class=\"data row13 col3\" >-0.0439</td>\n",
              "      <td id=\"T_d9ae7_row13_col4\" class=\"data row13 col4\" >+0.2305</td>\n",
              "      <td id=\"T_d9ae7_row13_col5\" class=\"data row13 col5\" >0.0690</td>\n",
              "      <td id=\"T_d9ae7_row13_col6\" class=\"data row13 col6\" >1.395</td>\n",
              "      <td id=\"T_d9ae7_row13_col7\" class=\"data row13 col7\" >0.1688</td>\n",
              "      <td id=\"T_d9ae7_row13_col8\" class=\"data row13 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row14\" class=\"row_heading level0 row14\" >9</th>\n",
              "      <td id=\"T_d9ae7_row14_col0\" class=\"data row14 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row14_col1\" class=\"data row14 col1\" >conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row14_col2\" class=\"data row14 col2\" >+0.1007</td>\n",
              "      <td id=\"T_d9ae7_row14_col3\" class=\"data row14 col3\" >-0.0445</td>\n",
              "      <td id=\"T_d9ae7_row14_col4\" class=\"data row14 col4\" >+0.2570</td>\n",
              "      <td id=\"T_d9ae7_row14_col5\" class=\"data row14 col5\" >0.0765</td>\n",
              "      <td id=\"T_d9ae7_row14_col6\" class=\"data row14 col6\" >1.316</td>\n",
              "      <td id=\"T_d9ae7_row14_col7\" class=\"data row14 col7\" >0.1732</td>\n",
              "      <td id=\"T_d9ae7_row14_col8\" class=\"data row14 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row15\" class=\"row_heading level0 row15\" >8</th>\n",
              "      <td id=\"T_d9ae7_row15_col0\" class=\"data row15 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row15_col1\" class=\"data row15 col1\" >congruencia_influencer_producto</td>\n",
              "      <td id=\"T_d9ae7_row15_col2\" class=\"data row15 col2\" >+0.0790</td>\n",
              "      <td id=\"T_d9ae7_row15_col3\" class=\"data row15 col3\" >-0.0366</td>\n",
              "      <td id=\"T_d9ae7_row15_col4\" class=\"data row15 col4\" >+0.2028</td>\n",
              "      <td id=\"T_d9ae7_row15_col5\" class=\"data row15 col5\" >0.0614</td>\n",
              "      <td id=\"T_d9ae7_row15_col6\" class=\"data row15 col6\" >1.288</td>\n",
              "      <td id=\"T_d9ae7_row15_col7\" class=\"data row15 col7\" >0.1764</td>\n",
              "      <td id=\"T_d9ae7_row15_col8\" class=\"data row15 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row16\" class=\"row_heading level0 row16\" >2</th>\n",
              "      <td id=\"T_d9ae7_row16_col0\" class=\"data row16 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row16_col1\" class=\"data row16 col1\" >autenticidad</td>\n",
              "      <td id=\"T_d9ae7_row16_col2\" class=\"data row16 col2\" >+0.0816</td>\n",
              "      <td id=\"T_d9ae7_row16_col3\" class=\"data row16 col3\" >-0.0425</td>\n",
              "      <td id=\"T_d9ae7_row16_col4\" class=\"data row16 col4\" >+0.1963</td>\n",
              "      <td id=\"T_d9ae7_row16_col5\" class=\"data row16 col5\" >0.0607</td>\n",
              "      <td id=\"T_d9ae7_row16_col6\" class=\"data row16 col6\" >1.343</td>\n",
              "      <td id=\"T_d9ae7_row16_col7\" class=\"data row16 col7\" >0.2004</td>\n",
              "      <td id=\"T_d9ae7_row16_col8\" class=\"data row16 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row17\" class=\"row_heading level0 row17\" >10</th>\n",
              "      <td id=\"T_d9ae7_row17_col0\" class=\"data row17 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row17_col1\" class=\"data row17 col1\" >integridad_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row17_col2\" class=\"data row17 col2\" >+0.0835</td>\n",
              "      <td id=\"T_d9ae7_row17_col3\" class=\"data row17 col3\" >-0.0498</td>\n",
              "      <td id=\"T_d9ae7_row17_col4\" class=\"data row17 col4\" >+0.2285</td>\n",
              "      <td id=\"T_d9ae7_row17_col5\" class=\"data row17 col5\" >0.0723</td>\n",
              "      <td id=\"T_d9ae7_row17_col6\" class=\"data row17 col6\" >1.154</td>\n",
              "      <td id=\"T_d9ae7_row17_col7\" class=\"data row17 col7\" >0.2212</td>\n",
              "      <td id=\"T_d9ae7_row17_col8\" class=\"data row17 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row18\" class=\"row_heading level0 row18\" >11</th>\n",
              "      <td id=\"T_d9ae7_row18_col0\" class=\"data row18 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row18_col1\" class=\"data row18 col1\" >expertis_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row18_col2\" class=\"data row18 col2\" >-0.1031</td>\n",
              "      <td id=\"T_d9ae7_row18_col3\" class=\"data row18 col3\" >-0.2707</td>\n",
              "      <td id=\"T_d9ae7_row18_col4\" class=\"data row18 col4\" >+0.0536</td>\n",
              "      <td id=\"T_d9ae7_row18_col5\" class=\"data row18 col5\" >0.0827</td>\n",
              "      <td id=\"T_d9ae7_row18_col6\" class=\"data row18 col6\" >-1.246</td>\n",
              "      <td id=\"T_d9ae7_row18_col7\" class=\"data row18 col7\" >0.2244</td>\n",
              "      <td id=\"T_d9ae7_row18_col8\" class=\"data row18 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row19\" class=\"row_heading level0 row19\" >26</th>\n",
              "      <td id=\"T_d9ae7_row19_col0\" class=\"data row19 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row19_col1\" class=\"data row19 col1\" >congruencia_influencer_follower</td>\n",
              "      <td id=\"T_d9ae7_row19_col2\" class=\"data row19 col2\" >-0.0763</td>\n",
              "      <td id=\"T_d9ae7_row19_col3\" class=\"data row19 col3\" >-0.1895</td>\n",
              "      <td id=\"T_d9ae7_row19_col4\" class=\"data row19 col4\" >+0.0514</td>\n",
              "      <td id=\"T_d9ae7_row19_col5\" class=\"data row19 col5\" >0.0612</td>\n",
              "      <td id=\"T_d9ae7_row19_col6\" class=\"data row19 col6\" >-1.247</td>\n",
              "      <td id=\"T_d9ae7_row19_col7\" class=\"data row19 col7\" >0.2300</td>\n",
              "      <td id=\"T_d9ae7_row19_col8\" class=\"data row19 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row20\" class=\"row_heading level0 row20\" >6</th>\n",
              "      <td id=\"T_d9ae7_row20_col0\" class=\"data row20 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row20_col1\" class=\"data row20 col1\" >informatividad_del_contenido</td>\n",
              "      <td id=\"T_d9ae7_row20_col2\" class=\"data row20 col2\" >+0.0613</td>\n",
              "      <td id=\"T_d9ae7_row20_col3\" class=\"data row20 col3\" >-0.0561</td>\n",
              "      <td id=\"T_d9ae7_row20_col4\" class=\"data row20 col4\" >+0.1860</td>\n",
              "      <td id=\"T_d9ae7_row20_col5\" class=\"data row20 col5\" >0.0606</td>\n",
              "      <td id=\"T_d9ae7_row20_col6\" class=\"data row20 col6\" >1.012</td>\n",
              "      <td id=\"T_d9ae7_row20_col7\" class=\"data row20 col7\" >0.2816</td>\n",
              "      <td id=\"T_d9ae7_row20_col8\" class=\"data row20 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row21\" class=\"row_heading level0 row21\" >18</th>\n",
              "      <td id=\"T_d9ae7_row21_col0\" class=\"data row21 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row21_col1\" class=\"data row21 col1\" >congruencia_influencer_producto_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row21_col2\" class=\"data row21 col2\" >+0.0596</td>\n",
              "      <td id=\"T_d9ae7_row21_col3\" class=\"data row21 col3\" >-0.0797</td>\n",
              "      <td id=\"T_d9ae7_row21_col4\" class=\"data row21 col4\" >+0.1963</td>\n",
              "      <td id=\"T_d9ae7_row21_col5\" class=\"data row21 col5\" >0.0699</td>\n",
              "      <td id=\"T_d9ae7_row21_col6\" class=\"data row21 col6\" >0.853</td>\n",
              "      <td id=\"T_d9ae7_row21_col7\" class=\"data row21 col7\" >0.4200</td>\n",
              "      <td id=\"T_d9ae7_row21_col8\" class=\"data row21 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row22\" class=\"row_heading level0 row22\" >31</th>\n",
              "      <td id=\"T_d9ae7_row22_col0\" class=\"data row22 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row22_col1\" class=\"data row22 col1\" >autenticidad_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row22_col2\" class=\"data row22 col2\" >+0.0502</td>\n",
              "      <td id=\"T_d9ae7_row22_col3\" class=\"data row22 col3\" >-0.0870</td>\n",
              "      <td id=\"T_d9ae7_row22_col4\" class=\"data row22 col4\" >+0.1796</td>\n",
              "      <td id=\"T_d9ae7_row22_col5\" class=\"data row22 col5\" >0.0676</td>\n",
              "      <td id=\"T_d9ae7_row22_col6\" class=\"data row22 col6\" >0.743</td>\n",
              "      <td id=\"T_d9ae7_row22_col7\" class=\"data row22 col7\" >0.4364</td>\n",
              "      <td id=\"T_d9ae7_row22_col8\" class=\"data row22 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row23\" class=\"row_heading level0 row23\" >19</th>\n",
              "      <td id=\"T_d9ae7_row23_col0\" class=\"data row23 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row23_col1\" class=\"data row23 col1\" >integridad</td>\n",
              "      <td id=\"T_d9ae7_row23_col2\" class=\"data row23 col2\" >+0.0563</td>\n",
              "      <td id=\"T_d9ae7_row23_col3\" class=\"data row23 col3\" >-0.0748</td>\n",
              "      <td id=\"T_d9ae7_row23_col4\" class=\"data row23 col4\" >+0.1769</td>\n",
              "      <td id=\"T_d9ae7_row23_col5\" class=\"data row23 col5\" >0.0641</td>\n",
              "      <td id=\"T_d9ae7_row23_col6\" class=\"data row23 col6\" >0.878</td>\n",
              "      <td id=\"T_d9ae7_row23_col7\" class=\"data row23 col7\" >0.4432</td>\n",
              "      <td id=\"T_d9ae7_row23_col8\" class=\"data row23 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row24\" class=\"row_heading level0 row24\" >16</th>\n",
              "      <td id=\"T_d9ae7_row24_col0\" class=\"data row24 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row24_col1\" class=\"data row24 col1\" >informatividad_del_contenido_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row24_col2\" class=\"data row24 col2\" >+0.0529</td>\n",
              "      <td id=\"T_d9ae7_row24_col3\" class=\"data row24 col3\" >-0.0846</td>\n",
              "      <td id=\"T_d9ae7_row24_col4\" class=\"data row24 col4\" >+0.1786</td>\n",
              "      <td id=\"T_d9ae7_row24_col5\" class=\"data row24 col5\" >0.0668</td>\n",
              "      <td id=\"T_d9ae7_row24_col6\" class=\"data row24 col6\" >0.792</td>\n",
              "      <td id=\"T_d9ae7_row24_col7\" class=\"data row24 col7\" >0.4820</td>\n",
              "      <td id=\"T_d9ae7_row24_col8\" class=\"data row24 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row25\" class=\"row_heading level0 row25\" >37</th>\n",
              "      <td id=\"T_d9ae7_row25_col0\" class=\"data row25 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row25_col1\" class=\"data row25 col1\" >congruencia_influencer_producto_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row25_col2\" class=\"data row25 col2\" >-0.0747</td>\n",
              "      <td id=\"T_d9ae7_row25_col3\" class=\"data row25 col3\" >-0.2245</td>\n",
              "      <td id=\"T_d9ae7_row25_col4\" class=\"data row25 col4\" >+0.1230</td>\n",
              "      <td id=\"T_d9ae7_row25_col5\" class=\"data row25 col5\" >0.0895</td>\n",
              "      <td id=\"T_d9ae7_row25_col6\" class=\"data row25 col6\" >-0.835</td>\n",
              "      <td id=\"T_d9ae7_row25_col7\" class=\"data row25 col7\" >0.4924</td>\n",
              "      <td id=\"T_d9ae7_row25_col8\" class=\"data row25 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row26\" class=\"row_heading level0 row26\" >35</th>\n",
              "      <td id=\"T_d9ae7_row26_col0\" class=\"data row26 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row26_col1\" class=\"data row26 col1\" >informatividad_del_contenido_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row26_col2\" class=\"data row26 col2\" >-0.0382</td>\n",
              "      <td id=\"T_d9ae7_row26_col3\" class=\"data row26 col3\" >-0.1819</td>\n",
              "      <td id=\"T_d9ae7_row26_col4\" class=\"data row26 col4\" >+0.0928</td>\n",
              "      <td id=\"T_d9ae7_row26_col5\" class=\"data row26 col5\" >0.0706</td>\n",
              "      <td id=\"T_d9ae7_row26_col6\" class=\"data row26 col6\" >-0.541</td>\n",
              "      <td id=\"T_d9ae7_row26_col7\" class=\"data row26 col7\" >0.5016</td>\n",
              "      <td id=\"T_d9ae7_row26_col8\" class=\"data row26 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row27\" class=\"row_heading level0 row27\" >34</th>\n",
              "      <td id=\"T_d9ae7_row27_col0\" class=\"data row27 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row27_col1\" class=\"data row27 col1\" >lider_de_opinion_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row27_col2\" class=\"data row27 col2\" >+0.0530</td>\n",
              "      <td id=\"T_d9ae7_row27_col3\" class=\"data row27 col3\" >-0.1006</td>\n",
              "      <td id=\"T_d9ae7_row27_col4\" class=\"data row27 col4\" >+0.2264</td>\n",
              "      <td id=\"T_d9ae7_row27_col5\" class=\"data row27 col5\" >0.0833</td>\n",
              "      <td id=\"T_d9ae7_row27_col6\" class=\"data row27 col6\" >0.636</td>\n",
              "      <td id=\"T_d9ae7_row27_col7\" class=\"data row27 col7\" >0.5276</td>\n",
              "      <td id=\"T_d9ae7_row27_col8\" class=\"data row27 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row28\" class=\"row_heading level0 row28\" >7</th>\n",
              "      <td id=\"T_d9ae7_row28_col0\" class=\"data row28 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row28_col1\" class=\"data row28 col1\" >congruencia_influencer_follower</td>\n",
              "      <td id=\"T_d9ae7_row28_col2\" class=\"data row28 col2\" >-0.0365</td>\n",
              "      <td id=\"T_d9ae7_row28_col3\" class=\"data row28 col3\" >-0.1596</td>\n",
              "      <td id=\"T_d9ae7_row28_col4\" class=\"data row28 col4\" >+0.0938</td>\n",
              "      <td id=\"T_d9ae7_row28_col5\" class=\"data row28 col5\" >0.0652</td>\n",
              "      <td id=\"T_d9ae7_row28_col6\" class=\"data row28 col6\" >-0.560</td>\n",
              "      <td id=\"T_d9ae7_row28_col7\" class=\"data row28 col7\" >0.5780</td>\n",
              "      <td id=\"T_d9ae7_row28_col8\" class=\"data row28 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row29\" class=\"row_heading level0 row29\" >38</th>\n",
              "      <td id=\"T_d9ae7_row29_col0\" class=\"data row29 col0\" >predisposicion_a_comprar_un_producto</td>\n",
              "      <td id=\"T_d9ae7_row29_col1\" class=\"data row29 col1\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row29_col2\" class=\"data row29 col2\" >+0.0319</td>\n",
              "      <td id=\"T_d9ae7_row29_col3\" class=\"data row29 col3\" >-0.0926</td>\n",
              "      <td id=\"T_d9ae7_row29_col4\" class=\"data row29 col4\" >+0.1699</td>\n",
              "      <td id=\"T_d9ae7_row29_col5\" class=\"data row29 col5\" >0.0662</td>\n",
              "      <td id=\"T_d9ae7_row29_col6\" class=\"data row29 col6\" >0.482</td>\n",
              "      <td id=\"T_d9ae7_row29_col7\" class=\"data row29 col7\" >0.5944</td>\n",
              "      <td id=\"T_d9ae7_row29_col8\" class=\"data row29 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row30\" class=\"row_heading level0 row30\" >23</th>\n",
              "      <td id=\"T_d9ae7_row30_col0\" class=\"data row30 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row30_col1\" class=\"data row30 col1\" >similitud</td>\n",
              "      <td id=\"T_d9ae7_row30_col2\" class=\"data row30 col2\" >-0.0295</td>\n",
              "      <td id=\"T_d9ae7_row30_col3\" class=\"data row30 col3\" >-0.1425</td>\n",
              "      <td id=\"T_d9ae7_row30_col4\" class=\"data row30 col4\" >+0.0884</td>\n",
              "      <td id=\"T_d9ae7_row30_col5\" class=\"data row30 col5\" >0.0590</td>\n",
              "      <td id=\"T_d9ae7_row30_col6\" class=\"data row30 col6\" >-0.500</td>\n",
              "      <td id=\"T_d9ae7_row30_col7\" class=\"data row30 col7\" >0.6160</td>\n",
              "      <td id=\"T_d9ae7_row30_col8\" class=\"data row30 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row31\" class=\"row_heading level0 row31\" >30</th>\n",
              "      <td id=\"T_d9ae7_row31_col0\" class=\"data row31 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row31_col1\" class=\"data row31 col1\" >expertis_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row31_col2\" class=\"data row31 col2\" >-0.0526</td>\n",
              "      <td id=\"T_d9ae7_row31_col3\" class=\"data row31 col3\" >-0.1949</td>\n",
              "      <td id=\"T_d9ae7_row31_col4\" class=\"data row31 col4\" >+0.1280</td>\n",
              "      <td id=\"T_d9ae7_row31_col5\" class=\"data row31 col5\" >0.0819</td>\n",
              "      <td id=\"T_d9ae7_row31_col6\" class=\"data row31 col6\" >-0.642</td>\n",
              "      <td id=\"T_d9ae7_row31_col7\" class=\"data row31 col7\" >0.6488</td>\n",
              "      <td id=\"T_d9ae7_row31_col8\" class=\"data row31 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
              "      <td id=\"T_d9ae7_row32_col0\" class=\"data row32 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row32_col1\" class=\"data row32 col1\" >atractividad_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row32_col2\" class=\"data row32 col2\" >-0.0225</td>\n",
              "      <td id=\"T_d9ae7_row32_col3\" class=\"data row32 col3\" >-0.1693</td>\n",
              "      <td id=\"T_d9ae7_row32_col4\" class=\"data row32 col4\" >+0.1064</td>\n",
              "      <td id=\"T_d9ae7_row32_col5\" class=\"data row32 col5\" >0.0690</td>\n",
              "      <td id=\"T_d9ae7_row32_col6\" class=\"data row32 col6\" >-0.327</td>\n",
              "      <td id=\"T_d9ae7_row32_col7\" class=\"data row32 col7\" >0.6692</td>\n",
              "      <td id=\"T_d9ae7_row32_col8\" class=\"data row32 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row33\" class=\"row_heading level0 row33\" >41</th>\n",
              "      <td id=\"T_d9ae7_row33_col0\" class=\"data row33 col0\" >predisposicion_a_comprar_un_producto</td>\n",
              "      <td id=\"T_d9ae7_row33_col1\" class=\"data row33 col1\" >actitud_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row33_col2\" class=\"data row33 col2\" >-0.0269</td>\n",
              "      <td id=\"T_d9ae7_row33_col3\" class=\"data row33 col3\" >-0.1556</td>\n",
              "      <td id=\"T_d9ae7_row33_col4\" class=\"data row33 col4\" >+0.0927</td>\n",
              "      <td id=\"T_d9ae7_row33_col5\" class=\"data row33 col5\" >0.0633</td>\n",
              "      <td id=\"T_d9ae7_row33_col6\" class=\"data row33 col6\" >-0.425</td>\n",
              "      <td id=\"T_d9ae7_row33_col7\" class=\"data row33 col7\" >0.6740</td>\n",
              "      <td id=\"T_d9ae7_row33_col8\" class=\"data row33 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row34\" class=\"row_heading level0 row34\" >42</th>\n",
              "      <td id=\"T_d9ae7_row34_col0\" class=\"data row34 col0\" >predisposicion_a_comprar_un_producto</td>\n",
              "      <td id=\"T_d9ae7_row34_col1\" class=\"data row34 col1\" >engagement_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row34_col2\" class=\"data row34 col2\" >-0.0107</td>\n",
              "      <td id=\"T_d9ae7_row34_col3\" class=\"data row34 col3\" >-0.1477</td>\n",
              "      <td id=\"T_d9ae7_row34_col4\" class=\"data row34 col4\" >+0.1200</td>\n",
              "      <td id=\"T_d9ae7_row34_col5\" class=\"data row34 col5\" >0.0686</td>\n",
              "      <td id=\"T_d9ae7_row34_col6\" class=\"data row34 col6\" >-0.156</td>\n",
              "      <td id=\"T_d9ae7_row34_col7\" class=\"data row34 col7\" >0.8404</td>\n",
              "      <td id=\"T_d9ae7_row34_col8\" class=\"data row34 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row35\" class=\"row_heading level0 row35\" >22</th>\n",
              "      <td id=\"T_d9ae7_row35_col0\" class=\"data row35 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row35_col1\" class=\"data row35 col1\" >atractividad</td>\n",
              "      <td id=\"T_d9ae7_row35_col2\" class=\"data row35 col2\" >-0.0195</td>\n",
              "      <td id=\"T_d9ae7_row35_col3\" class=\"data row35 col3\" >-0.1322</td>\n",
              "      <td id=\"T_d9ae7_row35_col4\" class=\"data row35 col4\" >+0.1083</td>\n",
              "      <td id=\"T_d9ae7_row35_col5\" class=\"data row35 col5\" >0.0607</td>\n",
              "      <td id=\"T_d9ae7_row35_col6\" class=\"data row35 col6\" >-0.321</td>\n",
              "      <td id=\"T_d9ae7_row35_col7\" class=\"data row35 col7\" >0.8412</td>\n",
              "      <td id=\"T_d9ae7_row35_col8\" class=\"data row35 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row36\" class=\"row_heading level0 row36\" >39</th>\n",
              "      <td id=\"T_d9ae7_row36_col0\" class=\"data row36 col0\" >predisposicion_a_comprar_un_producto</td>\n",
              "      <td id=\"T_d9ae7_row36_col1\" class=\"data row36 col1\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row36_col2\" class=\"data row36 col2\" >-0.0105</td>\n",
              "      <td id=\"T_d9ae7_row36_col3\" class=\"data row36 col3\" >-0.1275</td>\n",
              "      <td id=\"T_d9ae7_row36_col4\" class=\"data row36 col4\" >+0.1078</td>\n",
              "      <td id=\"T_d9ae7_row36_col5\" class=\"data row36 col5\" >0.0610</td>\n",
              "      <td id=\"T_d9ae7_row36_col6\" class=\"data row36 col6\" >-0.173</td>\n",
              "      <td id=\"T_d9ae7_row36_col7\" class=\"data row36 col7\" >0.8420</td>\n",
              "      <td id=\"T_d9ae7_row36_col8\" class=\"data row36 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row37\" class=\"row_heading level0 row37\" >5</th>\n",
              "      <td id=\"T_d9ae7_row37_col0\" class=\"data row37 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row37_col1\" class=\"data row37 col1\" >lider_de_opinion</td>\n",
              "      <td id=\"T_d9ae7_row37_col2\" class=\"data row37 col2\" >+0.0212</td>\n",
              "      <td id=\"T_d9ae7_row37_col3\" class=\"data row37 col3\" >-0.1359</td>\n",
              "      <td id=\"T_d9ae7_row37_col4\" class=\"data row37 col4\" >+0.1630</td>\n",
              "      <td id=\"T_d9ae7_row37_col5\" class=\"data row37 col5\" >0.0760</td>\n",
              "      <td id=\"T_d9ae7_row37_col6\" class=\"data row37 col6\" >0.278</td>\n",
              "      <td id=\"T_d9ae7_row37_col7\" class=\"data row37 col7\" >0.8644</td>\n",
              "      <td id=\"T_d9ae7_row37_col8\" class=\"data row37 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row38\" class=\"row_heading level0 row38\" >15</th>\n",
              "      <td id=\"T_d9ae7_row38_col0\" class=\"data row38 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row38_col1\" class=\"data row38 col1\" >lider_de_opinion_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row38_col2\" class=\"data row38 col2\" >+0.0162</td>\n",
              "      <td id=\"T_d9ae7_row38_col3\" class=\"data row38 col3\" >-0.1509</td>\n",
              "      <td id=\"T_d9ae7_row38_col4\" class=\"data row38 col4\" >+0.1606</td>\n",
              "      <td id=\"T_d9ae7_row38_col5\" class=\"data row38 col5\" >0.0804</td>\n",
              "      <td id=\"T_d9ae7_row38_col6\" class=\"data row38 col6\" >0.202</td>\n",
              "      <td id=\"T_d9ae7_row38_col7\" class=\"data row38 col7\" >0.8972</td>\n",
              "      <td id=\"T_d9ae7_row38_col8\" class=\"data row38 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row39\" class=\"row_heading level0 row39\" >36</th>\n",
              "      <td id=\"T_d9ae7_row39_col0\" class=\"data row39 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row39_col1\" class=\"data row39 col1\" >congruencia_influencer_follower_x_conciencia_de_la_persuasion</td>\n",
              "      <td id=\"T_d9ae7_row39_col2\" class=\"data row39 col2\" >+0.0079</td>\n",
              "      <td id=\"T_d9ae7_row39_col3\" class=\"data row39 col3\" >-0.1158</td>\n",
              "      <td id=\"T_d9ae7_row39_col4\" class=\"data row39 col4\" >+0.1259</td>\n",
              "      <td id=\"T_d9ae7_row39_col5\" class=\"data row39 col5\" >0.0606</td>\n",
              "      <td id=\"T_d9ae7_row39_col6\" class=\"data row39 col6\" >0.131</td>\n",
              "      <td id=\"T_d9ae7_row39_col7\" class=\"data row39 col7\" >0.8980</td>\n",
              "      <td id=\"T_d9ae7_row39_col8\" class=\"data row39 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row40\" class=\"row_heading level0 row40\" >20</th>\n",
              "      <td id=\"T_d9ae7_row40_col0\" class=\"data row40 col0\" >engagement</td>\n",
              "      <td id=\"T_d9ae7_row40_col1\" class=\"data row40 col1\" >expertis</td>\n",
              "      <td id=\"T_d9ae7_row40_col2\" class=\"data row40 col2\" >+0.0034</td>\n",
              "      <td id=\"T_d9ae7_row40_col3\" class=\"data row40 col3\" >-0.1328</td>\n",
              "      <td id=\"T_d9ae7_row40_col4\" class=\"data row40 col4\" >+0.1340</td>\n",
              "      <td id=\"T_d9ae7_row40_col5\" class=\"data row40 col5\" >0.0676</td>\n",
              "      <td id=\"T_d9ae7_row40_col6\" class=\"data row40 col6\" >0.051</td>\n",
              "      <td id=\"T_d9ae7_row40_col7\" class=\"data row40 col7\" >0.9660</td>\n",
              "      <td id=\"T_d9ae7_row40_col8\" class=\"data row40 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row41\" class=\"row_heading level0 row41\" >0</th>\n",
              "      <td id=\"T_d9ae7_row41_col0\" class=\"data row41 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row41_col1\" class=\"data row41 col1\" >integridad</td>\n",
              "      <td id=\"T_d9ae7_row41_col2\" class=\"data row41 col2\" >-0.0055</td>\n",
              "      <td id=\"T_d9ae7_row41_col3\" class=\"data row41 col3\" >-0.1425</td>\n",
              "      <td id=\"T_d9ae7_row41_col4\" class=\"data row41 col4\" >+0.1408</td>\n",
              "      <td id=\"T_d9ae7_row41_col5\" class=\"data row41 col5\" >0.0724</td>\n",
              "      <td id=\"T_d9ae7_row41_col6\" class=\"data row41 col6\" >-0.075</td>\n",
              "      <td id=\"T_d9ae7_row41_col7\" class=\"data row41 col7\" >0.9836</td>\n",
              "      <td id=\"T_d9ae7_row41_col8\" class=\"data row41 col8\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9ae7_level0_row42\" class=\"row_heading level0 row42\" >3</th>\n",
              "      <td id=\"T_d9ae7_row42_col0\" class=\"data row42 col0\" >actitud</td>\n",
              "      <td id=\"T_d9ae7_row42_col1\" class=\"data row42 col1\" >atractividad</td>\n",
              "      <td id=\"T_d9ae7_row42_col2\" class=\"data row42 col2\" >-0.0028</td>\n",
              "      <td id=\"T_d9ae7_row42_col3\" class=\"data row42 col3\" >-0.1257</td>\n",
              "      <td id=\"T_d9ae7_row42_col4\" class=\"data row42 col4\" >+0.1220</td>\n",
              "      <td id=\"T_d9ae7_row42_col5\" class=\"data row42 col5\" >0.0640</td>\n",
              "      <td id=\"T_d9ae7_row42_col6\" class=\"data row42 col6\" >-0.043</td>\n",
              "      <td id=\"T_d9ae7_row42_col7\" class=\"data row42 col7\" >1.0000</td>\n",
              "      <td id=\"T_d9ae7_row42_col8\" class=\"data row42 col8\" >False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Listo. Ya tienes CI + p para todos en una tabla bien renderizada (no consola).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SEM (SOLO 1er ORDEN) — VISUALIZACIÓN LIMPIA en Colab (sin Graphviz)\n",
        "# - Nodos: SOLO constructos de 1er orden (incluye moderador)\n",
        "# - Aristas: muestra SOLO efectos relevantes (sig directos y/o sig moderaciones)\n",
        "# - Moderación: NO crea nodos de interacción (para cumplir “solo 1er orden”).\n",
        "#   En su lugar, si X×Conciencia -> Y es significativo, lo anota en la arista X->Y.\n",
        "#\n",
        "# REQUIERE que ya existan en tu notebook:\n",
        "#   - betas  (dict[endog][exog] = beta)  -> de tu modelo 1er orden\n",
        "#   - r2s    (dict[endog] = R2)\n",
        "#   - paths  (dict[endog] = lista de exogs)\n",
        "#   - tabla_boot (DataFrame)  (opcional pero recomendado para p/CI/significancia)\n",
        "#\n",
        "# OUTPUT:\n",
        "#   - sem_first_order_results.png  (diagrama)\n",
        "#   - (opcional) tabla_boot limpia y centrada con display()\n",
        "# ============================================================\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle, FancyArrowPatch\n",
        "from IPython.display import display\n",
        "\n",
        "# ----------------------------\n",
        "# A) CONFIGURACIÓN\n",
        "# ----------------------------\n",
        "MOD = \"conciencia_de_la_persuasion\"   # debe coincidir con tu modelo\n",
        "\n",
        "# Qué mostrar:\n",
        "SHOW_ONLY_RELEVANT_EDGES = True  # True = solo aristas que \"importan\" según resultados\n",
        "LABEL_ONLY_RELEVANT      = True  # etiquetas solo donde vale la pena (evita saturación)\n",
        "INCLUDE_CORE_PATHS       = True  # siempre incluye actitud->intención y engagement->intención\n",
        "INCLUDE_MOD_DIRECT       = True  # siempre incluye MOD->(actitud, engagement, intención)\n",
        "ALSO_FAINT_NONSIG        = False # si quieres ver todo, pon True (pero puede ensuciar)\n",
        "\n",
        "# Tamaño del lienzo\n",
        "FIG_W, FIG_H = 14, 10\n",
        "\n",
        "# ----------------------------\n",
        "# B) UTILIDADES bootstrap (p, CI, sig)\n",
        "# ----------------------------\n",
        "def _safe_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception:\n",
        "        return float(\"nan\")\n",
        "\n",
        "def _norm_boot_table(tb: pd.DataFrame) -> pd.DataFrame:\n",
        "    tb = tb.copy()\n",
        "    # normaliza nombres comunes\n",
        "    ren = {}\n",
        "    for c in tb.columns:\n",
        "        c2 = c.strip()\n",
        "        if c2.lower() in [\"beta\", \"beta_orig\", \"beta_original\"]:\n",
        "            ren[c] = \"Beta\"\n",
        "        elif c2.replace(\" \", \"\").lower() in [\"ci_2.5%\", \"ci2.5%\", \"ci_2.5\", \"ci2.5\"]:\n",
        "            ren[c] = \"CI_2.5%\"\n",
        "        elif c2.replace(\" \", \"\").lower() in [\"ci_97.5%\", \"ci97.5%\", \"ci_97.5\", \"ci97.5\"]:\n",
        "            ren[c] = \"CI_97.5%\"\n",
        "        elif c2.lower() in [\"p\", \"p_emp(2-colas)\", \"p_emp\", \"p_empirico\", \"p_empirico(2-colas)\"]:\n",
        "            ren[c] = \"p\"\n",
        "        elif c2.lower() in [\"sig_0.05\", \"significativo_0.05\", \"sig\", \"signif_0.05\"]:\n",
        "            ren[c] = \"Sig_0.05\"\n",
        "        elif c2.lower() == \"endog\":\n",
        "            ren[c] = \"Endog\"\n",
        "        elif c2.lower() == \"exog\":\n",
        "            ren[c] = \"Exog\"\n",
        "    tb = tb.rename(columns=ren)\n",
        "\n",
        "    # limpia strings\n",
        "    for col in [\"Endog\", \"Exog\"]:\n",
        "        if col in tb.columns:\n",
        "            tb[col] = tb[col].astype(str).str.strip()\n",
        "\n",
        "    # asegura columnas mínimas\n",
        "    need = [\"Endog\",\"Exog\",\"Beta\",\"CI_2.5%\",\"CI_97.5%\",\"p\",\"Sig_0.05\"]\n",
        "    for col in need:\n",
        "        if col not in tb.columns:\n",
        "            # crea si no existe\n",
        "            tb[col] = np.nan\n",
        "\n",
        "    # tipado\n",
        "    for col in [\"Beta\",\"CI_2.5%\",\"CI_97.5%\",\"p\"]:\n",
        "        tb[col] = tb[col].apply(_safe_float)\n",
        "    tb[\"Sig_0.05\"] = tb[\"Sig_0.05\"].astype(str).str.lower().isin([\"true\",\"1\",\"yes\",\"y\",\"t\"])\n",
        "\n",
        "    return tb[need]\n",
        "\n",
        "sig_map, p_map, ci_map = {}, {}, {}\n",
        "tb_norm = None\n",
        "if \"tabla_boot\" in globals() and isinstance(globals()[\"tabla_boot\"], pd.DataFrame):\n",
        "    try:\n",
        "        tb_norm = _norm_boot_table(globals()[\"tabla_boot\"])\n",
        "        for _, r in tb_norm.iterrows():\n",
        "            k = (r[\"Endog\"], r[\"Exog\"])\n",
        "            sig_map[k] = bool(r[\"Sig_0.05\"])\n",
        "            p_map[k]  = float(r[\"p\"])\n",
        "            ci_map[k] = (float(r[\"CI_2.5%\"]), float(r[\"CI_97.5%\"]))\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ No pude normalizar tabla_boot:\", e)\n",
        "\n",
        "def p_stars(p):\n",
        "    if p is None or (isinstance(p, float) and np.isnan(p)):\n",
        "        return \"\"\n",
        "    if p < 0.001: return \"***\"\n",
        "    if p < 0.01:  return \"**\"\n",
        "    if p < 0.05:  return \"*\"\n",
        "    return \"\"\n",
        "\n",
        "def fmt_beta(b):\n",
        "    if b is None or (isinstance(b, float) and (np.isnan(b) or np.isinf(b))):\n",
        "        return \"NA\"\n",
        "    return f\"{b:+.3f}\"\n",
        "\n",
        "def fmt_p(p):\n",
        "    if p is None or (isinstance(p, float) and np.isnan(p)):\n",
        "        return \"p=NA\"\n",
        "    return f\"p={p:.3f}\"\n",
        "\n",
        "def fmt_ci(ci):\n",
        "    if not ci or any(np.isnan(x) for x in ci):\n",
        "        return \"[CI NA]\"\n",
        "    return f\"[{ci[0]:+.3f}, {ci[1]:+.3f}]\"\n",
        "\n",
        "# ----------------------------\n",
        "# C) DEFINIR NODOS (SOLO 1er ORDEN) + etiquetas bonitas\n",
        "# ----------------------------\n",
        "pretty = {\n",
        "    \"integridad\": \"Integridad\",\n",
        "    \"expertis\": \"Expertise\",\n",
        "    \"autenticidad\": \"Autenticidad\",\n",
        "    \"atractividad\": \"Atractividad\",\n",
        "    \"similitud\": \"Similitud\",\n",
        "    \"lider_de_opinion\": \"Liderazgo\\nde opinión\",\n",
        "    \"informatividad_del_contenido\": \"Informatividad\\ndel contenido\",\n",
        "    \"congruencia_influencer_follower\": \"Congruencia\\nInf–Seguidor\",\n",
        "    \"congruencia_influencer_producto\": \"Congruencia\\nInf–Producto\",\n",
        "    MOD: \"Conciencia\\nde la persuasión\",\n",
        "    \"actitud\": \"Actitud\",\n",
        "    \"engagement\": \"Engagement\",\n",
        "    \"predisposicion_a_comprar_un_producto\": \"Intención\\nde compra\",\n",
        "}\n",
        "\n",
        "# Columnas (layout manual para que NO se superponga)\n",
        "predictors = [\n",
        "    \"integridad\",\"expertis\",\"autenticidad\",\"atractividad\",\"similitud\",\n",
        "    \"lider_de_opinion\",\"informatividad_del_contenido\",\n",
        "    \"congruencia_influencer_follower\",\"congruencia_influencer_producto\"\n",
        "]\n",
        "mediators = [\"actitud\",\"engagement\"]\n",
        "outcome   = \"predisposicion_a_comprar_un_producto\"\n",
        "\n",
        "# ----------------------------\n",
        "# D) DETECTAR MODERACIONES SIGNIFICATIVAS SIN CREAR NODOS DE INTERACCIÓN\n",
        "#    (si existe tabla_boot, usamos Sig_0.05; si no, no anotamos moderación)\n",
        "# ----------------------------\n",
        "def inter_name(x, mod=MOD):\n",
        "    return f\"{x}_x_{mod}\"\n",
        "\n",
        "def get_beta(endog, exog):\n",
        "    try:\n",
        "        return float(betas[endog][exog])\n",
        "    except Exception:\n",
        "        return float(\"nan\")\n",
        "\n",
        "def get_sig(endog, exog):\n",
        "    if sig_map:\n",
        "        return sig_map.get((endog, exog), None)\n",
        "    return None\n",
        "\n",
        "def get_p(endog, exog):\n",
        "    if p_map:\n",
        "        return p_map.get((endog, exog), float(\"nan\"))\n",
        "    return float(\"nan\")\n",
        "\n",
        "def get_ci(endog, exog):\n",
        "    if ci_map:\n",
        "        return ci_map.get((endog, exog), (float(\"nan\"), float(\"nan\")))\n",
        "    return (float(\"nan\"), float(\"nan\"))\n",
        "\n",
        "# para cada arista directa X->Y, si existe X_x_MOD -> Y significativo, lo anotamos\n",
        "moderation_effect = {}  # (Y,X) -> dict(beta,p,ci,sig)\n",
        "for endog, exogs in paths.items():\n",
        "    for ex in exogs:\n",
        "        if ex == MOD:\n",
        "            continue\n",
        "        # ignorar términos de interacción como nodos\n",
        "        if isinstance(ex, str) and ex.endswith(f\"_x_{MOD}\"):\n",
        "            continue\n",
        "        inter = inter_name(ex)\n",
        "        if inter in exogs:\n",
        "            b_int = get_beta(endog, inter)\n",
        "            p_int = get_p(endog, inter)\n",
        "            s_int = get_sig(endog, inter)\n",
        "            ci_int = get_ci(endog, inter)\n",
        "            moderation_effect[(endog, ex)] = {\n",
        "                \"beta\": b_int, \"p\": p_int, \"sig\": s_int, \"ci\": ci_int\n",
        "            }\n",
        "\n",
        "# ----------------------------\n",
        "# E) CONSTRUIR LISTA DE ARISTAS A DIBUJAR\n",
        "# ----------------------------\n",
        "edges = []  # (src, dst, kind=\"direct\")\n",
        "for endog, exogs in paths.items():\n",
        "    for ex in exogs:\n",
        "        if isinstance(ex, str) and ex.endswith(f\"_x_{MOD}\"):\n",
        "            continue  # NO dibujamos nodos interacción\n",
        "        edges.append((ex, endog))\n",
        "\n",
        "def edge_is_relevant(src, dst):\n",
        "    # direct sig?\n",
        "    s_dir = get_sig(dst, src)\n",
        "    dir_sig = (s_dir is True)\n",
        "\n",
        "    # moderation sig?\n",
        "    mod = moderation_effect.get((dst, src), None)\n",
        "    mod_sig = (mod is not None and mod.get(\"sig\") is True)\n",
        "\n",
        "    # core paths siempre\n",
        "    core = False\n",
        "    if INCLUDE_CORE_PATHS and (src in [\"actitud\",\"engagement\"]) and (dst == outcome):\n",
        "        core = True\n",
        "    if INCLUDE_MOD_DIRECT and (src == MOD) and (dst in [\"actitud\",\"engagement\", outcome]):\n",
        "        core = True\n",
        "\n",
        "    return (dir_sig or mod_sig or core)\n",
        "\n",
        "edges_to_draw = []\n",
        "for (src, dst) in edges:\n",
        "    if SHOW_ONLY_RELEVANT_EDGES:\n",
        "        if edge_is_relevant(src, dst):\n",
        "            edges_to_draw.append((src, dst))\n",
        "        elif ALSO_FAINT_NONSIG:\n",
        "            edges_to_draw.append((src, dst))\n",
        "    else:\n",
        "        edges_to_draw.append((src, dst))\n",
        "\n",
        "# ----------------------------\n",
        "# F) POSICIONES (layout fijo)\n",
        "# ----------------------------\n",
        "pos = {}\n",
        "\n",
        "# predictors en columna izquierda\n",
        "x_pred = 0.08\n",
        "ys = np.linspace(0.90, 0.18, len(predictors))\n",
        "for n, y in zip(predictors, ys):\n",
        "    pos[n] = (x_pred, float(y))\n",
        "\n",
        "# mediadores centro\n",
        "pos[\"actitud\"]    = (0.52, 0.68)\n",
        "pos[\"engagement\"] = (0.52, 0.42)\n",
        "\n",
        "# outcome derecha\n",
        "pos[outcome] = (0.88, 0.55)\n",
        "\n",
        "# moderador abajo izquierda (separado)\n",
        "pos[MOD] = (0.20, 0.08)\n",
        "\n",
        "# ----------------------------\n",
        "# G) DIBUJO\n",
        "# ----------------------------\n",
        "def edge_style(beta, sig=None):\n",
        "    # color por signo\n",
        "    col = \"#1B9E77\" if (not np.isnan(beta) and beta >= 0) else \"#D95F02\"\n",
        "    # si hay bootstrap: no sig -> gris punteado\n",
        "    if sig is False:\n",
        "        return {\"color\":\"#9E9E9E\", \"lw\":1.2, \"ls\":\"dashed\", \"alpha\":0.9}\n",
        "    # sin info de sig: normal\n",
        "    if sig is None:\n",
        "        return {\"color\":col, \"lw\":1.6, \"ls\":\"solid\", \"alpha\":0.95}\n",
        "    # sig True:\n",
        "    # grosor por magnitud\n",
        "    lw = 1.6 + min(4.0, abs(beta) * 6.0)\n",
        "    return {\"color\":col, \"lw\":lw, \"ls\":\"solid\", \"alpha\":0.95}\n",
        "\n",
        "def node_style(n):\n",
        "    # moderador verde\n",
        "    if n == MOD:\n",
        "        return {\"fc\":\"#93C47D\", \"ec\":\"#38761D\", \"r\":0.065}\n",
        "    # outcome más grande\n",
        "    if n == outcome:\n",
        "        return {\"fc\":\"#6FA8DC\", \"ec\":\"#2F5597\", \"r\":0.085}\n",
        "    # mediadores\n",
        "    if n in mediators:\n",
        "        return {\"fc\":\"#6FA8DC\", \"ec\":\"#2F5597\", \"r\":0.070}\n",
        "    # predictores\n",
        "    return {\"fc\":\"#6FA8DC\", \"ec\":\"#2F5597\", \"r\":0.065}\n",
        "\n",
        "def draw_node(ax, n):\n",
        "    x,y = pos[n]\n",
        "    st = node_style(n)\n",
        "    circ = Circle((x,y), st[\"r\"], facecolor=st[\"fc\"], edgecolor=st[\"ec\"], lw=2.2, zorder=3)\n",
        "    ax.add_patch(circ)\n",
        "\n",
        "    # label + R² si aplica\n",
        "    label = pretty.get(n, n)\n",
        "    if n in r2s:\n",
        "        r2 = r2s.get(n, float(\"nan\"))\n",
        "        if not (np.isnan(r2) or np.isinf(r2)):\n",
        "            label = f\"{label}\\nR²={r2:.3f}\"\n",
        "        else:\n",
        "            label = f\"{label}\\nR²=NA\"\n",
        "    ax.text(x, y, label, ha=\"center\", va=\"center\", color=\"white\", fontsize=11, fontweight=600, zorder=4)\n",
        "\n",
        "def draw_edge(ax, src, dst, rad):\n",
        "    x1,y1 = pos[src]\n",
        "    x2,y2 = pos[dst]\n",
        "\n",
        "    b = get_beta(dst, src)\n",
        "    s = get_sig(dst, src)\n",
        "\n",
        "    st = edge_style(b, s if s is not None else None)\n",
        "\n",
        "    # flecha curva\n",
        "    arrow = FancyArrowPatch(\n",
        "        (x1,y1), (x2,y2),\n",
        "        arrowstyle='-|>',\n",
        "        mutation_scale=14,\n",
        "        lw=st[\"lw\"],\n",
        "        linestyle=st[\"ls\"],\n",
        "        color=st[\"color\"],\n",
        "        alpha=st[\"alpha\"],\n",
        "        connectionstyle=f\"arc3,rad={rad}\",\n",
        "        zorder=2\n",
        "    )\n",
        "    ax.add_patch(arrow)\n",
        "\n",
        "    # etiqueta (solo si relevante)\n",
        "    label = \"\"\n",
        "    p = get_p(dst, src)\n",
        "    if (not LABEL_ONLY_RELEVANT) or edge_is_relevant(src, dst):\n",
        "        # direct label si: es core o sig o si quieres\n",
        "        if (get_sig(dst, src) is True) or ((src in [\"actitud\",\"engagement\",MOD]) or (dst in [\"actitud\",\"engagement\",outcome])):\n",
        "            stars = p_stars(p)\n",
        "            label = f\"{fmt_beta(b)}{stars}\"\n",
        "            if not np.isnan(p):\n",
        "                label += f\"\\n({fmt_p(p)})\"\n",
        "            # añade CI direct si es sig\n",
        "            if get_sig(dst, src) is True and ci_map:\n",
        "                label += f\"\\n{fmt_ci(get_ci(dst, src))}\"\n",
        "\n",
        "    # anotación de moderación (si X×MOD -> dst es sig)\n",
        "    mod = moderation_effect.get((dst, src), None)\n",
        "    if mod and (mod.get(\"sig\") is True):\n",
        "        b_int = mod[\"beta\"]\n",
        "        p_int = mod[\"p\"]\n",
        "        stars_int = p_stars(p_int)\n",
        "        # lo marcamos como \"mod\"\n",
        "        label += (\"\" if label==\"\" else \"\\n\") + f\"mod {fmt_beta(b_int)}{stars_int}\"\n",
        "        if not np.isnan(p_int):\n",
        "            label += f\"\\n({fmt_p(p_int)})\"\n",
        "        if ci_map:\n",
        "            label += f\"\\n{fmt_ci(mod['ci'])}\"\n",
        "\n",
        "    if label.strip():\n",
        "        # posición label cerca del medio, con offset según rad\n",
        "        mx, my = (x1+x2)/2, (y1+y2)/2\n",
        "        ax.text(mx, my + 0.035*np.sign(rad), label,\n",
        "                ha=\"center\", va=\"center\", fontsize=9, color=\"#1a1a1a\",\n",
        "                bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"none\", alpha=0.75),\n",
        "                zorder=5)\n",
        "\n",
        "# -------------- render --------------\n",
        "plt.figure(figsize=(FIG_W, FIG_H))\n",
        "ax = plt.gca()\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.axis(\"off\")\n",
        "\n",
        "# nodos\n",
        "for n in predictors + mediators + [outcome, MOD]:\n",
        "    draw_node(ax, n)\n",
        "\n",
        "# edges (curvatura automática por diferencia vertical)\n",
        "def rad_for(src, dst):\n",
        "    x1,y1 = pos[src]\n",
        "    x2,y2 = pos[dst]\n",
        "    dy = y2 - y1\n",
        "    # rad pequeño, alterna signo para separar\n",
        "    base = 0.18\n",
        "    r = np.clip(dy, -0.7, 0.7) * base\n",
        "    # si casi recto, agrega un poquito para evitar que se encimen\n",
        "    if abs(r) < 0.02:\n",
        "        r = 0.05 * (1 if (y1 < y2) else -1)\n",
        "    return float(r)\n",
        "\n",
        "for (src, dst) in edges_to_draw:\n",
        "    if src not in pos or dst not in pos:\n",
        "        continue\n",
        "    # si queremos ver no-sig muy tenue y sin etiquetas:\n",
        "    if ALSO_FAINT_NONSIG and (not edge_is_relevant(src, dst)):\n",
        "        # dibuja tenue\n",
        "        b = get_beta(dst, src)\n",
        "        arrow = FancyArrowPatch(\n",
        "            pos[src], pos[dst],\n",
        "            arrowstyle='-|>', mutation_scale=10,\n",
        "            lw=1.0, linestyle=\"dashed\", color=\"#BDBDBD\", alpha=0.55,\n",
        "            connectionstyle=f\"arc3,rad={rad_for(src,dst)}\",\n",
        "            zorder=1\n",
        "        )\n",
        "        ax.add_patch(arrow)\n",
        "        continue\n",
        "\n",
        "    draw_edge(ax, src, dst, rad_for(src, dst))\n",
        "\n",
        "# leyenda\n",
        "legend = (\n",
        "    \"Leyenda:\\n\"\n",
        "    \"Verde=β+ | Naranja=β-\\n\"\n",
        "    \"Sólido=significativo (si hay bootstrap)\\n\"\n",
        "    \"Gris punteado=no significativo\\n\"\n",
        "    \"En etiqueta: 'mod' = moderación (X×Conciencia→Y) si es significativa\\n\"\n",
        "    \"(* p<.05, ** p<.01, *** p<.001)\"\n",
        ")\n",
        "ax.text(0.02, 0.98, legend, ha=\"left\", va=\"top\", fontsize=11,\n",
        "        bbox=dict(boxstyle=\"round,pad=0.35\", fc=\"white\", ec=\"#e0e0e0\", alpha=0.95))\n",
        "\n",
        "plt.tight_layout()\n",
        "out_png = \"sem_first_order_results.png\"\n",
        "plt.savefig(out_png, dpi=220, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"✅ Diagrama guardado como:\", out_png)\n",
        "\n",
        "# ----------------------------\n",
        "# H) TABLA APARTE (p y CI para todos) — BIEN ALINEADA EN COLAB\n",
        "# ----------------------------\n",
        "if tb_norm is not None and isinstance(tb_norm, pd.DataFrame):\n",
        "    tb_show = tb_norm.copy()\n",
        "    # ordena por p\n",
        "    tb_show = tb_show.sort_values(\"p\", ascending=True).reset_index(drop=True)\n",
        "    # redondea\n",
        "    for c in [\"Beta\",\"CI_2.5%\",\"CI_97.5%\",\"p\"]:\n",
        "        tb_show[c] = tb_show[c].astype(float).round(4)\n",
        "    print(\"\\n✅ Tabla bootstrap (centrada/limpia):\")\n",
        "    display(tb_show)\n",
        "else:\n",
        "    print(\"\\nℹ️ No detecté 'tabla_boot' (o no pude normalizarla). Solo dibujé con betas/r2s.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0wPHxcmgnkU",
        "outputId": "ddcf009d-244d-4f40-bbd8-95a2ba562f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Diagrama guardado como: sem_first_order_results.png\n",
            "\n",
            "✅ Tabla bootstrap (centrada/limpia):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                   Endog                                               Exog   Beta  CI_2.5%  CI_97.5%     p  Sig_0.05\n",
              "0   predisposicion_a_comprar_un_producto                        conciencia_de_la_persuasion  0.217    0.101     0.334 0.001      True\n",
              "1                             engagement                                   lider_de_opinion  0.256    0.109     0.386 0.001      True\n",
              "2                             engagement                    congruencia_influencer_producto  0.180    0.035     0.290 0.010      True\n",
              "3                             engagement           integridad_x_conciencia_de_la_persuasion  0.161    0.034     0.289 0.012      True\n",
              "4                                actitud         atractividad_x_conciencia_de_la_persuasion  0.198    0.048     0.339 0.015      True\n",
              "5                                actitud            similitud_x_conciencia_de_la_persuasion -0.205   -0.367    -0.032 0.021      True\n",
              "6                             engagement            similitud_x_conciencia_de_la_persuasion  0.121    0.011     0.233 0.033      True\n",
              "7                             engagement                        conciencia_de_la_persuasion  0.141   -0.017     0.272 0.079     False\n",
              "8                                actitud         autenticidad_x_conciencia_de_la_persuasion -0.147   -0.293     0.017 0.080     False\n",
              "9                             engagement                       informatividad_del_contenido  0.092   -0.023     0.215 0.111     False\n",
              "10                            engagement                                       autenticidad -0.098   -0.215     0.029 0.130     False\n",
              "11                               actitud  congruencia_influencer_follower_x_conciencia_d...  0.113   -0.035     0.251 0.132     False\n",
              "12                               actitud                                          similitud  0.125   -0.034     0.281 0.139     False\n",
              "13                               actitud                                           expertis  0.096   -0.044     0.231 0.169     False\n",
              "14                               actitud                        conciencia_de_la_persuasion  0.101   -0.044     0.257 0.173     False\n",
              "15                               actitud                    congruencia_influencer_producto  0.079   -0.037     0.203 0.176     False\n",
              "16                               actitud                                       autenticidad  0.082   -0.043     0.196 0.200     False\n",
              "17                               actitud           integridad_x_conciencia_de_la_persuasion  0.084   -0.050     0.229 0.221     False\n",
              "18                               actitud             expertis_x_conciencia_de_la_persuasion -0.103   -0.271     0.054 0.224     False\n",
              "19                            engagement                    congruencia_influencer_follower -0.076   -0.190     0.051 0.230     False\n",
              "20                               actitud                       informatividad_del_contenido  0.061   -0.056     0.186 0.282     False\n",
              "21                               actitud  congruencia_influencer_producto_x_conciencia_d...  0.060   -0.080     0.196 0.420     False\n",
              "22                            engagement         autenticidad_x_conciencia_de_la_persuasion  0.050   -0.087     0.180 0.436     False\n",
              "23                            engagement                                         integridad  0.056   -0.075     0.177 0.443     False\n",
              "24                               actitud  informatividad_del_contenido_x_conciencia_de_l...  0.053   -0.085     0.179 0.482     False\n",
              "25                            engagement  congruencia_influencer_producto_x_conciencia_d... -0.075   -0.225     0.123 0.492     False\n",
              "26                            engagement  informatividad_del_contenido_x_conciencia_de_l... -0.038   -0.182     0.093 0.502     False\n",
              "27                            engagement     lider_de_opinion_x_conciencia_de_la_persuasion  0.053   -0.101     0.226 0.528     False\n",
              "28                               actitud                    congruencia_influencer_follower -0.036   -0.160     0.094 0.578     False\n",
              "29  predisposicion_a_comprar_un_producto                                            actitud  0.032   -0.093     0.170 0.594     False\n",
              "30                            engagement                                          similitud -0.029   -0.142     0.088 0.616     False\n",
              "31                            engagement             expertis_x_conciencia_de_la_persuasion -0.053   -0.195     0.128 0.649     False\n",
              "32                            engagement         atractividad_x_conciencia_de_la_persuasion -0.022   -0.169     0.106 0.669     False\n",
              "33  predisposicion_a_comprar_un_producto              actitud_x_conciencia_de_la_persuasion -0.027   -0.156     0.093 0.674     False\n",
              "34  predisposicion_a_comprar_un_producto           engagement_x_conciencia_de_la_persuasion -0.011   -0.148     0.120 0.840     False\n",
              "35                            engagement                                       atractividad -0.019   -0.132     0.108 0.841     False\n",
              "36  predisposicion_a_comprar_un_producto                                         engagement -0.011   -0.128     0.108 0.842     False\n",
              "37                               actitud                                   lider_de_opinion  0.021   -0.136     0.163 0.864     False\n",
              "38                               actitud     lider_de_opinion_x_conciencia_de_la_persuasion  0.016   -0.151     0.161 0.897     False\n",
              "39                            engagement  congruencia_influencer_follower_x_conciencia_d...  0.008   -0.116     0.126 0.898     False\n",
              "40                            engagement                                           expertis  0.003   -0.133     0.134 0.966     False\n",
              "41                               actitud                                         integridad -0.005   -0.142     0.141 0.984     False\n",
              "42                               actitud                                       atractividad -0.003   -0.126     0.122 1.000     False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c648e55c-2042-432b-b961-9dd93377d9a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Endog</th>\n",
              "      <th>Exog</th>\n",
              "      <th>Beta</th>\n",
              "      <th>CI_2.5%</th>\n",
              "      <th>CI_97.5%</th>\n",
              "      <th>p</th>\n",
              "      <th>Sig_0.05</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>predisposicion_a_comprar_un_producto</td>\n",
              "      <td>conciencia_de_la_persuasion</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.334</td>\n",
              "      <td>0.001</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>engagement</td>\n",
              "      <td>lider_de_opinion</td>\n",
              "      <td>0.256</td>\n",
              "      <td>0.109</td>\n",
              "      <td>0.386</td>\n",
              "      <td>0.001</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>engagement</td>\n",
              "      <td>congruencia_influencer_producto</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.290</td>\n",
              "      <td>0.010</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>engagement</td>\n",
              "      <td>integridad_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.161</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.289</td>\n",
              "      <td>0.012</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>actitud</td>\n",
              "      <td>atractividad_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.198</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.339</td>\n",
              "      <td>0.015</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>actitud</td>\n",
              "      <td>similitud_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.367</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.021</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>engagement</td>\n",
              "      <td>similitud_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.121</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.233</td>\n",
              "      <td>0.033</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>engagement</td>\n",
              "      <td>conciencia_de_la_persuasion</td>\n",
              "      <td>0.141</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.079</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>actitud</td>\n",
              "      <td>autenticidad_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.147</td>\n",
              "      <td>-0.293</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.080</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>engagement</td>\n",
              "      <td>informatividad_del_contenido</td>\n",
              "      <td>0.092</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.111</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>engagement</td>\n",
              "      <td>autenticidad</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.215</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.130</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>actitud</td>\n",
              "      <td>congruencia_influencer_follower_x_conciencia_d...</td>\n",
              "      <td>0.113</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.251</td>\n",
              "      <td>0.132</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>actitud</td>\n",
              "      <td>similitud</td>\n",
              "      <td>0.125</td>\n",
              "      <td>-0.034</td>\n",
              "      <td>0.281</td>\n",
              "      <td>0.139</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>actitud</td>\n",
              "      <td>expertis</td>\n",
              "      <td>0.096</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.169</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>actitud</td>\n",
              "      <td>conciencia_de_la_persuasion</td>\n",
              "      <td>0.101</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>0.257</td>\n",
              "      <td>0.173</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>actitud</td>\n",
              "      <td>congruencia_influencer_producto</td>\n",
              "      <td>0.079</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.176</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>actitud</td>\n",
              "      <td>autenticidad</td>\n",
              "      <td>0.082</td>\n",
              "      <td>-0.043</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.200</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>actitud</td>\n",
              "      <td>integridad_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.084</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>0.229</td>\n",
              "      <td>0.221</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>actitud</td>\n",
              "      <td>expertis_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.103</td>\n",
              "      <td>-0.271</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.224</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>engagement</td>\n",
              "      <td>congruencia_influencer_follower</td>\n",
              "      <td>-0.076</td>\n",
              "      <td>-0.190</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.230</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>actitud</td>\n",
              "      <td>informatividad_del_contenido</td>\n",
              "      <td>0.061</td>\n",
              "      <td>-0.056</td>\n",
              "      <td>0.186</td>\n",
              "      <td>0.282</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>actitud</td>\n",
              "      <td>congruencia_influencer_producto_x_conciencia_d...</td>\n",
              "      <td>0.060</td>\n",
              "      <td>-0.080</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.420</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>engagement</td>\n",
              "      <td>autenticidad_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.087</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.436</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>engagement</td>\n",
              "      <td>integridad</td>\n",
              "      <td>0.056</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>0.177</td>\n",
              "      <td>0.443</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>actitud</td>\n",
              "      <td>informatividad_del_contenido_x_conciencia_de_l...</td>\n",
              "      <td>0.053</td>\n",
              "      <td>-0.085</td>\n",
              "      <td>0.179</td>\n",
              "      <td>0.482</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>engagement</td>\n",
              "      <td>congruencia_influencer_producto_x_conciencia_d...</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.225</td>\n",
              "      <td>0.123</td>\n",
              "      <td>0.492</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>engagement</td>\n",
              "      <td>informatividad_del_contenido_x_conciencia_de_l...</td>\n",
              "      <td>-0.038</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>0.093</td>\n",
              "      <td>0.502</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>engagement</td>\n",
              "      <td>lider_de_opinion_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.053</td>\n",
              "      <td>-0.101</td>\n",
              "      <td>0.226</td>\n",
              "      <td>0.528</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>actitud</td>\n",
              "      <td>congruencia_influencer_follower</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.578</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>predisposicion_a_comprar_un_producto</td>\n",
              "      <td>actitud</td>\n",
              "      <td>0.032</td>\n",
              "      <td>-0.093</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.594</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>engagement</td>\n",
              "      <td>similitud</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.616</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>engagement</td>\n",
              "      <td>expertis_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>-0.195</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.649</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>engagement</td>\n",
              "      <td>atractividad_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>0.106</td>\n",
              "      <td>0.669</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>predisposicion_a_comprar_un_producto</td>\n",
              "      <td>actitud_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>0.093</td>\n",
              "      <td>0.674</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>predisposicion_a_comprar_un_producto</td>\n",
              "      <td>engagement_x_conciencia_de_la_persuasion</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>-0.148</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.840</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>engagement</td>\n",
              "      <td>atractividad</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.132</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.841</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>predisposicion_a_comprar_un_producto</td>\n",
              "      <td>engagement</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>-0.128</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.842</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>actitud</td>\n",
              "      <td>lider_de_opinion</td>\n",
              "      <td>0.021</td>\n",
              "      <td>-0.136</td>\n",
              "      <td>0.163</td>\n",
              "      <td>0.864</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>actitud</td>\n",
              "      <td>lider_de_opinion_x_conciencia_de_la_persuasion</td>\n",
              "      <td>0.016</td>\n",
              "      <td>-0.151</td>\n",
              "      <td>0.161</td>\n",
              "      <td>0.897</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>engagement</td>\n",
              "      <td>congruencia_influencer_follower_x_conciencia_d...</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>0.126</td>\n",
              "      <td>0.898</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>engagement</td>\n",
              "      <td>expertis</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.966</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>actitud</td>\n",
              "      <td>integridad</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.984</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>actitud</td>\n",
              "      <td>atractividad</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.126</td>\n",
              "      <td>0.122</td>\n",
              "      <td>1.000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c648e55c-2042-432b-b961-9dd93377d9a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c648e55c-2042-432b-b961-9dd93377d9a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c648e55c-2042-432b-b961-9dd93377d9a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1d2dad73-bca1-4c6a-8abc-cd7359be6d85\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tb_show')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d2dad73-bca1-4c6a-8abc-cd7359be6d85 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tb_show');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tb_show",
              "summary": "{\n  \"name\": \"tb_show\",\n  \"rows\": 43,\n  \"fields\": [\n    {\n      \"column\": \"Endog\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"predisposicion_a_comprar_un_producto\",\n          \"engagement\",\n          \"actitud\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Exog\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"integridad\",\n          \"congruencia_influencer_follower_x_conciencia_de_la_persuasion\",\n          \"conciencia_de_la_persuasion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Beta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09666669379844582,\n        \"min\": -0.2049,\n        \"max\": 0.2556,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          0.0212,\n          0.0529,\n          -0.0747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI_2.5%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09887810968995236,\n        \"min\": -0.3675,\n        \"max\": 0.1087,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          -0.2245,\n          -0.0439,\n          -0.2934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CI_97.5%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09094093144553567,\n        \"min\": -0.0317,\n        \"max\": 0.3857,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.0928,\n          0.2305,\n          0.0171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32846448218580016,\n        \"min\": 0.0008,\n        \"max\": 1.0,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          0.8644,\n          0.482,\n          0.4924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sig_0.05\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lS04mxCbikuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Elemento de la lista\n",
        "*   Elemento de la lista\n",
        "\n"
      ],
      "metadata": {
        "id": "8vumV0XhDugX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# MODELADO SEM-PLS\n",
        "```\n",
        "\n",
        "# MODELADO SEM-PLS\n",
        "\n",
        "Con constructos de segundo ORDEN\n",
        "\n",
        "(HCM - Two Stage):"
      ],
      "metadata": {
        "id": "SqnDhJ2sQd5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# PLS-SEM (Mode A) + HCM 2º ORDEN (Two-Stage) + MODERACIÓN PKM\n",
        "# + (OPCIONAL) Bootstrap de paths (CI + p aproximado)\n",
        "# Copia y pega TODO este bloque en una sola celda.\n",
        "# Requisitos: ya debes tener cargado:\n",
        "#   - df  (tu dataframe original)\n",
        "#   - constructos_1er_orden (tu diccionario de bloques/ítems)\n",
        "# ============================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# 0) CONFIGURACIÓN\n",
        "# ============================================================\n",
        "BOOTSTRAP = True      # True para CI/p; False si solo quieres betas y R²\n",
        "N_BOOT = 500          # 500 rápido; 2000-5000 para tesis\n",
        "SEED = 7\n",
        "\n",
        "# ============================================================\n",
        "# 1) STAGE 1: modelo plano para obtener SCORES de 1er orden (LOCs)\n",
        "#    (Dimensiones -> actitud/engagement; moderación sobre intención)\n",
        "# ============================================================\n",
        "paths_stage1 = {\n",
        "    \"actitud\": [\n",
        "        \"integridad\", \"expertis\", \"autenticidad\",\n",
        "        \"atractividad\", \"similitud\",\n",
        "        \"lider_de_opinion\", \"informatividad_del_contenido\",\n",
        "        \"congruencia_influencer_follower\", \"congruencia_influencer_producto\"\n",
        "    ],\n",
        "    \"engagement\": [\n",
        "        \"integridad\", \"expertis\", \"autenticidad\",\n",
        "        \"atractividad\", \"similitud\",\n",
        "        \"lider_de_opinion\", \"informatividad_del_contenido\",\n",
        "        \"congruencia_influencer_follower\", \"congruencia_influencer_producto\"\n",
        "    ],\n",
        "    \"predisposicion_a_comprar_un_producto\": [\n",
        "        \"actitud\", \"engagement\",\n",
        "        \"conciencia_de_la_persuasion\",\n",
        "        \"actitud_x_conciencia_de_la_persuasion\",\n",
        "        \"engagement_x_conciencia_de_la_persuasion\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 2) HCM (2º ORDEN) según tu imagen\n",
        "# ============================================================\n",
        "hcm_map = {\n",
        "    \"credibilidad\": [\"integridad\", \"expertis\", \"autenticidad\"],\n",
        "    \"semejanza\": [\"atractividad\", \"similitud\"],\n",
        "    \"flujo_de_informacion\": [\"lider_de_opinion\", \"informatividad_del_contenido\"],\n",
        "    \"congruencia\": [\"congruencia_influencer_follower\", \"congruencia_influencer_producto\"],\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 3) STAGE 2: modelo REAL (HOCs -> actitud/engagement -> intención) + moderación PKM\n",
        "# ============================================================\n",
        "paths_stage2 = {\n",
        "    \"actitud\": [\"credibilidad\", \"semejanza\", \"flujo_de_informacion\", \"congruencia\"],\n",
        "    \"engagement\": [\"credibilidad\", \"semejanza\", \"flujo_de_informacion\", \"congruencia\"],\n",
        "    \"predisposicion_a_comprar_un_producto\": [\n",
        "        \"actitud\", \"engagement\",\n",
        "        \"conciencia_de_la_persuasion\",\n",
        "        \"actitud_x_conciencia_de_la_persuasion\",\n",
        "        \"engagement_x_conciencia_de_la_persuasion\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 4) PREPARA df_analisis (solo columnas necesarias + limpieza robusta)\n",
        "# ============================================================\n",
        "def preparar_df_para_pls(df, constructos):\n",
        "    cols = [it for items in constructos.values() for it in items]\n",
        "    faltan = [c for c in cols if c not in df.columns]\n",
        "    if faltan:\n",
        "        raise ValueError(f\"Faltan columnas en tu df: {faltan}\")\n",
        "\n",
        "    df2 = df[cols].copy()\n",
        "    df2 = df2.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    df2 = df2.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    nun = df2.nunique(dropna=True)\n",
        "    const_cols = nun[nun <= 1].index.tolist()\n",
        "    if const_cols:\n",
        "        print(\"⚠️ Columnas constantes/sin datos (se eliminan):\", const_cols)\n",
        "        df2 = df2.drop(columns=const_cols)\n",
        "\n",
        "    nan_before = df2.isna().sum().sum()\n",
        "    if nan_before > 0:\n",
        "        df2 = df2.apply(lambda s: s.fillna(s.mean()))\n",
        "        nan_after = df2.isna().sum().sum()\n",
        "        print(f\"✅ Imputación NaN: antes={nan_before}, después={nan_after}\")\n",
        "\n",
        "    if not np.isfinite(df2.to_numpy()).all():\n",
        "        df2 = df2.replace([np.inf, -np.inf], np.nan).apply(lambda s: s.fillna(s.mean()))\n",
        "        if not np.isfinite(df2.to_numpy()).all():\n",
        "            raise ValueError(\"Aún hay valores no finitos en df_analisis (NaN/Inf).\")\n",
        "\n",
        "    print(\"✅ df_analisis listo. Shape:\", df2.shape)\n",
        "    return df2\n",
        "\n",
        "df_analisis = preparar_df_para_pls(df, constructos_1er_orden)\n",
        "\n",
        "# ============================================================\n",
        "# 5) FUNCIONES PLS Mode A + Moderación (robustas)\n",
        "# ============================================================\n",
        "def zscore_df(df):\n",
        "    mu = df.mean()\n",
        "    sd = df.std(ddof=0).replace(0, 1)\n",
        "    out = (df - mu) / sd\n",
        "    out = out.replace([np.inf, -np.inf], np.nan)\n",
        "    return out.fillna(0)\n",
        "\n",
        "def ols_beta(X, y):\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    y = np.asarray(y, dtype=float).reshape(-1, 1)\n",
        "    mask = np.isfinite(X).all(axis=1) & np.isfinite(y).ravel()\n",
        "    X = X[mask]; y = y[mask]\n",
        "    if X.shape[0] < X.shape[1] + 2:\n",
        "        return np.full(X.shape[1], np.nan), np.nan\n",
        "\n",
        "    X1 = np.column_stack([np.ones(len(X)), X])\n",
        "    try:\n",
        "        b = np.linalg.lstsq(X1, y, rcond=None)[0]\n",
        "    except np.linalg.LinAlgError:\n",
        "        lam = 1e-6\n",
        "        XtX = X1.T @ X1 + lam * np.eye(X1.shape[1])\n",
        "        b = np.linalg.solve(XtX, X1.T @ y)\n",
        "\n",
        "    yhat = X1 @ b\n",
        "    ssr = ((y - yhat) ** 2).sum()\n",
        "    sst = ((y - y.mean()) ** 2).sum()\n",
        "    r2 = 1 - (ssr / sst) if sst > 0 else np.nan\n",
        "    return b[1:].flatten(), float(r2)\n",
        "\n",
        "def init_outer_weights(cols):\n",
        "    return np.ones(len(cols)) / max(len(cols), 1)\n",
        "\n",
        "def latent_scores(dfZ, blocks, outer_w):\n",
        "    scores = {}\n",
        "    for c, cols in blocks.items():\n",
        "        cols_ok = [x for x in cols if x in dfZ.columns]\n",
        "        if len(cols_ok) == 0:\n",
        "            raise ValueError(f\"El constructo '{c}' se quedó sin ítems.\")\n",
        "        X = dfZ[cols_ok].to_numpy()\n",
        "\n",
        "        w = outer_w[c]\n",
        "        if len(w) != len(cols_ok):\n",
        "            w = np.ones(len(cols_ok)) / len(cols_ok)\n",
        "        w = w.reshape(-1, 1)\n",
        "\n",
        "        lv = (X @ w).flatten()\n",
        "        lv = (lv - lv.mean()) / (lv.std(ddof=0) + 1e-12)\n",
        "        scores[c] = lv\n",
        "\n",
        "        outer_w[c] = (w.flatten() / (np.linalg.norm(w) + 1e-12))\n",
        "    return pd.DataFrame(scores), outer_w\n",
        "\n",
        "def update_outer_weights_modeA(dfZ, blocks, LV_base, inner_pred):\n",
        "    new_w = {}\n",
        "    for c, cols in blocks.items():\n",
        "        cols_ok = [x for x in cols if x in dfZ.columns]\n",
        "        X = dfZ[cols_ok].to_numpy()\n",
        "        ref = inner_pred.get(c, LV_base[c].to_numpy()).reshape(-1, 1)\n",
        "\n",
        "        w = []\n",
        "        for j in range(X.shape[1]):\n",
        "            xj = X[:, [j]]\n",
        "            num = float((xj * ref).mean())\n",
        "            den = float(xj.std(ddof=0) * ref.std(ddof=0) + 1e-12)\n",
        "            w.append(num / den)\n",
        "\n",
        "        w = np.array(w, dtype=float)\n",
        "        w = w / (np.linalg.norm(w) + 1e-12)\n",
        "        new_w[c] = w\n",
        "    return new_w\n",
        "\n",
        "def inner_estimates_with_moderation(LV_base, paths):\n",
        "    LV = LV_base.copy()\n",
        "\n",
        "    # interacciones PKM (two-stage)\n",
        "    LV[\"actitud_x_conciencia_de_la_persuasion\"] = LV[\"actitud\"] * LV[\"conciencia_de_la_persuasion\"]\n",
        "    LV[\"engagement_x_conciencia_de_la_persuasion\"] = LV[\"engagement\"] * LV[\"conciencia_de_la_persuasion\"]\n",
        "\n",
        "    for col in [\"actitud_x_conciencia_de_la_persuasion\", \"engagement_x_conciencia_de_la_persuasion\"]:\n",
        "        LV[col] = (LV[col] - LV[col].mean()) / (LV[col].std(ddof=0) + 1e-12)\n",
        "\n",
        "    preds, betas, r2s = {}, {}, {}\n",
        "    for endog, exogs in paths.items():\n",
        "        X = LV[exogs].to_numpy()\n",
        "        y = LV[endog].to_numpy()\n",
        "        b, r2 = ols_beta(X, y)\n",
        "        betas[endog] = dict(zip(exogs, b))\n",
        "        r2s[endog] = r2\n",
        "\n",
        "        yhat = X @ b\n",
        "        yhat = (yhat - yhat.mean()) / (yhat.std(ddof=0) + 1e-12)\n",
        "        preds[endog] = yhat\n",
        "\n",
        "    return preds, betas, r2s, LV\n",
        "\n",
        "def pls_scores_modeA(df, blocks, paths, max_iter=200, tol=1e-7, verbose=False):\n",
        "    dfZ = zscore_df(df)\n",
        "    outer_w = {c: init_outer_weights([x for x in cols if x in dfZ.columns]) for c, cols in blocks.items()}\n",
        "\n",
        "    for it in range(max_iter):\n",
        "        LV_base, outer_w = latent_scores(dfZ, blocks, outer_w)\n",
        "        inner_pred, _, _, _ = inner_estimates_with_moderation(LV_base, paths)\n",
        "        new_w = update_outer_weights_modeA(dfZ, blocks, LV_base, inner_pred)\n",
        "\n",
        "        deltas = []\n",
        "        for c in blocks.keys():\n",
        "            w_old = outer_w[c]; w_new = new_w[c]\n",
        "            m = min(len(w_old), len(w_new))\n",
        "            deltas.append(np.max(np.abs(w_new[:m] - w_old[:m])))\n",
        "        change = float(np.max(deltas)) if deltas else np.nan\n",
        "\n",
        "        outer_w = new_w\n",
        "        if verbose and (it % 20 == 0 or change < tol):\n",
        "            print(f\"Iter {it:03d} | max Δw = {change:.2e}\")\n",
        "        if change < tol:\n",
        "            break\n",
        "\n",
        "    LV_base, _ = latent_scores(zscore_df(df), blocks, outer_w)\n",
        "    _, _, _, LV_full = inner_estimates_with_moderation(LV_base, paths)\n",
        "    return LV_full, outer_w\n",
        "\n",
        "# ============================================================\n",
        "# 6) STAGE 2: construir HOCs + estimar estructura final\n",
        "# ============================================================\n",
        "def build_stage2_latents(LV_stage1, hcm_map):\n",
        "    LV2 = LV_stage1.copy()\n",
        "\n",
        "    # HOCs como promedio estandarizado de LOCs (scores)\n",
        "    for hoc, locs in hcm_map.items():\n",
        "        for loc in locs:\n",
        "            if loc not in LV2.columns:\n",
        "                raise ValueError(f\"Falta '{loc}' para construir '{hoc}'.\")\n",
        "        comp = LV2[locs].mean(axis=1)\n",
        "        LV2[hoc] = (comp - comp.mean()) / (comp.std(ddof=0) + 1e-12)\n",
        "\n",
        "    # interacciones PKM (en stage 2)\n",
        "    LV2[\"actitud_x_conciencia_de_la_persuasion\"] = LV2[\"actitud\"] * LV2[\"conciencia_de_la_persuasion\"]\n",
        "    LV2[\"engagement_x_conciencia_de_la_persuasion\"] = LV2[\"engagement\"] * LV2[\"conciencia_de_la_persuasion\"]\n",
        "    for col in [\"actitud_x_conciencia_de_la_persuasion\", \"engagement_x_conciencia_de_la_persuasion\"]:\n",
        "        LV2[col] = (LV2[col] - LV2[col].mean()) / (LV2[col].std(ddof=0) + 1e-12)\n",
        "\n",
        "    return LV2\n",
        "\n",
        "def estimate_structural(LV2, paths):\n",
        "    betas, r2s = {}, {}\n",
        "    for endog, exogs in paths.items():\n",
        "        X = LV2[exogs].to_numpy()\n",
        "        y = LV2[endog].to_numpy()\n",
        "        b, r2 = ols_beta(X, y)\n",
        "        betas[endog] = dict(zip(exogs, b))\n",
        "        r2s[endog] = r2\n",
        "    return betas, r2s\n",
        "\n",
        "# ============================================================\n",
        "# 7) EJECUTA (ORIGINAL) y muestra resultados STAGE 2\n",
        "# ============================================================\n",
        "LV_stage1, outer_w = pls_scores_modeA(df_analisis, constructos_1er_orden, paths_stage1, verbose=False)\n",
        "LV_stage2 = build_stage2_latents(LV_stage1, hcm_map)\n",
        "betas2, r2s2 = estimate_structural(LV_stage2, paths_stage2)\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"STAGE 2 (Modelo como tu imagen) - R²\")\n",
        "print(\"====================\")\n",
        "for k, v in r2s2.items():\n",
        "    print(f\"{k}: {v:.3f}\")\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"STAGE 2 - PATH COEFFICIENTS β\")\n",
        "print(\"====================\")\n",
        "for endog, exogs in paths_stage2.items():\n",
        "    print(f\"\\n{endog} (R²={r2s2[endog]:.3f})\")\n",
        "    for ex in exogs:\n",
        "        print(f\"  {ex:40s} -> {endog:35s}  β={betas2[endog][ex]:+.3f}\")\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"STAGE 2 - MODERACIÓN (lo clave)\")\n",
        "print(\"====================\")\n",
        "b4 = betas2[\"predisposicion_a_comprar_un_producto\"][\"actitud_x_conciencia_de_la_persuasion\"]\n",
        "b5 = betas2[\"predisposicion_a_comprar_un_producto\"][\"engagement_x_conciencia_de_la_persuasion\"]\n",
        "print(f\"β(Actitud×conciencia de la persuasión -> Intención)     = {b4:+.3f}  (esperas NEGATIVO)\")\n",
        "print(f\"β(Engagement×conciencia de la persuasión -> Intención)  = {b5:+.3f}  (esperas NEGATIVO)\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8) BOOTSTRAP (OPCIONAL) para CI/p de los β del STAGE 2\n",
        "# ============================================================\n",
        "def bootstrap_stage2(df_analisis, blocks, paths_stage1, hcm_map, paths_stage2, B=5000, seed=7):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # original\n",
        "    LV1_orig, _ = pls_scores_modeA(df_analisis, blocks, paths_stage1, verbose=False)\n",
        "    LV2_orig = build_stage2_latents(LV1_orig, hcm_map)\n",
        "    betas_orig, r2_orig = estimate_structural(LV2_orig, paths_stage2)\n",
        "\n",
        "    edges = []\n",
        "    for endog, exogs in paths_stage2.items():\n",
        "        for ex in exogs:\n",
        "            edges.append((endog, ex))\n",
        "\n",
        "    boot = {e: [] for e in edges}\n",
        "\n",
        "    n = len(df_analisis)\n",
        "    for _ in range(B):\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        sample = df_analisis.iloc[idx].reset_index(drop=True)\n",
        "\n",
        "        LV1_b, _ = pls_scores_modeA(sample, blocks, paths_stage1, verbose=False)\n",
        "        LV2_b = build_stage2_latents(LV1_b, hcm_map)\n",
        "        betas_b, _ = estimate_structural(LV2_b, paths_stage2)\n",
        "\n",
        "        for (endog, exog) in edges:\n",
        "            boot[(endog, exog)].append(float(betas_b[endog][exog]))\n",
        "\n",
        "    rows = []\n",
        "    for (endog, exog) in edges:\n",
        "        dist = np.array(boot[(endog, exog)], dtype=float)\n",
        "        b0 = float(betas_orig[endog][exog])\n",
        "        se = float(np.nanstd(dist, ddof=1))\n",
        "        t = (b0 / se) if se > 0 else np.nan\n",
        "        p_emp = 2 * min(np.mean(dist <= 0), np.mean(dist >= 0))\n",
        "        ci_low = float(np.nanpercentile(dist, 2.5))\n",
        "        ci_high = float(np.nanpercentile(dist, 97.5))\n",
        "\n",
        "        rows.append({\n",
        "            \"Endog\": endog,\n",
        "            \"Exog\": exog,\n",
        "            \"Beta_orig\": b0,\n",
        "            \"CI_2.5%\": ci_low,\n",
        "            \"CI_97.5%\": ci_high,\n",
        "            \"SE_boot\": se,\n",
        "            \"t_boot\": float(t),\n",
        "            \"p_emp(2-colas)\": float(p_emp),\n",
        "            \"Significativo_0.05\": (p_emp < 0.05)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows).sort_values(by=\"p_emp(2-colas)\")\n",
        "\n",
        "if BOOTSTRAP:\n",
        "    print(\"\\n====================\")\n",
        "    print(f\"BOOTSTRAP STAGE 2 (B={N_BOOT})\")\n",
        "    print(\"====================\")\n",
        "    tabla_boot = bootstrap_stage2(\n",
        "        df_analisis, constructos_1er_orden,\n",
        "        paths_stage1, hcm_map, paths_stage2,\n",
        "        B=N_BOOT, seed=SEED\n",
        "    )\n",
        "    pd.options.display.float_format = \"{:.4f}\".format\n",
        "    print(tabla_boot)\n",
        "\n",
        "print(\"\\n✅ Listo: este bloque implementa HCM 2º orden + moderación PKM + (opcional) bootstrap.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGoJRrEuZELe",
        "outputId": "90f09269-43c1-4d15-e24b-2318a48ff8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imputación NaN: antes=8, después=0\n",
            "✅ df_analisis listo. Shape: (240, 47)\n",
            "\n",
            "====================\n",
            "STAGE 2 (Modelo como tu imagen) - R²\n",
            "====================\n",
            "actitud: 0.014\n",
            "engagement: 0.060\n",
            "predisposicion_a_comprar_un_producto: 0.051\n",
            "\n",
            "====================\n",
            "STAGE 2 - PATH COEFFICIENTS β\n",
            "====================\n",
            "\n",
            "actitud (R²=0.014)\n",
            "  credibilidad                             -> actitud                              β=+0.063\n",
            "  semejanza                                -> actitud                              β=+0.093\n",
            "  flujo_de_informacion                     -> actitud                              β=+0.039\n",
            "  congruencia                              -> actitud                              β=+0.010\n",
            "\n",
            "engagement (R²=0.060)\n",
            "  credibilidad                             -> engagement                           β=-0.025\n",
            "  semejanza                                -> engagement                           β=-0.010\n",
            "  flujo_de_informacion                     -> engagement                           β=+0.218\n",
            "  congruencia                              -> engagement                           β=+0.091\n",
            "\n",
            "predisposicion_a_comprar_un_producto (R²=0.051)\n",
            "  actitud                                  -> predisposicion_a_comprar_un_producto  β=+0.031\n",
            "  engagement                               -> predisposicion_a_comprar_un_producto  β=-0.011\n",
            "  conciencia_de_la_persuasion              -> predisposicion_a_comprar_un_producto  β=+0.217\n",
            "  actitud_x_conciencia_de_la_persuasion    -> predisposicion_a_comprar_un_producto  β=-0.035\n",
            "  engagement_x_conciencia_de_la_persuasion -> predisposicion_a_comprar_un_producto  β=-0.010\n",
            "\n",
            "====================\n",
            "STAGE 2 - MODERACIÓN (lo clave)\n",
            "====================\n",
            "β(Actitud×conciencia de la persuasión -> Intención)     = -0.035  (esperas NEGATIVO)\n",
            "β(Engagement×conciencia de la persuasión -> Intención)  = -0.010  (esperas NEGATIVO)\n",
            "\n",
            "====================\n",
            "BOOTSTRAP STAGE 2 (B=500)\n",
            "====================\n",
            "                                   Endog                                      Exog  Beta_orig  CI_2.5%  CI_97.5%  SE_boot  t_boot  p_emp(2-colas)  Significativo_0.05\n",
            "6                             engagement                      flujo_de_informacion     0.2176   0.1067    0.3405   0.0597  3.6468          0.0000                True\n",
            "10  predisposicion_a_comprar_un_producto               conciencia_de_la_persuasion     0.2174   0.0996    0.3291   0.0608  3.5746          0.0000                True\n",
            "7                             engagement                               congruencia     0.0912  -0.0311    0.2008   0.0632  1.4431          0.1800               False\n",
            "1                                actitud                                 semejanza     0.0926  -0.0644    0.2330   0.0736  1.2572          0.2360               False\n",
            "0                                actitud                              credibilidad     0.0633  -0.0497    0.1877   0.0613  1.0317          0.2960               False\n",
            "2                                actitud                      flujo_de_informacion     0.0389  -0.0865    0.1594   0.0643  0.6047          0.5400               False\n",
            "8   predisposicion_a_comprar_un_producto                                   actitud     0.0313  -0.0904    0.1659   0.0669  0.4677          0.5680               False\n",
            "11  predisposicion_a_comprar_un_producto     actitud_x_conciencia_de_la_persuasion    -0.0349  -0.1660    0.0801   0.0632 -0.5529          0.6000               False\n",
            "4                             engagement                              credibilidad    -0.0250  -0.1499    0.0839   0.0595 -0.4211          0.6920               False\n",
            "5                             engagement                                 semejanza    -0.0099  -0.1321    0.0940   0.0559 -0.1766          0.7880               False\n",
            "3                                actitud                               congruencia     0.0102  -0.1082    0.1325   0.0619  0.1648          0.7920               False\n",
            "9   predisposicion_a_comprar_un_producto                                engagement    -0.0107  -0.1216    0.1121   0.0614 -0.1735          0.8440               False\n",
            "12  predisposicion_a_comprar_un_producto  engagement_x_conciencia_de_la_persuasion    -0.0099  -0.1485    0.1199   0.0674 -0.1471          0.8520               False\n",
            "\n",
            "✅ Listo: este bloque implementa HCM 2º orden + moderación PKM + (opcional) bootstrap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# SEM mejorado (Graphviz): layout limpio + tamaños fijos + color por signo\n",
        "# + (opcional) estilo por significancia si existe \"tabla_boot\"\n",
        "# Requiere: betas2, r2s2, paths_stage2 (y opcional tabla_boot)\n",
        "# Salida: sem_stage2_pretty.png\n",
        "# ============================\n",
        "\n",
        "import math\n",
        "from graphviz import Digraph\n",
        "\n",
        "# --------- 1) Labels bonitos y cortos ---------\n",
        "pretty = {\n",
        "    \"credibilidad\": \"Credibilidad\",\n",
        "    \"semejanza\": \"Semejanza\",\n",
        "    \"flujo_de_informacion\": \"Flujo de información\",\n",
        "    \"congruencia\": \"Congruencia\",\n",
        "    \"actitud\": \"Actitud\",\n",
        "    \"engagement\": \"Engagement\",\n",
        "    \"predisposicion_a_comprar_un_producto\": \"Intención de compra\",\n",
        "    \"conciencia_de_la_persuasion\": \"Conciencia de la persuasión\",\n",
        "    \"actitud_x_conciencia_de_la_persuasion\": \"Actitud × Conciencia\",\n",
        "    \"engagement_x_conciencia_de_la_persuasion\": \"Engagement × Conciencia\",\n",
        "}\n",
        "\n",
        "exo = [\"flujo_de_informacion\", \"semejanza\", \"credibilidad\", \"congruencia\"]\n",
        "med = [\"engagement\", \"actitud\"]\n",
        "end = [\"predisposicion_a_comprar_un_producto\"]\n",
        "mod = \"conciencia_de_la_persuasion\"\n",
        "inter = [\"actitud_x_conciencia_de_la_persuasion\", \"engagement_x_conciencia_de_la_persuasion\"]\n",
        "\n",
        "# --------- 2) Significancia opcional (si existe tabla_boot) ---------\n",
        "sig_map = {}\n",
        "p_map = {}\n",
        "if \"tabla_boot\" in globals() and isinstance(globals()[\"tabla_boot\"], object):\n",
        "    try:\n",
        "        tb = globals()[\"tabla_boot\"].copy()\n",
        "        # esperamos columnas: Endog, Exog, Significativo_0.05, p_emp(2-colas)\n",
        "        for _, r in tb.iterrows():\n",
        "            sig_map[(r[\"Endog\"], r[\"Exog\"])] = bool(r.get(\"Significativo_0.05\", False))\n",
        "            p_map[(r[\"Endog\"], r[\"Exog\"])] = float(r.get(\"p_emp(2-colas)\", float(\"nan\")))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def fmt_beta(b):\n",
        "    if b is None or (isinstance(b, float) and (math.isnan(b) or math.isinf(b))):\n",
        "        return \"NA\"\n",
        "    return f\"{b:+.3f}\"\n",
        "\n",
        "def fmt_r2(x):\n",
        "    if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):\n",
        "        return \"R²=NA\"\n",
        "    return f\"R²={x:.3f}\"\n",
        "\n",
        "def edge_style(beta, significant=None):\n",
        "    \"\"\"Color por signo, grosor por magnitud, y si hay significancia: gris punteado cuando no.\"\"\"\n",
        "    if beta is None or (isinstance(beta, float) and (math.isnan(beta) or math.isinf(beta))):\n",
        "        return {\"color\":\"#999999\", \"style\":\"dashed\", \"penwidth\":\"1.2\"}\n",
        "\n",
        "    # grosor por magnitud (cap)\n",
        "    pw = 1.2 + min(4.0, abs(beta) * 6.0)   # ajusta si quieres más/menos\n",
        "    color = \"#1B9E77\" if beta >= 0 else \"#D95F02\"  # verde/rojo\n",
        "\n",
        "    if significant is False:\n",
        "        return {\"color\":\"#9E9E9E\", \"style\":\"dashed\", \"penwidth\":str(max(1.1, pw-0.6))}\n",
        "    return {\"color\":color, \"style\":\"solid\", \"penwidth\":str(pw)}\n",
        "\n",
        "# --------- 3) Crear grafo con layout en capas ---------\n",
        "dot = Digraph(\"SEM_STAGE2_PRETTY\", format=\"png\")\n",
        "\n",
        "dot.attr(\n",
        "    rankdir=\"LR\",\n",
        "    bgcolor=\"white\",\n",
        "    splines=\"spline\",\n",
        "    concentrate=\"true\",\n",
        "    nodesep=\"0.55\",\n",
        "    ranksep=\"0.95\",\n",
        "    pad=\"0.25\"\n",
        ")\n",
        "\n",
        "# ---- estilo base nodos latentes ----\n",
        "dot.attr(\"node\",\n",
        "         shape=\"circle\",\n",
        "         style=\"filled\",\n",
        "         fillcolor=\"#6FA8DC\",\n",
        "         color=\"#2F5597\",\n",
        "         fontname=\"Arial\",\n",
        "         fontsize=\"11\",\n",
        "         fontcolor=\"white\",\n",
        "         fixedsize=\"true\",\n",
        "         width=\"1.55\",\n",
        "         height=\"1.55\")\n",
        "\n",
        "# exógenas\n",
        "for n in exo:\n",
        "    dot.node(n, label=pretty.get(n, n))\n",
        "\n",
        "# mediadores (con R² si existe)\n",
        "for n in med:\n",
        "    lab = pretty.get(n, n)\n",
        "    if n in r2s2:\n",
        "        lab = f\"{lab}\\n{fmt_r2(r2s2[n])}\"\n",
        "    dot.node(n, label=lab)\n",
        "\n",
        "# endógena final (más grande)\n",
        "dot.attr(\"node\", width=\"2.05\", height=\"2.05\")\n",
        "n = end[0]\n",
        "lab = f\"{pretty.get(n, n)}\\n{fmt_r2(r2s2.get(n, float('nan')))}\"\n",
        "dot.node(n, label=lab)\n",
        "\n",
        "# moderador (verde)\n",
        "dot.attr(\"node\", width=\"1.75\", height=\"1.75\", fillcolor=\"#93C47D\", color=\"#38761D\")\n",
        "dot.node(mod, label=pretty.get(mod, mod))\n",
        "\n",
        "# interacciones (más pequeñas y NO gigantes)\n",
        "dot.attr(\"node\", width=\"1.85\", height=\"1.15\", shape=\"box\", style=\"rounded,filled\", fillcolor=\"#6FA8DC\", color=\"#2F5597\")\n",
        "for n in inter:\n",
        "    dot.node(n, label=pretty.get(n, n))\n",
        "\n",
        "# --------- 4) Subgrafos para ordenar por columnas ---------\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    for n in exo:\n",
        "        s.node(n)\n",
        "\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    for n in med:\n",
        "        s.node(n)\n",
        "\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    s.node(end[0])\n",
        "\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    s.node(mod)\n",
        "\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    for n in inter:\n",
        "        s.node(n)\n",
        "\n",
        "# --------- 5) Dibujar paths con betas (Stage 2) ---------\n",
        "dot.attr(\"edge\", fontname=\"Arial\", fontsize=\"10\", arrowsize=\"0.9\")\n",
        "\n",
        "for endog, exogs in paths_stage2.items():\n",
        "    for ex in exogs:\n",
        "        beta = betas2.get(endog, {}).get(ex, None)\n",
        "        signif = sig_map.get((endog, ex), None) if sig_map else None\n",
        "        st = edge_style(beta, signif)\n",
        "\n",
        "        # etiqueta beta + (si hay p) agrega p pequeño\n",
        "        lab = fmt_beta(beta)\n",
        "        if (endog, ex) in p_map and not math.isnan(p_map[(endog, ex)]):\n",
        "            lab = f\"{lab}\\n(p={p_map[(endog, ex)]:.3f})\"\n",
        "\n",
        "        dot.edge(ex, endog, label=lab, color=st[\"color\"], style=st[\"style\"], penwidth=st[\"penwidth\"])\n",
        "\n",
        "# --------- 6) Moderación (líneas rojas punteadas del moderador a interacciones) ---------\n",
        "dot.attr(\"edge\", color=\"red\", style=\"dashed\", penwidth=\"1.6\")\n",
        "dot.edge(mod, \"actitud_x_conciencia_de_la_persuasion\", label=\"\")\n",
        "dot.edge(mod, \"engagement_x_conciencia_de_la_persuasion\", label=\"\")\n",
        "\n",
        "# --------- 7) Render ---------\n",
        "out = dot.render(\"sem_stage2_pretty\", cleanup=True)\n",
        "print(\"✅ Listo. Archivo generado:\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCbYHW6bp2jb",
        "outputId": "20a9c779-d03a-484a-ece9-4db9e8d2dd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: node 'conciencia_de_la_persuasion', graph 'SEM_STAGE2_PRETTY' size too small for label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Listo. Archivo generado: sem_stage2_pretty.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# DIAGRAMA SEM \"RICO\" (FIX): β + p + CI + f² (y opcional VIF)\n",
        "# Evita AttributeError usando dict en vez de itertuples()\n",
        "# Requiere: betas2, r2s2, paths_stage2, df_paths_ext\n",
        "# Salida: sem_stage2_rich.png\n",
        "# ============================\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from graphviz import Digraph\n",
        "\n",
        "# -------- helpers ----------\n",
        "def safe_float(x):\n",
        "    try:\n",
        "        x = float(x)\n",
        "        if math.isnan(x) or math.isinf(x):\n",
        "            return np.nan\n",
        "        return x\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def stars_from_p(p):\n",
        "    if p is None or math.isnan(p):\n",
        "        return \"\"\n",
        "    if p < 0.001: return \"***\"\n",
        "    if p < 0.01:  return \"**\"\n",
        "    if p < 0.05:  return \"*\"\n",
        "    return \"\"\n",
        "\n",
        "def edge_style(beta, sig):\n",
        "    # color por signo, grosor por |β|, si no sig -> gris punteado\n",
        "    if beta is None or math.isnan(beta):\n",
        "        return {\"color\":\"#9E9E9E\", \"style\":\"dashed\", \"penwidth\":\"1.2\"}\n",
        "    pw = 1.2 + min(4.0, abs(beta)*6.0)\n",
        "    col = \"#1B9E77\" if beta >= 0 else \"#D95F02\"\n",
        "    if sig is False:\n",
        "        return {\"color\":\"#9E9E9E\", \"style\":\"dashed\", \"penwidth\":str(max(1.1, pw-0.6))}\n",
        "    return {\"color\":col, \"style\":\"solid\", \"penwidth\":str(pw)}\n",
        "\n",
        "# -------- etiquetas cortas ----------\n",
        "pretty = {\n",
        "    \"credibilidad\": \"Credibilidad\",\n",
        "    \"semejanza\": \"Semejanza\",\n",
        "    \"flujo_de_informacion\": \"Flujo de información\",\n",
        "    \"congruencia\": \"Congruencia\",\n",
        "    \"actitud\": \"Actitud\",\n",
        "    \"engagement\": \"Engagement\",\n",
        "    \"predisposicion_a_comprar_un_producto\": \"Intención de compra\",\n",
        "    \"conciencia_de_la_persuasion\": \"Conciencia de la persuasión\",\n",
        "    \"actitud_x_conciencia_de_la_persuasion\": \"Actitud × Conciencia\",\n",
        "    \"engagement_x_conciencia_de_la_persuasion\": \"Engagement × Conciencia\",\n",
        "}\n",
        "\n",
        "exo = [\"credibilidad\", \"semejanza\", \"flujo_de_informacion\", \"congruencia\"]\n",
        "med = [\"actitud\", \"engagement\"]\n",
        "end = [\"predisposicion_a_comprar_un_producto\"]\n",
        "mod = \"conciencia_de_la_persuasion\"\n",
        "inter = [\"actitud_x_conciencia_de_la_persuasion\", \"engagement_x_conciencia_de_la_persuasion\"]\n",
        "\n",
        "def fmt_node(n):\n",
        "    base = pretty.get(n, n)\n",
        "    if n in r2s2:\n",
        "        return f\"{base}\\nR²={r2s2[n]:.3f}\"\n",
        "    return base\n",
        "\n",
        "# --------- indexar df_paths_ext como dict (robusto) ----------\n",
        "# clave: (Endog, Exog) -> dict con valores de columnas\n",
        "key_index = {}\n",
        "for _, r in df_paths_ext.iterrows():\n",
        "    key_index[(r[\"Endog\"], r[\"Exog\"])] = r.to_dict()\n",
        "\n",
        "# toggles para no saturar etiquetas\n",
        "SHOW_CI = True\n",
        "SHOW_F2 = True\n",
        "SHOW_VIF = False  # pon True si lo quieres (a veces satura)\n",
        "\n",
        "# --------- crear grafo ----------\n",
        "dot = Digraph(\"SEM_STAGE2_RICH\", format=\"png\")\n",
        "dot.attr(rankdir=\"LR\", splines=\"spline\", nodesep=\"0.6\", ranksep=\"1.0\", pad=\"0.25\")\n",
        "\n",
        "# nodos latentes (círculos)\n",
        "dot.attr(\"node\", shape=\"circle\", style=\"filled\", fixedsize=\"true\",\n",
        "         width=\"1.65\", height=\"1.65\", fontname=\"Arial\", fontsize=\"11\",\n",
        "         fillcolor=\"#6FA8DC\", color=\"#2F5597\", fontcolor=\"white\")\n",
        "\n",
        "for n in exo + med:\n",
        "    dot.node(n, label=fmt_node(n))\n",
        "\n",
        "# endógena final más grande\n",
        "dot.attr(\"node\", width=\"2.10\", height=\"2.10\")\n",
        "dot.node(end[0], label=fmt_node(end[0]))\n",
        "\n",
        "# moderador verde\n",
        "dot.attr(\"node\", width=\"1.75\", height=\"1.75\", fillcolor=\"#93C47D\", color=\"#38761D\")\n",
        "dot.node(mod, label=pretty.get(mod, mod))\n",
        "\n",
        "# interacciones como cajas\n",
        "dot.attr(\"node\", shape=\"box\", style=\"rounded,filled\", width=\"2.05\", height=\"0.9\",\n",
        "         fillcolor=\"#6FA8DC\", color=\"#2F5597\", fontcolor=\"white\")\n",
        "for n in inter:\n",
        "    dot.node(n, label=pretty.get(n, n))\n",
        "\n",
        "# ranks por columnas\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    for n in exo: s.node(n)\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    for n in med: s.node(n)\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\"); s.node(end[0])\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\"); s.node(mod)\n",
        "with dot.subgraph() as s:\n",
        "    s.attr(rank=\"same\")\n",
        "    for n in inter: s.node(n)\n",
        "\n",
        "# edges\n",
        "dot.attr(\"edge\", fontname=\"Arial\", fontsize=\"10\", arrowsize=\"0.9\")\n",
        "\n",
        "for endog, exogs in paths_stage2.items():\n",
        "    for ex in exogs:\n",
        "        row = key_index.get((endog, ex), {})  # dict con columnas, o vacío\n",
        "        beta = safe_float(betas2.get(endog, {}).get(ex, np.nan))\n",
        "\n",
        "        # estas claves EXISTEN tal como en df_paths_ext\n",
        "        p = safe_float(row.get(\"p_emp(2-colas)\", np.nan))\n",
        "        sig = row.get(\"Sig_0.05\", None)      # True/False o None\n",
        "        ci_lo = safe_float(row.get(\"CI_2.5%\", np.nan))\n",
        "        ci_hi = safe_float(row.get(\"CI_97.5%\", np.nan))\n",
        "        f2 = safe_float(row.get(\"f2\", np.nan))\n",
        "        vif = safe_float(row.get(\"VIF\", np.nan))\n",
        "\n",
        "        st = edge_style(beta, sig if sig is not None else True)\n",
        "\n",
        "        # etiqueta\n",
        "        lab = f\"{beta:+.3f}{stars_from_p(p)}\"\n",
        "        if not math.isnan(p): lab += f\"\\n(p={p:.3f})\"\n",
        "        if SHOW_CI and (not math.isnan(ci_lo) and not math.isnan(ci_hi)):\n",
        "            lab += f\"\\n[{ci_lo:+.3f}, {ci_hi:+.3f}]\"\n",
        "        if SHOW_F2 and (not math.isnan(f2)):\n",
        "            lab += f\"\\nf²={f2:.3f}\"\n",
        "        if SHOW_VIF and (not math.isnan(vif)):\n",
        "            lab += f\"\\nVIF={vif:.2f}\"\n",
        "\n",
        "        dot.edge(ex, endog, label=lab, color=st[\"color\"], style=st[\"style\"], penwidth=st[\"penwidth\"])\n",
        "\n",
        "# moderación (rojo punteado desde conciencia a interacciones)\n",
        "dot.attr(\"edge\", color=\"red\", style=\"dashed\", penwidth=\"1.6\")\n",
        "dot.edge(mod, inter[0], label=\"\")\n",
        "dot.edge(mod, inter[1], label=\"\")\n",
        "\n",
        "out = dot.render(\"sem_stage2_rich\", cleanup=True)\n",
        "print(\"✅ Diagrama generado:\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-IzztfptBlF",
        "outputId": "c696ad3b-d165-4aba-d2c2-effffdf0e0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: node 'conciencia_de_la_persuasion', graph 'SEM_STAGE2_RICH' size too small for label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Diagrama generado: sem_stage2_rich.png\n"
          ]
        }
      ]
    }
  ]
}